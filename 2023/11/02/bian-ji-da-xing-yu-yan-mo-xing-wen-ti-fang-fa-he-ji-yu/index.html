
<!DOCTYPE html><html lang="zh-CN">

<head>
  <meta charset="utf-8">
  <meta name="hexo-theme" content="https://github.com/xaoxuu/hexo-theme-stellar/tree/1.27.0" theme-name="Stellar" theme-version="1.27.0">
  
  <meta name="generator" content="Hexo 7.0.0">
  <meta http-equiv='x-dns-prefetch-control' content='on' />
  
  <meta name="renderer" content="webkit">
  <meta name="force-rendering" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  <meta name="HandheldFriendly" content="True" >
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="theme-color" content="#f8f8f8">
  
  <title>编辑大型语言模型：问题、方法和机遇 - humbleyl</title>

  
    <meta name="description" content="编辑大型语言模型：问题、方法和机遇Abstruct尽管有能力培养有能力的LLMs，但维持其相关性和纠正错误的方法仍然难以捉摸。为此，过去几年见证了LLMs编辑技术的激增，其目标是有效地改变特定领域内LLMs的行为，而不会对其他输入的性能产生负面影响。本文深入探讨了LLMs模型编辑相关的问题、方法和机遇。特别是，我们对任务定义和与模型编辑相关的挑战进行了详尽的概述，并对我们目前掌握的最先进的方法进行">
<meta property="og:type" content="article">
<meta property="og:title" content="编辑大型语言模型：问题、方法和机遇">
<meta property="og:url" content="http://humble2967738843.github.io/2023/11/02/bian-ji-da-xing-yu-yan-mo-xing-wen-ti-fang-fa-he-ji-yu/index.html">
<meta property="og:site_name" content="humbleyl">
<meta property="og:description" content="编辑大型语言模型：问题、方法和机遇Abstruct尽管有能力培养有能力的LLMs，但维持其相关性和纠正错误的方法仍然难以捉摸。为此，过去几年见证了LLMs编辑技术的激增，其目标是有效地改变特定领域内LLMs的行为，而不会对其他输入的性能产生负面影响。本文深入探讨了LLMs模型编辑相关的问题、方法和机遇。特别是，我们对任务定义和与模型编辑相关的挑战进行了详尽的概述，并对我们目前掌握的最先进的方法进行">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://humble2967738843.github.io/2023/11/02/imgs/$%7Bfiilename%7D/SWBFWKDL.png">
<meta property="og:image" content="http://humble2967738843.github.io/2023/11/02/imgs/$%7Bfiilename%7D/YCQJYKA2.png">
<meta property="og:image" content="http://humble2967738843.github.io/2023/11/02/imgs/$%7Bfiilename%7D/Q3XB8E8H.png">
<meta property="og:image" content="http://humble2967738843.github.io/2023/11/02/imgs/$%7Bfiilename%7D/TSPLLYFE.png">
<meta property="og:image" content="http://humble2967738843.github.io/2023/11/02/imgs/$%7Bfiilename%7D/88F6ZZTR.png">
<meta property="og:image" content="http://humble2967738843.github.io/2023/11/02/imgs/$%7Bfiilename%7D/Y5M6Y7UX.png">
<meta property="og:image" content="http://humble2967738843.github.io/2023/11/02/imgs/$%7Bfiilename%7D/B7WY2DBH.png">
<meta property="og:image" content="http://humble2967738843.github.io/2023/11/02/imgs/$%7Bfiilename%7D/WVMGDVMU.png">
<meta property="og:image" content="http://humble2967738843.github.io/2023/11/02/imgs/$%7Bfiilename%7D/AKCEUPGK.png">
<meta property="og:image" content="http://humble2967738843.github.io/2023/11/02/imgs/$%7Bfiilename%7D/ND8H464M.png">
<meta property="og:image" content="http://humble2967738843.github.io/2023/11/02/imgs/$%7Bfiilename%7D/EQ2WM2DI.png">
<meta property="og:image" content="http://humble2967738843.github.io/2023/11/02/imgs/$%7Bfiilename%7D/K9ABI2KM.png">
<meta property="article:published_time" content="2023-11-02T04:21:08.000Z">
<meta property="article:modified_time" content="2023-11-07T04:07:01.403Z">
<meta property="article:author" content="yuan long">
<meta property="article:tag" content="EMNLP2023">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://humble2967738843.github.io/2023/11/02/imgs/$%7Bfiilename%7D/SWBFWKDL.png">
<meta name="twitter:creator" content="@humbleyl">
  
  
  
  <meta name="keywords" content="EMNLP2023">

  <!-- feed -->
  
    <link rel="alternate" href="/atom.xml" title="humbleyl" type="application/atom+xml">
  

  <link rel="stylesheet" href="/css/main.css?v=1.27.0">

  
    <link rel="shortcut icon" href="solar:documents-bold-duotone">
  

  

  
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --></head>
<body>

<div class="l_body s:aa content tech" id="start" layout="post" ><aside class="l_left"><div class="leftbar-container">


<header class="header"><div class="logo-wrap"><a class="avatar" href="/about/"><div class="bg" style="opacity:0;background-image:url(https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/avatar/round/rainbow64@3x.webp);"></div><img no-lazy class="avatar" src="https://s2.loli.net/2024/04/10/32Y4obwgxJCeOMr.png" onerror="javascript:this.classList.add('error');this.src='https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/image/2659360.svg';"></a><a class="title" href="/"><div class="main" ff="title">humbleyl</div><div class="sub normal cap">院龙的博客</div><div class="sub hover cap" style="opacity:0"> humbleyl</div></a></div></header>

<div class="nav-area">
<div class="search-wrapper" id="search-wrapper"><form class="search-form"><a class="search-button" onclick="document.getElementById(&quot;search-input&quot;).focus();"><svg t="1705074644177" viewBox="0 0 1025 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="1560" width="200" height="200"><path d="M1008.839137 935.96571L792.364903 719.491476a56.783488 56.783488 0 0 0-80.152866 0 358.53545 358.53545 0 1 1 100.857314-335.166073 362.840335 362.840335 0 0 1-3.689902 170.145468 51.248635 51.248635 0 1 0 99.217358 26.444296 462.057693 462.057693 0 1 0-158.255785 242.303546l185.930047 185.725053a51.248635 51.248635 0 0 0 72.568068 0 51.248635 51.248635 0 0 0 0-72.978056z" p-id="1561"></path><path d="M616.479587 615.969233a50.428657 50.428657 0 0 0-61.498362-5.534852 174.655348 174.655348 0 0 1-177.525271 3.484907 49.403684 49.403684 0 0 0-58.833433 6.76482l-3.074918 2.869923a49.403684 49.403684 0 0 0 8.609771 78.10292 277.767601 277.767601 0 0 0 286.992355-5.739847 49.403684 49.403684 0 0 0 8.404776-76.667958z" p-id="1562"></path></svg></a><input type="text" class="search-input" id="search-input" placeholder="站内搜索"></form><div id="search-result"></div><div class="search-no-result">没有找到内容！</div></div>


<nav class="menu dis-select"><a class="nav-item active" title="博客" href="/" style="color:#1BCDFC"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M5.879 2.879C5 3.757 5 5.172 5 8v8c0 2.828 0 4.243.879 5.121C6.757 22 8.172 22 11 22h2c2.828 0 4.243 0 5.121-.879C19 20.243 19 18.828 19 16V8c0-2.828 0-4.243-.879-5.121C17.243 2 15.828 2 13 2h-2c-2.828 0-4.243 0-5.121.879M8.25 17a.75.75 0 0 1 .75-.75h3a.75.75 0 0 1 0 1.5H9a.75.75 0 0 1-.75-.75M9 12.25a.75.75 0 0 0 0 1.5h6a.75.75 0 0 0 0-1.5zM8.25 9A.75.75 0 0 1 9 8.25h6a.75.75 0 0 1 0 1.5H9A.75.75 0 0 1 8.25 9" clip-rule="evenodd"/><path fill="currentColor" d="M5.235 4.058C5 4.941 5 6.177 5 8v8c0 1.823 0 3.058.235 3.942L5 19.924c-.975-.096-1.631-.313-2.121-.803C2 18.243 2 16.828 2 14v-4c0-2.829 0-4.243.879-5.121c.49-.49 1.146-.707 2.121-.803zm13.53 15.884C19 19.058 19 17.822 19 16V8c0-1.823 0-3.059-.235-3.942l.235.018c.975.096 1.631.313 2.121.803C22 5.757 22 7.17 22 9.999v4c0 2.83 0 4.243-.879 5.122c-.49.49-1.146.707-2.121.803z" opacity=".5"/></svg></a><a class="nav-item" title="文档" href="/wiki/" style="color:#3DC550"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M14.25 4.48v3.057c0 .111 0 .27.02.406a.936.936 0 0 0 .445.683a.96.96 0 0 0 .783.072c.13-.04.272-.108.378-.159L17 8.005l1.124.534c.106.05.248.119.378.16a.958.958 0 0 0 .783-.073a.936.936 0 0 0 .444-.683c.021-.136.021-.295.021-.406V3.031c.113-.005.224-.01.332-.013C21.154 2.98 22 3.86 22 4.933v11.21c0 1.112-.906 2.01-2.015 2.08c-.97.06-2.108.179-2.985.41c-1.082.286-1.99 1.068-3.373 1.436c-.626.167-1.324.257-1.627.323V5.174c.32-.079 1.382-.203 1.674-.371c.184-.107.377-.216.576-.323m5.478 8.338a.75.75 0 0 1-.546.91l-4 1a.75.75 0 0 1-.364-1.456l4-1a.75.75 0 0 1 .91.546" clip-rule="evenodd"/><path fill="currentColor" d="M18.25 3.151c-.62.073-1.23.18-1.75.336a8.2 8.2 0 0 0-.75.27v3.182l.75-.356l.008-.005a1.13 1.13 0 0 1 .492-.13c.047 0 .094.004.138.01c.175.029.315.1.354.12l.009.005l.749.356V3.647z"/><path fill="currentColor" d="M12 5.214c-.334-.064-1.057-.161-1.718-.339C8.938 4.515 8.05 3.765 7 3.487c-.887-.234-2.041-.352-3.018-.412C2.886 3.007 2 3.9 2 4.998v11.146c0 1.11.906 2.01 2.015 2.079c.97.06 2.108.179 2.985.41c.486.129 1.216.431 1.873.726c1.005.451 2.052.797 3.127 1.034z" opacity=".5"/><path fill="currentColor" d="M4.273 12.818a.75.75 0 0 1 .91-.545l4 1a.75.75 0 1 1-.365 1.455l-4-1a.75.75 0 0 1-.545-.91m.909-4.545a.75.75 0 1 0-.364 1.455l4 1a.75.75 0 0 0 .364-1.455z"/></svg></a><a class="nav-item" title="探索" href="/explore/" style="color:#FA6400"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><path fill="currentColor" d="M20 12a8 8 0 1 1-16 0a8 8 0 0 1 16 0" opacity=".5"/><path fill="currentColor" d="M17.712 5.453c1.047-.193 2.006-.259 2.797-.152c.77.103 1.536.393 1.956 1.064c.446.714.312 1.542-.012 2.258c-.33.728-.918 1.499-1.672 2.268c-1.516 1.547-3.836 3.226-6.597 4.697c-2.763 1.472-5.495 2.484-7.694 2.92c-1.095.217-2.098.299-2.923.201c-.8-.095-1.6-.383-2.032-1.075c-.47-.752-.296-1.63.07-2.379c.375-.768 1.032-1.586 1.872-2.403L4 12.416c0 .219.083.71.168 1.146c.045.23.09.444.123.596c-.652.666-1.098 1.263-1.339 1.756c-.277.567-.208.825-.145.925c.072.116.305.305.937.38c.609.073 1.44.018 2.455-.183c2.02-.4 4.613-1.351 7.28-2.772c2.667-1.42 4.85-3.015 6.23-4.423c.694-.707 1.15-1.334 1.377-1.836c.233-.515.167-.75.107-.844c-.07-.112-.289-.294-.883-.374c-.542-.072-1.272-.041-2.163.112L16.87 5.656c.338-.101.658-.17.842-.203"/></svg></a><a class="nav-item" title="社交" href="/friends/" style="color:#F44336"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><path fill="currentColor" d="m13.629 20.472l-.542.916c-.483.816-1.69.816-2.174 0l-.542-.916c-.42-.71-.63-1.066-.968-1.262c-.338-.197-.763-.204-1.613-.219c-1.256-.021-2.043-.098-2.703-.372a5 5 0 0 1-2.706-2.706C2 14.995 2 13.83 2 11.5v-1c0-3.273 0-4.91.737-6.112a5 5 0 0 1 1.65-1.651C5.59 2 7.228 2 10.5 2h3c3.273 0 4.91 0 6.113.737a5 5 0 0 1 1.65 1.65C22 5.59 22 7.228 22 10.5v1c0 2.33 0 3.495-.38 4.413a5 5 0 0 1-2.707 2.706c-.66.274-1.447.35-2.703.372c-.85.015-1.275.022-1.613.219c-.338.196-.548.551-.968 1.262" opacity=".5"/><path fill="currentColor" d="M10.99 14.308c-1.327-.978-3.49-2.84-3.49-4.593c0-2.677 2.475-3.677 4.5-1.609c2.025-2.068 4.5-1.068 4.5 1.609c0 1.752-2.163 3.615-3.49 4.593c-.454.335-.681.502-1.01.502c-.329 0-.556-.167-1.01-.502"/></svg></a></nav>
</div>
<div class="widgets">


<widget class="widget-wrapper post-list"><div class="widget-header dis-select"><span class="name">最近更新</span></div><div class="widget-body fs14"><a class="item title" href="/2024/04/10/tui-jian-xi-tong/"><span class="title">推荐系统</span></a><a class="item title" href="/2023/12/29/zi-zhu-yi-li-ji-zhi/"><span class="title">自注意力机制</span></a><a class="item title" href="/2024/01/15/xi-gua-shu/"><span class="title">西瓜书</span></a><a class="item title" href="/2024/01/01/transformer/"><span class="title">Transformer</span></a><a class="item title" href="/2024/01/01/bert-and-its-family/"><span class="title">BERT and its family</span></a><a class="item title" href="/2024/01/16/53-li-jie-dropout/"><span class="title">53理解Dropout</span></a><a class="item title" href="/2024/01/13/52-dropout-zheng-ze-hua/"><span class="title">52Dropout正则化</span></a><a class="item title" href="/2024/01/06/51-wei-shi-me-zheng-ze-hua-ke-yi-jian-shao-guo-ni-he/"><span class="title">为什么正则化可以减少过拟合？</span></a><a class="item title" href="/2024/01/05/50-zheng-ze-hua/"><span class="title">50正则化</span></a><a class="item title" href="/2024/01/05/49-ji-qi-xue-xi-ji-chu/"><span class="title">49机器学习基础</span></a></div></widget>
</div>
<footer class="footer dis-select"><div class="social-wrap"><a class="social" href="https://github.com/Humble2967738843" target="_blank" rel="external nofollow noopener noreferrer"><svg t="1716701113980" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="4745" width="200" height="200"><path d="M512 512m-469.333333 0a469.333333 469.333333 0 1 0 938.666666 0 469.333333 469.333333 0 1 0-938.666666 0Z" fill="#434A54" p-id="4746"></path><path d="M610.688 808.149333c0-12.074667 0.426667-51.498667 0.426667-100.437333 0-34.133333-11.733333-56.448-24.832-67.84 81.493333-9.045333 167.125333-39.978667 167.125333-180.608 0-39.936-14.208-72.618667-37.674667-98.261333 3.84-9.216 16.341333-46.421333-3.584-96.853334 0 0-30.72-9.813333-100.565333 37.546667a351.658667 351.658667 0 0 0-91.733333-12.373333 350.549333 350.549333 0 0 0-91.605334 12.373333c-69.973333-47.36-100.693333-37.546667-100.693333-37.546667-19.882667 50.432-7.338667 87.637333-3.541333 96.853334a141.653333 141.653333 0 0 0-37.717334 98.261333c0 140.288 85.461333 171.690667 166.784 180.906667-10.453333 9.173333-19.968 25.301333-23.253333 48.981333-20.906667 9.386667-73.856 25.514667-106.496-30.421333 0 0-19.370667-35.157333-56.149333-37.76 0 0-35.712-0.426667-2.474667 22.272 0 0 23.978667 11.264 40.618667 53.546666 0 0 21.504 65.365333 123.349333 43.221334 0.170667 30.592 0.512 59.392 0.512 68.138666a19.968 19.968 0 0 1-2.218667 9.173334 339.925333 339.925333 0 0 0 187.904 3.114666 19.2 19.2 0 0 1-4.181333-12.288z" fill="#FFFFFF" p-id="4747"></path><path d="M180.138667 843.861333A467.882667 467.882667 0 0 0 512 981.333333c259.2 0 469.333333-210.133333 469.333333-469.333333 0-129.621333-52.522667-246.954667-137.472-331.861333L180.138667 843.861333z" fill="#231F20" opacity=".1" p-id="4748"></path></svg></a><a class="social" href="https://" target="_blank" rel="external nofollow noopener noreferrer"><svg t="1716701237965" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="12408" width="200" height="200"><path d="M276.822886 874.188342c-47.901937-0.484303-85.721573-1.942714-96.222136 64.483801-4.204628 59.150968 41.545465 67.092431 120.596869 81.461911 86.981861 4.49631 137.949214 16.482801 205.118694-49.93821l-227.814878-96.106564" fill="" p-id="12409"></path><path d="M270.939709 875.64125c-24.792995 0-64.296684-0.968605-81.098684 43.647779 2.102314 5.332833 12.327704 2.982864 18.794246-1.562977 9.691557-4.589869 5.162226 1.799625-5.552971 10.412507-11.661788 8.12858-37.660036 34.54509 6.461038 61.633019 46.801249 21.645028 193.974228 61.280799 285.678041-16.169105 0 0-180.892553-56.256158-222.493052-97.944713h-1.788618v-0.01651z" fill="#F0971C" p-id="12410"></path><path d="M764.482659 865.94419c47.896434-0.484303 85.710567-1.948218 96.222136 64.4838 4.204628 59.150968-64.731455 68.859035-120.602373 81.461912-59.734332 5.51995-137.949214 16.488305-205.118693-49.93821l227.820381-96.106564" fill="" p-id="12411"></path><path d="M770.360332 867.402601c24.787491 0 64.29118-0.974109 81.087678 43.642275-2.09681 5.332833-12.316698 2.982864-18.777736-1.562976-9.708067-4.589869-5.16773 1.799625 5.547467 10.412507 11.661788 8.123077 37.66554 34.54509-6.461038 61.633019-46.801249 21.645028-193.974228 61.275295-285.683544-16.174609 0 0 180.903559-56.250655 222.504059-97.939209l1.783114-0.011007z" fill="#F0971C" p-id="12412"></path><path d="M825.598354 441.216247c51.259035 54.307941 83.206502 107.641773 108.412255 245.337829 3.417636 83.393619-7.567229 91.153468-31.947466 113.453405-17.638524-2.905816-36.124577-30.059786-54.616134-94.070291-18.491557-63.993994-21.848655-264.720943-21.848655-264.720943z" fill="" p-id="12413"></path><path d="M847.452513 380.128069c0-15.21701-4.716448-29.894683-13.466917-43.741337C832.994977 150.420008 697.560835 0 530.619501 0 363.683671 0 228.249529 150.420008 227.25891 336.386732c-8.744965 13.852157-13.466916 28.52983-13.466917 43.735833 0 22.228392 10.043777 43.334083 28.078549 62.342963 39.349592 136.000997 153.744086 234.385984 288.748959 234.385984 135.015881 0 249.404871-98.384988 288.759967-234.385984 18.034771-19.003377 28.073045-40.109067 28.073045-62.337459zM198.035646 442.184853C146.771107 496.48729 114.834648 549.826626 89.623392 687.517178c-3.423139 83.393619 25.899186 111.031892 31.936459 113.458909 6.042777 2.410506 36.135584-30.06529 54.62714-94.064788 18.486053-63.988491 21.848655-264.726446 21.848655-264.726446z" fill="" p-id="12414"></path><path d="M864.254513 621.585973c0 200.82601-158.394492 363.634261-353.810621 363.634261-195.394116 0-353.805118-162.80825-353.805118-363.634261 0-200.831514 158.405499-363.639764 353.805118-363.639764 195.410626 0 353.810621 162.802747 353.810621 363.639764z" fill="" p-id="12415"></path><path d="M220.50619 696.245633c0 149.952216 134.702185 271.517691 300.86203 271.517691 166.154342 0 300.86203-121.565475 300.86203-271.517691s-134.707688-271.517691-300.86203-271.51769c-166.154342 0.005503-300.86203 121.565475-300.86203 271.51769z" fill="#FFFFFF" p-id="12416"></path><path d="M232.068916 322.672161s-23.950969 19.636272-18.909818 60.361724c-25.211256 30.544089-20.797498 62.54659-9.454909 95.281048 18.909818 62.788741 146.650152 162.665161 309.684043 162.665161 223.544209-15.018886 289.090173-123.392617 338.890797-180.122071 0 0 29.003126-47.280049-18.909818-129.457407l-72.491305 7.275547-528.80899-16.004002z" fill="" p-id="12417"></path><path d="M302.980734 572.85852c-3.147967 33.086678-15.128955 139.996494 3.786366 166.545086 20.170106 26.190869 44.43477 38.909317 96.112067 30.907316 23.323577-7.638774 28.364727-29.817635 26.163352-61.809129l-0.946592-92.364225-125.115193-43.279048z" fill="" p-id="12418"></path><path d="M223.246902 372.126068s83.200998 144.002998 271.033388 151.273041c83.206502 1.458411 167.662284 8.728455 292.458278-87.26804 24.583864-25.453408 29.003126-33.455409 29.003126-33.455409s8.189118 65.457909-112.820509 147.635268c0 0 82.562599 0.731957 141.812629-170.182859 0 0 29.003126 111.274043-72.480298 164.36022-93.288803 56.008504-154.432015 93.090679-309.480417 84.362224-101.874168-25.326829-254.005746-65.457909-264.726446-192.730451 0 0 6.306942-29.817635 14.49606-24.000499 0 0 0.627392 69.095683 52.943088 92.364225-0.011007 0.005503-52.326703-77.807627-42.238899-132.35772z" fill="#E71F19" p-id="12419"></path><path d="M321.059532 589.605486s-36.240149 138.185862 4.413759 161.459908c41.2813 19.273045 66.498059 14.182364 94.229891 4.727454 11.661788-16.004002 1.260288-111.63727 4.721951-121.455406-6.306942-4.006504-24.892057-8.370731-28.051031-8.370731 0 0-2.834271 40.719949-0.313696 65.463413-5.046654-19.273045-8.827517-19.273045-8.827517-71.275045-30.235897-10.550093-66.173356-30.549593-66.173357-30.549593z" fill="#E71F19" p-id="12420"></path><path d="M506.316313 242.426509c0 50.60963-22.487054 91.637771-50.218886 91.637771s-50.218885-41.028141-50.218885-91.637771 22.487054-91.637771 50.218885-91.63777c27.731832-0.005503 50.218885 41.022638 50.218886 91.63777z m147.492178 0c0 50.60963-22.498061 91.637771-50.218885 91.637771-27.731832 0-50.218885-41.028141-50.218886-91.637771s22.487054-91.637771 50.218886-91.63777c27.726328-0.005503 50.218885 41.022638 50.218885 91.63777z" fill="#FFFFFF" p-id="12421"></path><path d="M499.530572 243.395115c0 19.553721-8.469793 35.398123-18.915322 35.398123-10.440025 0-18.915322-15.844402-18.915321-35.398123 0-19.548217 8.469793-35.398123 18.915321-35.398123 10.445528 0.005503 18.915322 15.855409 18.915322 35.398123z m74.791742 10.54459c-1.794121-18.238398 8.662414-44.368729 29.151719-37.638023 14.86479 6.730706 14.028267 32.547341 13.703565 39.096434-0.324703 6.538086-8.97611 11.089431-12.922076 0-1.893183-10.36848-10.093308-41.63352-17.176235-2.371982-2.360976 9.091682-11.969981 8.915572-12.756973 0.913571z" fill="" p-id="12422"></path><path d="M676.779847 358.472035c-37.032644-15.618761-89.452905-25.381863-147.624261-25.381863-56.872544 0-108.236144 9.32833-145.109189 24.347216-30.57711 12.44878-57.648529 34.567103-56.597371 47.02689 3.153471 12.503815 13.13671 20.626891 68.176608 29.118699-19.53721-18.915322-15.21701-14.600625-15.21701-43.5212 0 28.920575 23.48868 43.669792 61.357847 59.42614 24.853533 10.340963 55.386615 16.455284 88.418259 16.455284 34.677172 0 66.602625-6.73621 92.072542-18.023764 35.805377-15.855409 53.108191-28.661913 53.108191-56.6414 0 27.979486 5.773108 19.030894-17.242276 42.310443 53.366853-9.383364 70.17986-19.757348 71.5227-32.525327 0.022014-11.238023-25.55247-31.072419-52.86604-42.591118z" fill="#F0971C" p-id="12423"></path></svg></a><a class="social" href="https://www.kaggle.com/humbleyll" target="_blank" rel="external nofollow noopener noreferrer"><svg t="1716701307894" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="13418" width="200" height="200"><path d="M803.1909 1017.952189c-0.927971 3.935877-4.991844 6.015812-11.999625 6.015812H657.27546c-7.967751 0-14.975532-3.487891-20.991344-10.591669l-220.921096-281.111215-61.790069 58.622168v218.073185c0 10.015687-4.991844 15.007531-14.975532 15.007531H234.88866c-10.079685 0-15.103528-4.991844-15.103528-15.007531V15.071529C219.785132 5.11984 224.808975 0 234.88866 0h103.708759c9.983688 0 14.975532 5.11984 14.975532 15.071529v611.948877l264.663729-267.607638c7.03978-7.03978 14.07956-10.495672 21.11934-10.495672h138.203681c6.143808 0 10.079685 2.55992 12.15962 7.67976 1.951939 6.367801 1.439955 10.87966-1.535952 13.43958l-279.67126 270.679542 291.670885 362.964657c4.063873 4.447861 4.991844 8.863723 2.975907 15.263523z" fill="#20BEFF" p-id="13419"></path></svg></a><a class="social" href="https://" target="_blank" rel="external nofollow noopener noreferrer"><svg t="1716701358358" class="icon" viewBox="0 0 1025 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="14411" width="200" height="200"><path d="M1024.16 694.816c0-149.92-143.104-271.392-319.584-271.392-176.576 0-319.68 121.504-319.68 271.392S528 966.208 704.576 966.208c55.456 0 107.648-12.096 153.184-33.248l125.984 54.528-14.592-140.544c34.784-43.392 55.04-95.808 55.04-152.128zM596.832 621.28c-25.152 0-45.472-20.352-45.472-45.472s20.32-45.472 45.472-45.472c25.12 0 45.44 20.384 45.44 45.472s-20.384 45.472-45.44 45.472z m215.392 0c-25.056 0-45.44-20.352-45.44-45.472s20.384-45.472 45.44-45.472c25.184 0 45.536 20.384 45.536 45.472s-20.352 45.472-45.536 45.472zM704.576 387.488c49.376 0 96.416 8.8 139.264 24.64 0.32-5.728 0.992-11.232 0.992-16.992 0-198.08-189.152-358.624-422.432-358.624C189.184 36.512 0.032 197.024 0.032 395.136c0 74.496 26.816 143.776 72.704 201.12L53.472 781.92l166.432-72.096c41.216 19.2 86.784 32.16 134.88 38.784-3.616-17.504-5.824-35.424-5.824-53.792 0.032-169.44 159.552-307.296 355.616-307.296z m-139.808-209.6c33.184 0 60 26.88 60 60 0 33.184-26.816 60.064-60 60.064s-60.032-26.88-60.032-60.064c0-33.152 26.88-60 60.032-60zM280.032 297.952c-33.184 0-60-26.88-60-60.064 0-33.152 26.848-60 60-60 33.184 0 60.032 26.88 60.032 60s-26.88 60.064-60.032 60.064z" fill="#51C332" p-id="14412"></path></svg></a></div></footer>
</div></aside><div class="l_main" id="main">





<div class="article banner top">
  <div class="content">
    <div class="top bread-nav footnote"><div class="left"><div class="flex-row" id="breadcrumb"><a class="cap breadcrumb" href="/">主页</a>
<span class="sep"></span><a class="cap breadcrumb" href="/">文章</a><span class="sep"></span><a class="cap breadcrumb-link" href="/categories/NLP%E9%A1%B6%E4%BC%9A/">NLP顶会</a></div>
<div class="flex-row" id="post-meta"><span class="text created">发布于：<time datetime="2023-11-02T04:21:08.000Z">2023-11-02</time></span><span class="sep updated"></span><span class="text updated">更新于：<time datetime="2023-11-07T04:07:01.403Z">2023-11-07</time></span></div></div></div>
    
    <div class="bottom only-title">
      
      <div class="text-area">
        <h1 class="text title"><span>编辑大型语言模型：问题、方法和机遇</span></h1>
        
      </div>
    </div>
    
  </div>
  </div><article class="md-text content"><h1 id="编辑大型语言模型：问题、方法和机遇"><a href="#编辑大型语言模型：问题、方法和机遇" class="headerlink" title="编辑大型语言模型：问题、方法和机遇"></a>编辑大型语言模型：问题、方法和机遇</h1><h2 id="Abstruct"><a href="#Abstruct" class="headerlink" title="Abstruct"></a>Abstruct</h2><p>尽管有能力培养有能力的LLMs，但维持其相关性和纠正错误的方法仍然难以捉摸。为此，过去几年见证了LLMs编辑技术的激增，其<span style="background-color: #2ea8e580">目标是有效地改变特定领域内LLMs的行为，而不会对其他输入的性能产生负面影响</span>。本文深入探讨了LLMs模型编辑相关的问题、方法和机遇。特别是，我们<span style="background-color: #ff666680">对任务定义和与模型编辑相关的挑战进行了详尽的概述，并对我们目前掌握的最先进的方法进行了深入的实证分析</span>。我们还<span style="background-color: #ff666680">构建了一个新的基准数据集，以促进更稳健的评估并查明现有技术固有的持久问题</span>。我们的目标是为每种编辑技术的有效性和可行性提供有价值的见解，从而帮助社区做出明智的决定，为特定任务或上下文选择最合适的方法。</p>
<h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h1><p>大型语言模型（LLM）已经表现出理解和生成类人文本的非凡能力（Brown et al., 2020；OpenAI, 2023；Anil et al., 2023；Touvron et al., 2023；Qiao et al., 2022；赵等人，2023）。尽管LLMs的训练非常熟练，但确保其相关性和修复错误的策略仍不清楚。理想情况下，随着世界形势的发展，我们的目标是更新LLMs，避免与训练全新模型相关的计算负担。如图1所示，解决这个问题模型编辑的概念被提出</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="../imgs/$%7Bfiilename%7D/SWBFWKDL.png" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;SWBFWKDL&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F9227ERUC%22%2C%22annotationKey%22%3A%226BF2NSVY%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B300.5%2C490.39%2C533%2C628.89%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FCU5SMQAC%22%5D%2C%22locator%22%3A%221%22%7D%7D&quot; width=&quot;388&quot; height=&quot;231&quot; src=&quot;attachments/SWBFWKDL.png&quot; ztype=&quot;zimage&quot;&gt;"></p>
<p>（Sinitsin 等人，2020；De Cao 等人，2021），<span style="background-color: #2ea8e580">能够对模型的行为进行数据有效的改变，特别是在指定的感兴趣领域内，同时确保不会对其他输入产生不利影响。</span>目前，大量关于LLMs模型编辑的工作（De Cao et al., 2021；Meng et al., 2022, 2023；Sinitsin et al., 2020；Huang et al., 2023)在各种编辑任务和设置方面取得了长足的进步。如图 2 所示，<span style="background-color: #2ea8e580">这些工作通过将辅助网络与原始未更改的模型集成或更改导致不良输出的模型参数来操纵特定情况下的模型输出。</span>尽管文献中存在广泛的模型编辑技术，但<span style="background-color: #5fb23680">明显缺乏在统一实验条件下评估这些方法的全面比较分析。缺乏直接比较会削弱我们辨别每种方法相对优缺点的能力，从而阻碍我们理解它们在不同问题领域的适应性。</span></p>
<pre><code> 为了解决这个问题，本研究致力于建立一个标准的问题定义，并对这些方法进行细致的评估（§2，§3）。我们在规定的条件下进行实验，促进对各自的优缺点进行公正的比较（§4）。&lt;span style=&quot;background-color: #2ea8e580&quot;&gt;我们最初使用两个流行的模型编辑数据集，ZsRE (Levy et al., 2017) 和 COUNTERFACT (Meng et al., 2022)，以及两个结构上的数据集不同的语言模型，T5（Raffel et al.，2020a）（编码器-解码器）和 GPT-J（Wang 和 Komatsuzaki，2021a）（仅解码器）作为我们的基础模型&lt;/span&gt;。我们还评估了较大模型 OPT-13B（Zhang 等人，2022a）和 GPT-NEOX20B（Black 等人，2022）的性能。除了基本编辑设置之外，我们还评估批量和顺序编辑的性能。虽然我们观察到当前的方法在事实模型编辑任务中表现出当大的能力，但&lt;span style=&quot;background-color: #2ea8e580&quot;&gt;我们重新考虑当前的评估并创建一个更具包容性的评估数据集（§5）：可移植性（强大的泛化能力）、局部性（副作用）和效率（时间）和内存使用情况）&lt;/span&gt;。我们发现当前的模型编辑方法在这些层面上有所限制，从而限制了它们的实际应用，未来值得更多的研究。通过系统评估，我们的目标是为每种模型编辑技术的有效性提供有价值的见解，帮助研究人员为特定任务选择合适的方法。
</code></pre><h2 id="2-Problem-Definition"><a href="#2-Problem-Definition" class="headerlink" title="2 Problem Definition"></a>2 Problem Definition</h2><p>模型编辑，由 Mitchell 等人阐明。 （2022b），<span style="background-color: #2ea8e580">旨在有效地调整特定编辑描述符（xe，ye）上的初始基础模型（fθ，θ表示模型的参数）行为，而不影响其他样本上的模型行为</span>。最终目标是创建一个编辑模型，表示为 fθe。具体来说，基本模型 fθ 由函数 f : X → Y 表示，该函数将输入 x 与其相应的预测 y 相关联。给定一个由编辑输入 xe 和编辑标签 ye 组成的编辑描述符，使得 fθ(xe) ̸= ye，后期编辑模型 fθe 被设计为产生预期输出，其中 fθe(xe) = ye。</p>
<pre><code> &lt;span style=&quot;background-color: #2ea8e580&quot;&gt;模型编辑过程通常会影响与编辑示例密切相关的大量输入的预测。这个输入集合称为编辑范围。&lt;/span&gt;成功的编辑应该调整编辑范围内示例的模型行为，同时保持范围外示例的性能不变：
</code></pre><p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="../imgs/$%7Bfiilename%7D/YCQJYKA2.png" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;YCQJYKA2&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F9227ERUC%22%2C%22annotationKey%22%3A%22WCMI8DSD%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%222%22%2C%22position%22%3A%7B%22pageIndex%22%3A1%2C%22rects%22%3A%5B%5B70.5%2C136.39%2C291.5%2C183.39%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FCU5SMQAC%22%5D%2C%22locator%22%3A%222%22%7D%7D&quot; width=&quot;368&quot; height=&quot;78&quot; src=&quot;attachments/YCQJYKA2.png&quot; ztype=&quot;zimage&quot;&gt;"></p>
<p>范围内 I(xe, ye) 通常包含 xe 及其等价邻域 N (xe, ye)，其中包括相关的输入/输出对。相反，超出范围的 O(xe, ye) 由与编辑示例无关的输入组成。模型fe应该满足以下三个属性：可靠性、泛化性和局部性。</p>
<p><strong>可靠性</strong> 先前的工作（Huang et al., 2023；De Cao et al., 2021；Meng et al., 2022）定义了当后期编辑模型 fθe 给出案例 (xe, ye) 的目标答案时的可靠编辑被编辑。可靠性以编辑案例的平均准确度来衡量：</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="../imgs/$%7Bfiilename%7D/Q3XB8E8H.png" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;Q3XB8E8H&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F9227ERUC%22%2C%22annotationKey%22%3A%22WHB9Z2XR%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%222%22%2C%22position%22%3A%7B%22pageIndex%22%3A1%2C%22rects%22%3A%5B%5B302.5%2C616.89%2C530%2C650.39%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FCU5SMQAC%22%5D%2C%22locator%22%3A%222%22%7D%7D&quot; width=&quot;379&quot; height=&quot;56&quot; src=&quot;attachments/Q3XB8E8H.png&quot; ztype=&quot;zimage&quot;&gt;"></p>
<p><strong>泛化</strong> 编辑后模型 fθe 还应该编辑等效邻居 N (xe, ye)（例如改写的句子)。它是通过模型 fθe 在从等价邻域中均匀抽取的示例上的平均精度来评估的：</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="../imgs/$%7Bfiilename%7D/TSPLLYFE.png" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;TSPLLYFE&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F9227ERUC%22%2C%22annotationKey%22%3A%22ICM3VKEP%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%222%22%2C%22position%22%3A%7B%22pageIndex%22%3A1%2C%22rects%22%3A%5B%5B305%2C503.39%2C527%2C538.89%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FCU5SMQAC%22%5D%2C%22locator%22%3A%222%22%7D%7D&quot; width=&quot;370&quot; height=&quot;59&quot; src=&quot;attachments/TSPLLYFE.png&quot; ztype=&quot;zimage&quot;&gt;"></p>
<p><strong>局部性 </strong>在一些工作中，也被称为特异性。编辑应该在本地实现，这意味着编辑后模型 fθe 不应更改范围外 O(xe, ye) 中不相关示例的输出。因此，局部性是通过编辑后模型 fθe 的预测与编辑前 fθ 模型相同的来评估的</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="../imgs/$%7Bfiilename%7D/88F6ZZTR.png" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;88F6ZZTR&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F9227ERUC%22%2C%22annotationKey%22%3A%22KH34VUGC%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%222%22%2C%22position%22%3A%7B%22pageIndex%22%3A1%2C%22rects%22%3A%5B%5B306.5%2C364.39%2C527%2C401.39%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FCU5SMQAC%22%5D%2C%22locator%22%3A%222%22%7D%7D&quot; width=&quot;368&quot; height=&quot;62&quot; src=&quot;attachments/88F6ZZTR.png&quot; ztype=&quot;zimage&quot;&gt;"></p>
<h3 id="3-Current-Methods"><a href="#3-Current-Methods" class="headerlink" title="3 Current Methods"></a>3 Current Methods</h3><p>目前LLMs的模型编辑方法可以分为两种主要范式，如图2所示：<span style="background-color: #2ea8e580">修改模型参数或保留模型参数。</span>更多比较见表 6。</p>
<h3 id="3-1-Methods-for-Preserving-LLMs-Parameters"><a href="#3-1-Methods-for-Preserving-LLMs-Parameters" class="headerlink" title="3.1 Methods for Preserving LLMs Parameters"></a>3.1 Methods for Preserving LLMs Parameters</h3><p><strong>基于内存的模型 </strong><span style="background-color: #2ea8e580">这种方法将所有编辑示例显式存储在内存中，并使用检索器为每个新输入提取最相关的编辑事实，以指导模型生成编辑事实。 </span>SERAC（Mitchell 等人，2022b）提出了一种采用独特的反事实模型，同时保持原始模型不变的方法。具体来说，<span style="background-color: #2ea8e580">它采用范围分类器来计算新输入落入存储的编辑示例范围内的可能性。如果输入与内存中任何缓存的编辑相匹配，则反事实模型的预测将基于输入和最可能的编辑。否则，如果输入超出了所有编辑的范围，给出了原始模型的预测。</span>此外，<span style="background-color: #5fb23680">最近的研究表明LLMs拥有强大的情境学习能力。模型本身可以生成与所提供的知识相对应的输出，而不是求助于用新事实训练的额外模型，并给出精炼的知识上下文作为提示。</span><span style="background-color: #2ea8e580">这种方法通过用编辑后的事实提示模型并从编辑记忆中检索编辑演示来编辑语言模型</span>，包括以下工作：MemPrompt (Madaan et al., 2022)、IKE (Zheng et al., 2023) 和MeLLo（Zhong 等人，2023）。</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="../imgs/$%7Bfiilename%7D/Y5M6Y7UX.png" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;Y5M6Y7UX&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F9227ERUC%22%2C%22annotationKey%22%3A%226XZYF4BM%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%223%22%2C%22position%22%3A%7B%22pageIndex%22%3A2%2C%22rects%22%3A%5B%5B79%2C517.39%2C515%2C782.89%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FCU5SMQAC%22%5D%2C%22locator%22%3A%223%22%7D%7D&quot; width=&quot;727&quot; height=&quot;443&quot; src=&quot;attachments/Y5M6Y7UX.png&quot; ztype=&quot;zimage&quot;&gt;"></p>
<p><strong>附加参数 </strong><span style="background-color: #2ea8e580">此范例在语言模型中引入了额外的可训练参数。这些参数在修改后的知识数据集上进行训练，而原始模型参数保持静态。</span> T-Patcher（Huang et al., 2023）在模型前馈网络（FFN）的最后一层针对一个错误集成了一个神经元（补丁），仅在遇到其对应错误时才生效。 CaliNET（Dong et al., 2022）整合了多个神经元以用于多个编辑案例。不同的是，GRACE（Hartvigsen et al., 2022）维护一个离散的密码本作为适配器，随着时间的推移添加和更新元素以编辑模型的预测。</p>
<h3 id="3-2-Methods-for-Modifying-LLMs-Paramete"><a href="#3-2-Methods-for-Modifying-LLMs-Paramete" class="headerlink" title="3.2 Methods for Modifying LLMs Paramete"></a>3.2 Methods for Modifying LLMs Paramete</h3><p>该范例将更新部分参数 θ，它应用更新 Δ 矩阵来编辑模型。</p>
<p><strong>定位然后编辑 </strong><span style="background-color: #2ea8e580">该范例首先识别与特定知识相对应的参数，并通过直接更新目标参数来修改它们。</span>知识神经元（KN）方法（Dai et al., 2022）<span style="background-color: #2ea8e580">引入了知识归因技术来精确定位体现知识的“知识神经元”（FFN 矩阵中的键值对），然后更新这些神经元。 </span>ROME（Meng et al., 2022）<span style="background-color: #2ea8e580">应用因果中介分析来定位编辑区域。 ROME 不是修改 FFN 中的知识神经元，而是改变整个矩阵。 ROME 将模型编辑视为具有线性等式约束的最小二乘法，并使用拉格朗日乘子来求解。</span>然而，<span style="background-color: #2ea8e580">KN 和 ROME 一次只能编辑一个事实关联。</span>为此，<span style="background-color: #2ea8e580">MEMIT（Meng et al., 2023）对ROME的设置进行了扩展，实现了多病例同步编辑的情况。</span>基于 MEMIT，PMET（Li et al., 2023a）涉及注意力值以获得更好的性能。</p>
<p><strong>元学习</strong> <span style="background-color: #2ea8e580">元学习方法采用超网络来学习编辑 LLM 所需的 Δ</span>。<span style="background-color: #2ea8e580">知识编辑器（KE）（De Cao et al., 2021）利用超网络（特别是双向 LSTM）来预测每个数据点的权重更新，从而能够在不干扰其他知识的情况下对编辑目标知识进行约束优化</span>。然而，这种方法在编辑LLMs方面存在不足。为了克服这个限制，<span style="background-color: #2ea8e580">模型编辑器网络梯度分解（MEND）（Mitchell et al., 2022a）学习通过采用梯度的低秩分解来变换微调语言模型的梯度，这可以应用于具有更好性能的LLM。</span></p>
<h2 id="4-Preliminary-Experiments"><a href="#4-Preliminary-Experiments" class="headerlink" title="4 Preliminary Experiments"></a>4 Preliminary Experiments</h2><p>考虑到大量以事实知识为中心的研究和数据集，我们将其用作主要比较基础。我们最初的对照实验使用两个著名的事实知识数据集（表 1）进行，促进了方法的直接比较，突出了它们独特的优势和局限性（Wang 等人，2023b）。</p>
<h3 id="4-1-Experiment-Setting"><a href="#4-1-Experiment-Setting" class="headerlink" title="4.1 Experiment Setting"></a>4.1 Experiment Setting</h3><p>我们使用两个著名的模型编辑数据集：ZsRE 和 COUNTERFACT，其详细信息请参见附录 B。以前的研究通常使用较小的语言模型 (&lt;1B)，并证明了当前编辑方法在 BERT 等较小模型上的有效性（Devlin 等人， 2019）。然而，这些方法是否适用于更大的模型仍有待探索。因此，考虑到编辑任务和未来的发展，我们专注于基于生成的模型并选择更大的模型：T5-XL（3B）和GPT-J（6B），代表编码器-解码器和仅解码器结构。</p>
<pre><code> 我们从每种方法类型中选择了有影响力的作品。除了现有的模型编辑技术之外，我们还检查了微调的结果，这是模型更新的基本方法。为了避免重新训练所有层的计算成本，我们采用了Meng等人提出的方法。 (2022)，由 ROME 识别的微调层，我们将其表示为 FT-L。该策略确保与其他直接编辑进行公平比较方法，增强我们分析的有效性。更多详细信息请参见附录 A。
</code></pre><h3 id="4-2-Experiment-Results"><a href="#4-2-Experiment-Results" class="headerlink" title="4.2 Experiment Results"></a>4.2 Experiment Results</h3><p>基本模型表 1 <span style="background-color: #ff666680">揭示了 SERAC 和 ROME 在 ZsRE 和 COUNTERFACT 数据集上的卓越性能，SERAC 在多个指标上超过 90%。虽然 MEMIT 缺乏通用性，但它在可靠性和局部性方面表现出色。 KE、CaliNET 和 KN 表现不佳，在较小的模型中表现尚可，但在较大的模型中表现平平。 MEND 在这两个数据集上表现良好，在 T5 上的结果达到了 80% 以上，尽管不如 ROME 和 SERAC 那样令人印象深刻。 T-Patcher 模型的性能因模型架构和大小的不同而有所不同。例如，它在 ZsRE 数据集的 T5-XL 上表现不佳，而在 GPT-J 上表现完美。在 COUNTERFACT 数据集的情况下，T-Patcher 在 T5 上实现了令人满意的可靠性和局部性，但缺乏泛化性。相反，在 GPT-J 上，该模型在可靠性和泛化性方面表现出色，但在局部性方面表现不佳。</span><span style="background-color: #5fb23680">这种不稳定性可归因于模型架构，因为 T-Patcher 在 T5 的最终解码器层添加了一个神经元；</span><span style="background-color: #ff666680">然而，编码器可能仍然保留原始知识。 FT-L 在 PLM 上的表现不如 ROME，即使修改相同的位置。它在 ZsRE 数据集上显示出令人印象深刻的性能，但在 GPT-J 上的 COUNTERFACT 数据集上与 ROME 的可靠性和泛化能力相当。然而，其较低的局部性得分表明对不相关知识领域的潜在影响。 IKE 表现出良好的可靠性，但在局部性方面遇到困难，因为预先设置的提示可能会影响不相关的输入。它的泛化能力也可以提高。情境学习</span></p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="../imgs/$%7Bfiilename%7D/B7WY2DBH.png" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;B7WY2DBH&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F9227ERUC%22%2C%22annotationKey%22%3A%22AYAJST64%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%225%22%2C%22position%22%3A%7B%22pageIndex%22%3A4%2C%22rects%22%3A%5B%5B67%2C654.39%2C531.5%2C770.39%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FCU5SMQAC%22%5D%2C%22locator%22%3A%225%22%7D%7D&quot; width=&quot;774&quot; height=&quot;193&quot; src=&quot;attachments/B7WY2DBH.png&quot; ztype=&quot;zimage&quot;&gt;"></p>
<p>该方法可能会遇到上下文调解失败的问题（Hernandez et al., 2023)，因为预先训练的语言模型可能无法始终生成与提示对齐的文本。</p>
<p><strong>模型缩放</strong> 由于计算限制，我们使用更大的模型进行实验，在 OPT-13B 和 GPT-NEOX-20B 上测试 IKE、ROME 和 MEMIT。结果（表 2）令人惊讶地<span style="background-color: #ff666680">显示 ROME 和 MEMIT 在 GPT-NEOX-20B 模型上表现良好，但在 OPT-13B 上表现不佳。这是由于这两种方法都依赖于矩阵求逆运算。然而，在 OPT-13B 模型中，矩阵是不可逆的。</span>我们甚至根据经验发现，<span style="background-color: #5fb23680">用最小二乘法逼近解会产生不令人满意的结果。我们认为这是 ROME 和 MEMIT 的局限性，因为它们不能应用于不同的模型。</span> <span style="background-color: #ff666680">MEMIT 由于依赖多层矩阵计算而表现较差，并且对于较大模型，其可靠性和泛化性比 ROME 下降得更多。 IKE 的性能受到模型本身的上下文学习能力的影响。 OPT的结果比GPT-J的结果还要差，这可能归因于OPT本身的上下文学习能力。</span><span style="background-color: #5fb23680">此外，随着模型大小的增加，其泛化和局部性的性能都会下降。</span></p>
<p><strong>批量编辑</strong> 鉴于许多研究通常将更新限制为几十个事实或仅关注单个编辑案例，我们进行了进一步的批量编辑分析。然而，通常需要同时修改具有多个知识片段的模型。我们重点关注支持批量编辑的方法（FT、SERAC、MEND 和 MEMIT），并在图 3 中展示了它们的性能。值得注意的是，<span style="background-color: #ff666680">MEMIT 支持LLMs的大规模知识编辑，允许以最少的时间和内存进行数百甚至数千个同时编辑成本。其在可靠性和泛化方面的性能在最多 1000 次编辑时仍然保持稳健，但局部性在此级别下降。而 FT-L、SERAC、和MEND还支持批量编辑，它们需要大量内存来处理更多情况，超出了我们当前的能力。因此，我们将测试限制为 100 次编辑。 SERAC 可以完美地进行最多 100 次编辑的批量编辑。 MEND 和 FT-L 在批量编辑中的性能并不那么强，随着编辑数量的增加，模型的性能迅速下降。</span></p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="../imgs/$%7Bfiilename%7D/WVMGDVMU.png" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;WVMGDVMU&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F9227ERUC%22%2C%22annotationKey%22%3A%22UTUV86Q8%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%225%22%2C%22position%22%3A%7B%22pageIndex%22%3A4%2C%22rects%22%3A%5B%5B303%2C516.89%2C528%2C639.39%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FCU5SMQAC%22%5D%2C%22locator%22%3A%225%22%7D%7D&quot; width=&quot;375&quot; height=&quot;204&quot; src=&quot;attachments/WVMGDVMU.png&quot; ztype=&quot;zimage&quot;&gt;"></p>
<p><strong>顺序编辑</strong> 请注意，默认评估过程是更新单个模型知识，评估新模型，然后回滚更新，然后对每个测试点重复该过程。在实际场景中，模型在进行新的编辑时应保留先前的更改。因此，进行连续编辑的能力是模型编辑的一个重要特征（Huang et al., 2023）。我们评估了具有强大的单编辑性能的顺序编辑方法，并在图 4 中报告了结果。<span style="background-color: #ff666680">冻结模型参数的方法（如 SERAC 和 T-Patcher)通常在顺序编辑中表现出稳定的性能。然而，那些改变模型参数的人却很困难</span>。 <span style="background-color: #ff666680">ROME 在 n = 10 之前表现良好，然后在 n = 100 时下降。MEMIT 的性能也会在超过 100 次编辑后下降，但不如 ROME 大幅下降。同样，MEND 在 n = 1 时表现良好，但在 n = 10 时表现明显下降。随着编辑过程的继续，这些模型越来越偏离其原始状态，导致性能次优。</span></p>
<h2 id="5-Comprehensive-Study"><a href="#5-Comprehensive-Study" class="headerlink" title="5 Comprehensive Study"></a>5 Comprehensive Study</h2><p>考虑到上述几点，我们认为以前的评估指标可能无法充分评估模型编辑能力。因此，我们提出对可移植性、局部性和效率进行更全面的评估。</p>
<h3 id="5-1-Portability-Robust-Generalization"><a href="#5-1-Portability-Robust-Generalization" class="headerlink" title="5.1 Portability - Robust Generalization"></a>5.1 Portability - Robust Generalization</h3><p>几项研究使用通过反向翻译生成的样本来评估泛化性（De Cao 等人，2021）。然而，这些释义的句子通常只涉及微小的措辞变化，并不能反映实质性的事实修改。正如 Jacques Thibodeau (2022) 中所述，验证这些方法是否能够处理编辑对实际应用程序的影响至关重要。因此，我们引入了一种称为可移植性的新评估指标，以衡量模型编辑在将知识转移到相关内容方面的有效性，称为鲁棒泛化。因此我们考虑三个方面：（1）<strong>主语替换</strong>：由于大多数改写的句子保留了主语描述，但更多地改写了关系，我们通过替换来测试泛化能力问题中的主题带有别名或同义词。这测试模型是否可以将编辑的属性推广到同一主题的其他描述。 (2)<strong>反向关系</strong>：当编辑主体和关系的目标时，目标实体的属性也发生变化。我们通过过滤合适的关系（例如一对一）并询问相反的问题来检查目标实体是否也更新来测试模型处理此问题的能力。 （3）<strong>一跳</strong>：修改后的知识应该可以被编辑后的语言模型用于下游任务。例如，如果我们更改“瓦茨·汉弗莱 (Watts Humphrey) 就读哪所大学？”这个问题的答案。从“三一学院”到“密歇根大学”，当被问到“Watts Humphrey 在大学学习期间住在哪个城市？”时，模型应该回答“密歇根州的安娜堡”而不是“爱尔兰的都柏林”。因此，我们构建了一个推理数据集来评估编辑后模型使用编辑知识的能力。</p>
<pre><code> 我们将一个新部分 P (xe, ye) 合并到现有数据集 ZsRE 中，可移植性计算为应用于 P (xe, ye) 中的推理示例时编辑模型 (fθe) 的平均准确度：
</code></pre><p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="../imgs/$%7Bfiilename%7D/AKCEUPGK.png" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;AKCEUPGK&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F9227ERUC%22%2C%22annotationKey%22%3A%22J5ARE9LF%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%226%22%2C%22position%22%3A%7B%22pageIndex%22%3A5%2C%22rects%22%3A%5B%5B306.5%2C154.39%2C526.5%2C190.39%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FCU5SMQAC%22%5D%2C%22locator%22%3A%226%22%7D%7D&quot; width=&quot;367&quot; height=&quot;60&quot; src=&quot;attachments/AKCEUPGK.png&quot; ztype=&quot;zimage&quot;&gt;"></p>
<p><strong>数据集构建 </strong>对于一跳数据集<span style="background-color: #ff666680">，在原始编辑中，我们将主题 s 的答案从 o 更改为 o<em>。然后，我们提示模型生成链接的三元组 (o</em>, r<em>, o′</em>)。随后，GPT-4 根据这个三元组和 s 创建一个问题和答案。尤其，如果模型可以回答这个新问题，意味着它具有三元组 (o<em>, r</em>, o′<em>) 的预先存在的知识。我们通过要求模型从 o</em> 和 r<em> 预测 o’</em> 来过滤未知的三元组。如果成功，则推断该模型具有先验知识。最后，人类评估者验证三元组的准确性和问题的流畅性</span>。其他详细信息，例如我们使用的演示和数据集构建的其他部分，可以在附录 B 中找到。</p>
<p><strong>结果 </strong>我们根据新提出的评估指标和数据集进行实验，结果如表3所示。如表所示，<span style="background-color: #ff666680">当前模型编辑方法在可移植性方面的性能有些欠佳。尽管 SERAC 在之前的指标上显示出无可挑剔的结果，但在所有三个可移植性方面的准确度均低于 20%。 SERAC的瓶颈在于分类器的准确性和附加模型的能力。对于主题替换场景，包括SERAC、MEND、ROME和MEMIT，只能适应特定的主题实体表达，而不能泛化到主题实体的概念。然而，FT-L、IKE 和 T-patcher 在面对替换主题时表现出了出色的性能。</span>关于反向关系，我们的结果表明，<span style="background-color: #ff666680">当前的编辑方法主要编辑单向关系，IKE 是一个明显的例外，在 GPT-J 和 GPT-NEOX-20B 上都达到了 90% 以上。其他方法改变主体实体的属性，同时保持客体实体不受影响</span>。在一跳推理环境中，<span style="background-color: #ff666680">大多数编辑方法都难以将改变的知识转移到相关事实。</span>出乎意料的是，<span style="background-color: #5fb23680">ROME、MEMIT和IKE在可移植性方面表现出相对值得称赞的表现（超过50%）。他们不仅能够编辑原始案件，而且能够在某些方面修改与案件相关的事实</span>。综上所述，在我们的评估中，IKE 在三个场景中都表现出了相对较好的性能。然而，很明显，当前的模型编辑技术在管理编辑的后果方面继续面临挑战，即确保知识的变化在相关上下文中连贯一致地反映。事实上，这一领域需要在未来的研究中进一步调查和创新。</p>
<h3 id="5-2-Locality-Side-Effect-of-Model-Editing"><a href="#5-2-Locality-Side-Effect-of-Model-Editing" class="headerlink" title="5.2 Locality - Side Effect of Model Editing"></a>5.2 Locality - Side Effect of Model Editing</h3><p>在上一节中，COUNTERFACT 和 ZsRE 从以下方面评估模型编辑的局部性：COUNTERFACT 使用与目标知识相同分布的三元组，而 ZsRE 使用来自不同自然问题数据集的问题。值得注意的是，一些方法（例如 T-Patcher）在这两个数据集上表现出不同的性能。这凸显出模型编辑对语言模型的影响是多方面的，需要进行彻底、全面的评估才能充分理解其效果。为了彻底检查模型编辑的潜在副作用，我们提出了三个不同层面的评估：（1）其他关系：尽管Meng等人。 (2022)引入了本质的概念，但他们没有明确评价它。我们认为，已更新的主题的其他属性在编辑后应保持不变。 (2)分散邻里的注意力：HoelscherObermaier等人。 （2023a）发现，如果我们将编辑后的案例连接在其他不相关的输入之前，模型往往会受到编辑后的事实的影响，并继续产生与编辑后的案例一致的结果。 (3) 其他任务：基于 Skill Neuron 的断言（Wang 等人，2022），即大语言模型（LLM）中的前馈网络拥有特定于任务的知识能力，我们引入了一个新的挑战来评估模型编辑是否可能对性能产生负面影响关于其他任务。数据集构建的详细信息请参见附录 B.3。</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="../imgs/$%7Bfiilename%7D/ND8H464M.png" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;ND8H464M&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F9227ERUC%22%2C%22annotationKey%22%3A%22DX678K73%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%227%22%2C%22position%22%3A%7B%22pageIndex%22%3A6%2C%22rects%22%3A%5B%5B297.5%2C600.89%2C529%2C776.89%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FCU5SMQAC%22%5D%2C%22locator%22%3A%227%22%7D%7D&quot; width=&quot;386&quot; height=&quot;293&quot; src=&quot;attachments/ND8H464M.png&quot; ztype=&quot;zimage&quot;&gt;"></p>
<p><strong>结果</strong> 表 4 列出了我们的结果。值得注意的是，当前的编辑方法在其他属性方面表现出色，表明它们仅修改目标特征而不影响其他属性。<span style="background-color: #5fb23680">然而，它们在 Distract-Neighbor 设置中通常表现不佳，</span>如与表 1 中的结果相比性能下降所反映的那样。IKE 是一个例外，它的性能保持相对稳定，因为它继承了以下事实：</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="../imgs/$%7Bfiilename%7D/EQ2WM2DI.png" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;EQ2WM2DI&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F9227ERUC%22%2C%22annotationKey%22%3A%22S55AHZG9%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%228%22%2C%22position%22%3A%7B%22pageIndex%22%3A7%2C%22rects%22%3A%5B%5B62.727%2C578.708%2C296.591%2C783.254%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FCU5SMQAC%22%5D%2C%22locator%22%3A%228%22%7D%7D&quot; width=&quot;390&quot; height=&quot;341&quot; src=&quot;attachments/EQ2WM2DI.png&quot; ztype=&quot;zimage&quot;&gt;"></p>
<p>完全需要在输入之前连接编辑后的事实。对于常识推理任务，参数保留方法在很大程度上保持了其在其他任务上的性能。相反，改变参数的方法往往会对性能产生负面影响，MEMIT 除外。尽管参数发生了变化，MEMIT 在常识性任务中仍然保持着强劲的性能，展示了其值得称赞的局部性。</p>
<h3 id="5-3-Efficiency"><a href="#5-3-Efficiency" class="headerlink" title="5.3 Efficiency"></a>5.3 Efficiency</h3><p>模型编辑应最大限度地减少进行编辑所需的时间和内存，而不影响模型的性能。</p>
<p>时间分析表5说明了不同模型编辑技术从提供编辑案例到获得发布后编辑模型所需的时间。我们观察到，一旦超网络经过训练，KE 和 MEND 就会以相当快的速度执行编辑过程。同样，SERAC 还可以快速编辑知识，在经过训练的分类器和反事实模型的情况下，在大约 5 秒内完成该过程。然而，这些方法需要数小时至数天的额外训练和额外的数据集。在我们的实验中，在 ZsRE 数据集上训练 MEND 需要超过 7 个小时，在 3× V100 上训练 SERAC 需要超过 36 个小时。另一方面，ROME 和 MEMIT 需要预先计算维基文本的协方差统计数据。然而，这种计算非常耗时，可能需要数小时至数天才能完成。相比之下，其他方法（例如 KN、CaliNET 和 T-Patcher）可能更快，因为它们不需要任何预计算或预训练。然而，KN 和 CaliNET 在较大模型上的性能</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="../imgs/$%7Bfiilename%7D/K9ABI2KM.png" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;K9ABI2KM&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F9227ERUC%22%2C%22annotationKey%22%3A%22GC2LNVEQ%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%228%22%2C%22position%22%3A%7B%22pageIndex%22%3A7%2C%22rects%22%3A%5B%5B302.045%2C605.981%2C532.5%2C781.89%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FCU5SMQAC%22%5D%2C%22locator%22%3A%228%22%7D%7D&quot; width=&quot;384&quot; height=&quot;293&quot; src=&quot;attachments/K9ABI2KM.png&quot; ztype=&quot;zimage&quot;&gt;"></p>
<p>不能令人满意，T-Patcher 是最慢的，因为需要针对每个相应的错误进行单独的神经元训练。考虑到时间方面，需要一种更加省时的模型编辑方法。</p>
<p><strong>内存分析</strong> 图 5 显示了每种模型编辑方法的内存 VRAM 使用情况。从该图中，我们观察到大多数方法消耗的内存量相似，但 MEND 除外，它需要超过 60GB 的内存用于训练。引入额外训练的方法（例如 MEND 和 SERAC）会导致额外的计算开销，从而显着增加内存消耗。</p>
<h2 id="6-Relationship-with-Relevant-Works"><a href="#6-Relationship-with-Relevant-Works" class="headerlink" title="6 Relationship with Relevant Works"></a>6 Relationship with Relevant Works</h2><h3 id="6-1Knowledge-in-LLMs"><a href="#6-1Knowledge-in-LLMs" class="headerlink" title="6.1Knowledge in LLMs"></a>6.1Knowledge in LLMs</h3><p>多种模型编辑方法旨在了解 PLM 中存储的知识如何精确且直接地改变模型参数。现有工作研究了 PLM 如何存储知识的原则（Geva 等人，2021、2022；Haviv 等人，2023；Hao 等人，2021；Hernandez 等人，2023；Yao 等人， 2023；Cao et al., 2023；Lamparth and Reuel, 2023；Cheng et al., 2023；Li et al., 2023b；Chen et al., 2023；Ju and Zhang, 2023），这些都有助于模型编辑过程。此外，一些模型编辑技术与知识增强相似（Zhang et al., 2019；Lewis et al., 2020；Zhang et al., 2022b；Yasunaga et al., 2021；Yao et al., 2022；Pan et al. ., 2023）方法，因为更新模型的知识也可以被视为将知识灌输到模型中。</p>
<h3 id="6-2Lifelong-Learning-and-Unlearning"><a href="#6-2Lifelong-Learning-and-Unlearning" class="headerlink" title="6.2Lifelong Learning and Unlearning"></a>6.2Lifelong Learning and Unlearning</h3><p>模型编辑包括终身学习和忘却，允许自适应地添加、修改和删除知识。持续学习（Biesialska et al., 2020）可以提高模型跨任务和领域的适应性，已在 PLM 中的模型编辑中显示出有效性（Zhu et al., 2020）。此外，模型忘记敏感知识并与机器遗忘概念保持一致至关重要（Hase 等人，2023；Wu 等人，2022；Tarun 等人，2021；Gandikota 等人，2023）。</p>
<h3 id="6-3Security-and-Privacy-for-LLMs"><a href="#6-3Security-and-Privacy-for-LLMs" class="headerlink" title="6.3Security and Privacy for LLMs"></a>6.3Security and Privacy for LLMs</h3><p>过去的研究（Carlini 等人，2020；Shen 等人，2023）表明，LLMs可以根据某些提示生成不可靠或个人的样本。删除大型语言模型 (LLM) 中存储的潜在有害信息和隐私信息的任务对于增强基于 LLM 的应用程序的隐私和安全性至关重要（Sun 等人，2023）。模型编辑可以抑制有害语言的生成（Geva et al., 2022；Hu et al., 2023），可以帮助解决这些问题。</p>
<h2 id="7-Conclusion"><a href="#7-Conclusion" class="headerlink" title="7 Conclusion"></a>7 Conclusion</h2><p>我们系统地分析了编辑大语言模型（LLM）的方法。我们的目标是通过检查现有编辑技术的特征、优势和局限性，帮助研究人员更好地理解现有编辑技术。我们的分析显示了很大的改进空间，特别是在可移植性、局部性和效率方面。改进的LLMs编辑可以帮助他们更好地适应用户不断变化的需求和价值观。我们希望我们的工作能够促进开放问题和进一步研究的进展。</p>

<div class="article-footer fs14">
    <section id="license">
      <div class="header"><span>许可协议</span></div>
      <div class="body"><p>本文采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">署名-非商业性使用-相同方式共享 4.0 国际</a> 许可协议，转载请注明出处。</p>
</div>
    </section>
    
    <section id="share">
      <div class="header"><span>分享文章</span></div>
      <div class="body">
        <div class="link"><input class="copy-area" readonly="true" id="copy-link" value="http://humble2967738843.github.io/2023/11/02/bian-ji-da-xing-yu-yan-mo-xing-wen-ti-fang-fa-he-ji-yu/" /></div>
        <div class="social-wrap dis-select"><a class="social share-item wechat" onclick="util.toggle(&quot;qrcode-wechat&quot)"><img class="lazy"  src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/social/b32ef3da1162a.svg" /></a><a class="social share-item weibo" target="_blank" rel="external nofollow noopener noreferrer" href="https://service.weibo.com/share/share.php?url=http://humble2967738843.github.io/2023/11/02/bian-ji-da-xing-yu-yan-mo-xing-wen-ti-fang-fa-he-ji-yu/&title=编辑大型语言模型：问题、方法和机遇 - humbleyl&summary=编辑大型语言模型：问题、方法和机遇Abstruct尽管有能力培养有能力的LLMs，但维持其相关性和纠正错误的方法仍然难以捉摸。为此，过去几年见证了LLMs编辑技术的激增，其目标是有效地改变特定领域内LLMs的行为，而不会对其他输入的性..."><img class="lazy"  src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/social/80c07e4dbb303.svg" /></a><a class="social share-item email" href="mailto:?subject=编辑大型语言模型：问题、方法和机遇 - humbleyl&amp;body=http://humble2967738843.github.io/2023/11/02/bian-ji-da-xing-yu-yan-mo-xing-wen-ti-fang-fa-he-ji-yu/"><img class="lazy"  src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/social/a1b00e20f425d.svg" /></a><a class="social share-item link" onclick="util.copy(&quot;copy-link&quot;, &quot;复制成功&quot;)"><img class="lazy"  src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/social/8411ed322ced6.svg" /></a></div>
        
        <div class="qrcode" id="qrcode-wechat" style="opacity:0;height:0">
          <img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://api.qrserver.com/v1/create-qr-code/?size=256x256&data=http://humble2967738843.github.io/2023/11/02/bian-ji-da-xing-yu-yan-mo-xing-wen-ti-fang-fa-he-ji-yu/"/>
        </div>
        
      </div>
    </section>
    </div>
</article>
<div class="related-wrap" id="read-next"><section class="body"><div class="item" id="prev"><div class="note">较新文章</div><a href="/2023/11/02/suan-fa-bi-ji-v2.0/">算法笔记V2.0</a></div><div class="item" id="next"></div></section></div>

<div class="related-wrap" id="related-posts">
    <section class='header'>
      <div class='title cap theme'>您可能感兴趣的文章</div>
    </section>
    <section class='body'>
    <div class="related-posts"><a class="item" href="\2023\11\06\wang-diao-ni-xiang-wang-diao-de-dong-xi-llms-de-gao-xiao-wang-que\" title="忘掉你想忘掉的东西：LLMs的高效忘却"><span class="title">忘掉你想忘掉的东西：LLMs的高效忘却</span></a><a class="item" href="\2023\11\02\duo-yu-yan-mo-xing-zhong-shi-shi-zhi-shi-de-kua-yu-yan-yi-zhi-xing\" title="多语言模型中事实知识的跨语言一致性"><span class="title">多语言模型中事实知识的跨语言一致性</span></a><a class="item" href="\2023\11\02\qing-jing-xue-xi-chuang-jian-ren-wu-xiang-liang\" title="情境学习创建任务向量"><span class="title">情境学习创建任务向量</span></a><a class="item" href="\2023\11\02\wo-men-ke-yi-bian-ji-duo-mo-tai-da-xing-yu-yan-mo-xing-ma\" title="我们可以编辑多模态大型语言模型吗？"><span class="title">我们可以编辑多模态大型语言模型吗？</span></a><a class="item" href="\2023\11\06\ji-yu-ti-shi-de-ling-yang-ben-guan-xi-chou-qu-fang-fa-tan-suo\" title="基于提示的零样本关系抽取方法探索"><span class="title">基于提示的零样本关系抽取方法探索</span></a></div></section></div>


  <div class="related-wrap md-text" id="comments">
    <section class='header cmt-title cap theme'>
      <p>快来参与讨论吧~</p>

    </section>
    <section class='body cmt-body giscus'>
      

<svg class="loading" style="vertical-align:middle;fill:currentColor;overflow:hidden;" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2709"><path d="M832 512c0-176-144-320-320-320V128c211.2 0 384 172.8 384 384h-64zM192 512c0 176 144 320 320 320v64C300.8 896 128 723.2 128 512h64z" p-id="2710"></path></svg>

<div id="giscus" src="https://giscus.app/client.js" data-repo="Humble2967738843/giscus" data-repo-id="R_kgDOLsS5kA" data-category="Announcements" data-category-id="DIC_kwDOLsS5kM4Cel5C" data-mapping="url" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="preferred_color_scheme" data-lang="zh-CN" data-loading="lazy" crossorigin="anonymous"></div>

    </section>
  </div>



<footer class="page-footer footnote"><hr><div class="text"><center>
</br>
</br>
<script type="text/javascript">
function show_runtime() {
    window.setTimeout("show_runtime()", 1000);
    X = new Date("10/20/2023 00:00:00");
    Y = new Date();
    T = (Y.getTime() - X.getTime());
    M = 24 * 60 * 60 * 1000;
    a = T / M;
    A = Math.floor(a);
    b = (a - A) * 24;
    B = Math.floor(b);
    c = (b - B) * 60;
    C = Math.floor((b - B) * 60);
    D = Math.floor((c - C) * 60);
    runtime_span.innerHTML = "⏲️本站已运行 " + A + "天|" + B + "小时|" + C + "分|" + D + "秒⏲️"
}
show_runtime();
</script>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<span id="busuanzi_container_site_pv">🤩本站总访问量<span id="busuanzi_value_site_pv"></span>次</span><br>
<span id="runtime_span"></span>
</center>
</div></footer>
<div class="main-mask" onclick="sidebar.dismiss()"></div></div><aside class="l_right">
<div class="widgets">



<widget class="widget-wrapper toc" id="data-toc" collapse="false"><div class="widget-header dis-select"><span class="name">本文目录</span><a class="cap-action" onclick="sidebar.toggleTOC()" ><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 6h11m-11 6h11m-11 6h11M4 6h1v4m-1 0h2m0 8H4c0-1 2-2 2-3s-1-1.5-2-1"/></svg></a></div><div class="widget-body"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%BC%96%E8%BE%91%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%9A%E9%97%AE%E9%A2%98%E3%80%81%E6%96%B9%E6%B3%95%E5%92%8C%E6%9C%BA%E9%81%87"><span class="toc-text">编辑大型语言模型：问题、方法和机遇</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Abstruct"><span class="toc-text">Abstruct</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#1-Introduction"><span class="toc-text">1 Introduction</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Problem-Definition"><span class="toc-text">2 Problem Definition</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-Current-Methods"><span class="toc-text">3 Current Methods</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-Methods-for-Preserving-LLMs-Parameters"><span class="toc-text">3.1 Methods for Preserving LLMs Parameters</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-Methods-for-Modifying-LLMs-Paramete"><span class="toc-text">3.2 Methods for Modifying LLMs Paramete</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-Preliminary-Experiments"><span class="toc-text">4 Preliminary Experiments</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-Experiment-Setting"><span class="toc-text">4.1 Experiment Setting</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-Experiment-Results"><span class="toc-text">4.2 Experiment Results</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-Comprehensive-Study"><span class="toc-text">5 Comprehensive Study</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-Portability-Robust-Generalization"><span class="toc-text">5.1 Portability - Robust Generalization</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-Locality-Side-Effect-of-Model-Editing"><span class="toc-text">5.2 Locality - Side Effect of Model Editing</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-Efficiency"><span class="toc-text">5.3 Efficiency</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-Relationship-with-Relevant-Works"><span class="toc-text">6 Relationship with Relevant Works</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#6-1Knowledge-in-LLMs"><span class="toc-text">6.1Knowledge in LLMs</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-2Lifelong-Learning-and-Unlearning"><span class="toc-text">6.2Lifelong Learning and Unlearning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-3Security-and-Privacy-for-LLMs"><span class="toc-text">6.3Security and Privacy for LLMs</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-Conclusion"><span class="toc-text">7 Conclusion</span></a></li></ol></li></ol></div><div class="widget-footer">

<a class="top" onclick="util.scrollTop()"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-width="1.5"><path d="M2 12c0-4.714 0-7.071 1.464-8.536C4.93 2 7.286 2 12 2c4.714 0 7.071 0 8.535 1.464C22 4.93 22 7.286 22 12c0 4.714 0 7.071-1.465 8.535C19.072 22 16.714 22 12 22s-7.071 0-8.536-1.465C2 19.072 2 16.714 2 12Z"/><path stroke-linecap="round" stroke-linejoin="round" d="m9 15.5l3-3l3 3m-6-4l3-3l3 3"/></g></svg><span>回到顶部</span></a></div></widget>
</div></aside><div class='float-panel blur'>
  <button type='button' style='display:none' class='laptop-only rightbar-toggle mobile' onclick='sidebar.rightbar()'>
    <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 6h11m-11 6h11m-11 6h11M4 6h1v4m-1 0h2m0 8H4c0-1 2-2 2-3s-1-1.5-2-1"/></svg>
  </button>
  <button type='button' style='display:none' class='mobile-only leftbar-toggle mobile' onclick='sidebar.leftbar()'>
    <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-width="1.5"><path d="M2 11c0-3.771 0-5.657 1.172-6.828C4.343 3 6.229 3 10 3h4c3.771 0 5.657 0 6.828 1.172C22 5.343 22 7.229 22 11v2c0 3.771 0 5.657-1.172 6.828C19.657 21 17.771 21 14 21h-4c-3.771 0-5.657 0-6.828-1.172C2 18.657 2 16.771 2 13z"/><path id="sep" stroke-linecap="round" d="M5.5 10h6m-5 4h4m4.5 7V3"/></g></svg>
  </button>
</div>
</div><div class="scripts">
<script type="text/javascript">
  const ctx = {
    date_suffix: {
      just: `刚刚`,
      min: `分钟前`,
      hour: `小时前`,
      day: `天前`,
    },
    root : `/`,
  };

  // required plugins (only load if needs)
  if (`local_search`) {
    ctx.search = {};
    ctx.search.service = `local_search`;
    if (ctx.search.service == 'local_search') {
      let service_obj = Object.assign({}, `{"field":"all","path":"/search.json","content":true,"codeblock":true,"sort":"-date"}`);
      ctx.search[ctx.search.service] = service_obj;
    }
  }
  const def = {
    avatar: `https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/avatar/round/3442075.svg`,
    cover: `https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/cover/76b86c0226ffd.svg`,
  };
  const deps = {
    jquery: `https://cdn.bootcdn.net/ajax/libs/jquery/3.7.1/jquery.min.js`,
    marked: `https://cdn.bootcdn.net/ajax/libs/marked/4.0.18/marked.min.js`
  }
  

</script>

<script type="text/javascript">
  const utils = {
    // 懒加载 css https://github.com/filamentgroup/loadCSS
    css: (href, before, media, attributes) => {
      var doc = window.document;
      var ss = doc.createElement("link");
      var ref;
      if (before) {
        ref = before;
      } else {
        var refs = (doc.body || doc.getElementsByTagName("head")[0]).childNodes;
        ref = refs[refs.length - 1];
      }
      var sheets = doc.styleSheets;
      if (attributes) {
        for (var attributeName in attributes) {
          if (attributes.hasOwnProperty(attributeName)) {
            ss.setAttribute(attributeName, attributes[attributeName]);
          }
        }
      }
      ss.rel = "stylesheet";
      ss.href = href;
      ss.media = "only x";
      function ready(cb) {
        if (doc.body) {
          return cb();
        }
        setTimeout(function () {
          ready(cb);
        });
      }
      ready(function () {
        ref.parentNode.insertBefore(ss, before ? ref : ref.nextSibling);
      });
      var onloadcssdefined = function (cb) {
        var resolvedHref = ss.href;
        var i = sheets.length;
        while (i--) {
          if (sheets[i].href === resolvedHref) {
            return cb();
          }
        }
        setTimeout(function () {
          onloadcssdefined(cb);
        });
      };
      function loadCB() {
        if (ss.addEventListener) {
          ss.removeEventListener("load", loadCB);
        }
        ss.media = media || "all";
      }
      if (ss.addEventListener) {
        ss.addEventListener("load", loadCB);
      }
      ss.onloadcssdefined = onloadcssdefined;
      onloadcssdefined(loadCB);
      return ss;
    },

    js: (src, opt) => new Promise((resolve, reject) => {
      var script = document.createElement('script');
      if (src.startsWith('/')){
        src = ctx.root + src.substring(1);
      }
      script.src = src;
      if (opt) {
        for (let key of Object.keys(opt)) {
          script[key] = opt[key]
        }
      } else {
        // 默认异步，如果需要同步，第二个参数传入 {} 即可
        script.async = true
      }
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    }),

    jq: (fn) => {
      if (typeof jQuery === 'undefined') {
        utils.js(deps.jquery).then(fn)
      } else {
        fn()
      }
    },
    
    onLoading: (el) => {
      if (el) {
        $(el).append('<div class="loading-wrap"><svg xmlns="http://www.w3.org/2000/svg" width="2em" height="2em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-width="2"><path stroke-dasharray="60" stroke-dashoffset="60" stroke-opacity=".3" d="M12 3C16.9706 3 21 7.02944 21 12C21 16.9706 16.9706 21 12 21C7.02944 21 3 16.9706 3 12C3 7.02944 7.02944 3 12 3Z"><animate fill="freeze" attributeName="stroke-dashoffset" dur="1.3s" values="60;0"/></path><path stroke-dasharray="15" stroke-dashoffset="15" d="M12 3C16.9706 3 21 7.02944 21 12"><animate fill="freeze" attributeName="stroke-dashoffset" dur="0.3s" values="15;0"/><animateTransform attributeName="transform" dur="1.5s" repeatCount="indefinite" type="rotate" values="0 12 12;360 12 12"/></path></g></svg></div>');
      }
    },
    onLoadSuccess: (el) => {
      if (el) {
        $(el).find('.loading-wrap').remove();
      }
    },
    onLoadFailure: (el) => {
      if (el) {
        $(el).find('.loading-wrap svg').remove();
        $(el).find('.loading-wrap').append('<svg xmlns="http://www.w3.org/2000/svg" width="2em" height="2em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path stroke-dasharray="60" stroke-dashoffset="60" d="M12 3L21 20H3L12 3Z"><animate fill="freeze" attributeName="stroke-dashoffset" dur="0.5s" values="60;0"/></path><path stroke-dasharray="6" stroke-dashoffset="6" d="M12 10V14"><animate fill="freeze" attributeName="stroke-dashoffset" begin="0.6s" dur="0.2s" values="6;0"/></path></g><circle cx="12" cy="17" r="1" fill="currentColor" fill-opacity="0"><animate fill="freeze" attributeName="fill-opacity" begin="0.8s" dur="0.4s" values="0;1"/></circle></svg>');
        $(el).find('.loading-wrap').addClass('error');
      }
    },
    request: (el, url, callback, onFailure) => {
      let retryTimes = 3;
      utils.onLoading(el);
      function req() {
        return new Promise((resolve, reject) => {
          let status = 0; // 0 等待 1 完成 2 超时
          let timer = setTimeout(() => {
            if (status === 0) {
              status = 2;
              timer = null;
              reject('请求超时');
              if (retryTimes == 0) {
                onFailure();
              }
            }
          }, 5000);
          fetch(url).then(function(response) {
            if (status !== 2) {
              clearTimeout(timer);
              resolve(response);
              timer = null;
              status = 1;
            }
            if (response.ok) {
              return response.json();
            }
            throw new Error('Network response was not ok.');
          }).then(function(data) {
            retryTimes = 0;
            utils.onLoadSuccess(el);
            callback(data);
          }).catch(function(error) {
            if (retryTimes > 0) {
              retryTimes -= 1;
              setTimeout(() => {
                req();
              }, 5000);
            } else {
              utils.onLoadFailure(el);
              onFailure();
            }
          });
        });
      }
      req();
    },
  };
</script>

<script>
  const sidebar = {
    leftbar: () => {
      if (l_body) {
        l_body.toggleAttribute('leftbar');
        l_body.removeAttribute('rightbar');
      }
    },
    rightbar: () => {
      if (l_body) {
        l_body.toggleAttribute('rightbar');
        l_body.removeAttribute('leftbar');
      }
    },
    dismiss: () => {
      if (l_body) {
        l_body.removeAttribute('leftbar');
        l_body.removeAttribute('rightbar');
      }
    },
    toggleTOC: () => {
      document.querySelector('#data-toc').classList.toggle('collapse');
    }
  }
</script>

<!-- required -->
<script src="/js/main.js?v=1.27.0" async></script>

<!-- optional -->

  <script>
  window.addEventListener('DOMContentLoaded', (event) => {
    const els = document.querySelectorAll("#comments #giscus");
    if (els.length === 0) return;
    els.forEach((el, i) => {
      try {
        el.innerHTML = '';
      } catch (error) {
        console.error(error);
      }
      var script = document.createElement('script');
      script.async = true;
      for (let key of Object.keys(el.attributes)) {
        let attr = el.attributes[key];
        if (['class', 'id'].includes(attr.name) === false) {
          script.setAttribute(attr.name, attr.value);
        }
      }
      el.appendChild(script);
    });
  });
</script>




<script defer>
  window.addEventListener('DOMContentLoaded', (event) => {
    ctx.services = Object.assign({}, JSON.parse(`{"mdrender":{"js":"/js/services/mdrender.js"},"siteinfo":{"js":"/js/services/siteinfo.js","api":null},"ghinfo":{"js":"/js/services/ghinfo.js"},"sites":{"js":"/js/services/sites.js"},"friends":{"js":"/js/services/friends.js"},"timeline":{"js":"/js/services/timeline.js"},"fcircle":{"js":"/js/services/fcircle.js"},"weibo":{"js":"/js/services/weibo.js"},"memos":{"js":"/js/services/memos.js"}}`));
    for (let id of Object.keys(ctx.services)) {
      const js = ctx.services[id].js;
      if (id == 'siteinfo') {
        ctx.cardlinks = document.querySelectorAll('a.link-card[cardlink]');
        if (ctx.cardlinks?.length > 0) {
          utils.js(js, { defer: true }).then(function () {
            setCardLink(ctx.cardlinks);
          });
        }
      } else {
        const els = document.getElementsByClassName(`ds-${id}`);
        if (els?.length > 0) {
          utils.jq(() => {
            if (id == 'timeline' || 'memos' || 'marked') {
              utils.js(deps.marked).then(function () {
                utils.js(js, { defer: true });
              });
            } else {
              utils.js(js, { defer: true });
            }
          });
        }
      }
    }
  });
</script>

<script>
  window.addEventListener('DOMContentLoaded', (event) => {
    ctx.search = {
      path: `/search.json`,
    }
    utils.js('/js/search/local-search.js', { defer: true });
  });
</script><script>
  window.FPConfig = {
    delay: 0,
    ignoreKeywords: [],
    maxRPS: 5,
    hoverDelay: 25
  };
</script>
<script defer src="https://cdn.bootcdn.net/ajax/libs/flying-pages/2.1.2/flying-pages.min.js"></script><script defer src="https://cdn.bootcdn.net/ajax/libs/vanilla-lazyload/17.8.4/lazyload.min.js"></script>
<script>
  // https://www.npmjs.com/package/vanilla-lazyload
  // Set the options globally
  // to make LazyLoad self-initialize
  window.lazyLoadOptions = {
    elements_selector: ".lazy",
  };
  // Listen to the initialization event
  // and get the instance of LazyLoad
  window.addEventListener(
    "LazyLoad::Initialized",
    function (event) {
      window.lazyLoadInstance = event.detail.instance;
    },
    false
  );
  document.addEventListener('DOMContentLoaded', function () {
    window.lazyLoadInstance?.update();
  });
</script><script>
  ctx.fancybox = {
    selector: `.timenode p>img`,
    css: `https://cdn.bootcdn.net/ajax/libs/fancyapps-ui/5.0.22/fancybox/fancybox.min.css`,
    js: `https://cdn.bootcdn.net/ajax/libs/fancyapps-ui/5.0.22/fancybox/fancybox.umd.min.js`
  };
  var selector = '[data-fancybox]:not(.error)';
  if (ctx.fancybox.selector) {
    selector += `, ${ctx.fancybox.selector}`
  }
  var needFancybox = document.querySelectorAll(selector).length !== 0;
  if (!needFancybox) {
    const els = document.getElementsByClassName('ds-memos');
    if (els != undefined && els.length > 0) {
      needFancybox = true;
    }
  }
  if (needFancybox) {
    utils.css(ctx.fancybox.css);
    utils.js(ctx.fancybox.js, { defer: true }).then(function () {
      Fancybox.bind(selector, {
        hideScrollbar: false,
        Thumbs: {
          autoStart: false,
        },
        caption: (fancybox, slide) => {
          return slide.triggerEl.alt || null
        }
      });
    })
  }
</script><script>
  window.addEventListener('DOMContentLoaded', (event) => {
    const swiper_api = document.getElementById('swiper-api');
    if (swiper_api != undefined) {
      utils.css(`https://unpkg.com/swiper@10.3.1/swiper-bundle.min.css`);
      utils.js(`https://unpkg.com/swiper@10.3.1/swiper-bundle.min.js`, { defer: true }).then(function () {
        const effect = swiper_api.getAttribute('effect') || '';
        var swiper = new Swiper('.swiper#swiper-api', {
          slidesPerView: 'auto',
          spaceBetween: 8,
          centeredSlides: true,
          effect: effect,
          loop: true,
          pagination: {
            el: '.swiper-pagination',
            clickable: true,
          },
          navigation: {
            nextEl: '.swiper-button-next',
            prevEl: '.swiper-button-prev',
          },
        });
      })
    }
  });
</script><script>
  document.addEventListener('DOMContentLoaded', function () {
    window.codeElements = document.querySelectorAll('.code');
    if (window.codeElements.length > 0) {
      ctx.copycode = {
        default_text: `Copy`,
        success_text: `Copied`,
        toast: `复制成功`,
      };
      utils.js('/js/plugins/copycode.js');
    }
  });
</script>


<!-- inject -->

</div></body></html>
