<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>多语言模型中事实知识的跨语言一致性</title>
      <link href="/2023/11/02/duo-yu-yan-mo-xing-zhong-shi-shi-zhi-shi-de-kua-yu-yan-yi-zhi-xing/"/>
      <url>/2023/11/02/duo-yu-yan-mo-xing-zhong-shi-shi-zhi-shi-de-kua-yu-yan-yi-zhi-xing/</url>
      
        <content type="html"><![CDATA[<h1 id="多语言模型中事实知识的跨语言一致性"><a href="#多语言模型中事实知识的跨语言一致性" class="headerlink" title="多语言模型中事实知识的跨语言一致性"></a>多语言模型中事实知识的跨语言一致性</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p><span style="background-color: #2ea8e580">多语言大规模预训练语言模型（PLM）已被证明可以存储大量的事实知识，但观察到语言之间存在很大差异</span>。为了确保具有不同语言背景的用户从同一模型获得一致的反馈，我们研究了各种多语言PLM中事实知识的跨语言一致性（CLC）。为此，我们<span style="background-color: #2ea8e580">提出了一个基于排名的一致性（RankC）指标，以独立于准确性来评估跨语言的知识一致性</span>。使用这个指标，我们在模型级别和语言对级别对CLC的决定因素进行了深入分析。在其他结果中，我们发现<span style="background-color: #ff666680">增加模型大小会导致大多数语言中更高的事实探测准确性，但不会提高跨语言的一致性</span>。最后，我们进行了关于CLC的案例研究，当通过模型编辑在PLM中插入新的事实关联时。英<span style="background-color: #ff666680">语插入的一小部分事实样本的结果揭示了一个清晰的模式，即新知识仅转移到英语具有高 RankC 分数的语言。</span></p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>     大规模预训练语言模型 （PLM） 在事实知识发挥重要作用的任务中展示了强大的能力（Roberts 等人，2020 年;秦等人，2022 年）。虽然以前大多数关于探索 PLM 中事实知识的工作都集中在英语上（Davison 等人，2019 年;布拉维等人，2020 年;申等人，2020;布朗等人，2020 年;阿尔甘米等人，2021 年;Peng 等人，2022 年），一些值得注意的研究已将评估扩展到许多其他语言（Jiang 等人，2020 年;卡斯纳等人，2021 年;尹等人，2022 年）。这些研究结果表明事实知识在多大程度上跨语言泛化，揭示了现代 NLP 技术中语言不平等的另一个方面（Hupkes 等人，2022 年）。</p><p><img src="/../imgs/$%7Bfiilename%7D/JTY72Y4D-1698899470325-23.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/JTY72Y4D-1698899470325-23.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;JTY72Y4D&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FRSQJFTAR%22%2C%22annotationKey%22%3A%225VBT7M5M%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B293.654%2C401.698%2C529.038%2C631.313%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FRHFZGHTF%22%5D%2C%22locator%22%3A%221%22%7D%7D&quot; width=&quot;392&quot; height=&quot;382&quot; src=&quot;attachments/JTY72Y4D.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p>     然而，<span style="background-color: #5fb23680">评估跨语言的事实知识并非易事。确保结果的可比性要求以所有语言查询一组“普遍”事实，但该集合的选择可能偏向于在维基数据等流行知识库中代表性更高的特定世界区域.2相反，在世界其他地区更相关的事实（例如， 关于某一特定区域的地点或重要人物的信息）不太可能出现在基准中，这使得难以解释这种评估的结果</span>。</p><p>     在这项工作中，我们采取了不同的立场：我们没有衡量PLM在每种语言中编码的事实知识量，而是关注其跨语言的一致性。如图 1 所示，多语言 BLOOM-3b 模型当以英语、西班牙语和越南语查询时，输出始终正确完成第一个提示，但不是匈牙利语和希腊语。该模型还以英语、西班牙语和越南语（但不是匈牙利语和希腊语）对第二个查询输出一致但错误的答案，这表明前三种语言在模型中共享相关的知识表示。</p><p>     跨语言一致性 （CLC） 的研究很重要，至少有两个原因：首先，对事实的真正了解意味着无论给定的表面形式如何，都要对其含义进行编码（Ohmer 等人，2023 年）。因此，如果模型知道北京市是中国的首都，那么当用不同的语言询问相同的问题时，它应该返回相同的答案。从实际的角度来看，CLC 对于确保用户在不同语言与同一模型交互时具有相似的体验至关重要。其次，研究CLC对于了解在多语言PLM中以一种语言获得的知识是否以及如何隐含地转移到另一种语言非常重要。除了科学相关性外，这对将外部知识纳入多语言PLM具有实际意义。事实上，虽然多产的工作线侧重于模型编辑，作为以各种数据和计算效率的方式在 PLM 中插入新事实关联的一种方式（De Cao 等人，2021 年;侯等人，2022;Meng 等人，2022 年），据我们所知，还没有人研究过这如何影响直接应用编辑的语言以外的语言中的事实知识。</p><p>      我们对多语言PLM中的事实知识CLC进行了首次深入研究，并做出了以下贡献：（i）我们提出了一种新的基于排名的一致性（RankC）指标，该指标独立于准确性评估知识的一致性。（ii） 我们过滤现有的不平衡数据集（Jiang 等人，2020 年;Kassner 等人，2021 年）形成多并行 CLC 基准，平衡多语言模型分析 （BMLAMA），该基准将相同的一组提示翻译成所有语言。（iii）我们将新指标应用于BMLAMA，以评估各种仅编码器，仅解码器和编码器解码器PLM中的CLC，包括XLM-RoBERTa-large，mT5-large和BLOOM系列。我们分析了许多与CLC相关的语言属性，并为事实知识如何在语言之间渗透提供了新的见解。最后（iv）我们使用基于神经元可解释性的最先进的模型编辑技术（Meng 等人，2022 年）提供案例研究，提供初步证据，证明 CLC 可以预测插入语言 X 的事实是否会转移到语言 Y 中。</p><h2 id="2-Related-Work"><a href="#2-Related-Work" class="headerlink" title="2.Related Work"></a>2.Related Work</h2><p><strong>探索 PLM 中的事实知识</strong> 自 LAMA 首次提出以来（Petroni 等人，2019 年），基于提示的探测已成为评估 PLM 中事实知识的主要技术（Davison 等人，2019 年;布拉维等人，2020 年;申等人，2020;布朗等人，2020 年;阿尔甘米等人，2021 年;彭等人，2022 年）。给定元组（主体、关系、对象）中表示的知识，通过将主题填充到特定于关系的模板中来形成查询 q，该模板被馈送到 PLM 中。如果预测与对象一致，则认为模型具有此知识。例如，给定一组候选城市名称，当查询“中华人民共和国的首都是_”时，如果PLM在所有候选城市中正确答案“北京”的概率最高，则认为PLM捕获了这条知识。</p><p><strong>事实知识的多语言探索</strong> 除了大量关注英语的著作外，一些著名的研究通过将英语提示-对象对翻译成多种语言来多语言探索事实知识。X-FACTR（Jiang 等人，2020 年）和 MLAMA（Kassner 等人，2021 年）表明，由于其培训语料库的大小，不同语言的知识量之间存在很大差异。除了英语和少数其他高资源欧洲语言外，总体上报告的探测准确性非常低（即&lt;10%）。另一项相关工作， GeoMLAMA（Yin 等人，2022 年）专门探测了在不同地区可能有所不同的常识性知识，导致相当令人惊讶的发现，即探索某个国家（例如中国）知识的最佳语言通常不是给定国家的母语（例如中文）。所有这些研究的主要重点是评估每种语言编码的事实知识的数量，而不是了解这些知识如何在语言之间渗透。</p><p><strong>自洽性</strong> 自洽性是指 PLM 对同一查询的保留含义的释义输出相同答案的能力。英语PLM的自洽性在不同任务中都受到了关注（Li等人，2019;米切尔等人，2022 年;王等人，2023 年）。Fierro和Søgaard（2022）通过将自洽性的研究扩展到多语言PLM，方法是在每种语言中单独测量自洽性。他们的结果显示，所有语言的自洽性都很差。</p><p><strong>跨语言一致性</strong> 据我们所知，我们是第一个对多语言PLM中事实知识的跨语言一致性进行系统分析的公司，即PLM对不同语言提出的相同问题返回相同答案的程度。作为探索研究的一部分，Jiang等人（2020）计算了mBERT中两种语言之间重叠的正确预测的比例（参见第3.1节）。他们报告的总体比率较低，在最相似的对（英语 - 荷兰语）中只有34%的峰值，但没有进一步调查决定一致性的因素。此外，他们将这种分析限制在一个（仅编码器）模型，同时我们还检查了编码器-解码器和一系列仅解码器模型（参见第5.1节）。另一个区别是，<span style="color: #ff2020"><span style="background-color: #ff666680">我们对一致性采取了更全面的观点，即不正确但跨语言引用同一实体的预测也应被视为一致。</span></span>有趣的是，Ohmer 等人（2023 年）的并行工作建议使用模型预测的跨语言一致性作为评估其对特定单词形式之外的含义的理解的一种手段。他们在两个语言理解任务（释义识别和自然语言推理）中展示了他们的方法。尽管范围不同，但他们使用英语、德语和中文翻译对 ChatGPT 的评估表明，模型响应的一致性有限，这与我们的事实调查结果一致（参见第 5 节），并进一步表明这个问题在非常大规模的上一代 PLM 中仍然存在</p><h2 id="3-Measuring-Cross-Lingual-Consistentcy"><a href="#3-Measuring-Cross-Lingual-Consistentcy" class="headerlink" title="3.Measuring Cross-Lingual Consistentcy"></a>3.Measuring Cross-Lingual Consistentcy</h2><p><strong>任务定义</strong> 每种语言l ∈ L有一组定义为 Ql 的查询（即提示）。对于每个查询 qi ∈ Ql，有Ni对应候选项，例如，查询“史蒂夫乔布斯为 __ 工作”有 10 个候选者：苹果、任天堂、谷歌、WWE、亚历山大、德国、雅虎、柏林、BBC、Microsoft。每个查询都会馈送到 PLM，返回的概率用于计算每个候选单词的排名分数。分数计算取决于模型的类型（仅编码器、编码器解码器或仅解码器）以及候选单词分割为子单词的方式（请参阅附录 B 中的详细信息）。按排名分数排序后，Qi 的候选集表示为 {ci1， . . . ， cNi i }，其中 ci1 的预测概率最高，cNi i 的预测概率最低。请注意，现有的用于知识探测的多语言数据集（X-FACTR（Jiang 等人，2020 年）和 MLAMA（Kassner 等人，2021 年））在不同语言中具有不同数量的查询，这对于衡量一致性是有问题的。</p><h3 id="3-1Prioions-Work-Correct-Predictions-Overlap"><a href="#3-1Prioions-Work-Correct-Predictions-Overlap" class="headerlink" title="3.1Prioions Work:Correct Predictions Overlap"></a>3.1Prioions Work:Correct Predictions Overlap</h3><p>     基于每个 qi 和 q′ i 的预测 ci1 和 c′1 i（即排序候选列表的第一个元素），Jiang 等人 （2020） 计算正确预测的平均重叠率如下：</p><p><img src="/../imgs/$%7Bfiilename%7D/UTGQ3CDQ-1698899466973-21.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/UTGQ3CDQ-1698899466973-21.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;UTGQ3CDQ&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FRSQJFTAR%22%2C%22annotationKey%22%3A%22BSQLBJQX%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%223%22%2C%22position%22%3A%7B%22pageIndex%22%3A2%2C%22rects%22%3A%5B%5B303%2C459.39%2C527.5%2C518.39%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FRHFZGHTF%22%5D%2C%22locator%22%3A%223%22%7D%7D&quot; width=&quot;374&quot; height=&quot;98&quot; src=&quot;attachments/UTGQ3CDQ.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p>其中 1（·) 是指示函数，oi 和 o′i 分别是 qi 和 q′ i 的正确答案。</p><p>     由于他们的基准测试包含不同语言的不同数量的查询，因此它们通过丢弃 l 或 l′ 中不可用的样本来过滤每个语言对 （l， l′） 的查询集：</p><p><img src="/../imgs/$%7Bfiilename%7D/CKJAUHAN-1698899465379-19.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/CKJAUHAN-1698899465379-19.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;CKJAUHAN&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FRSQJFTAR%22%2C%22annotationKey%22%3A%22GIHZDH3X%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%223%22%2C%22position%22%3A%7B%22pageIndex%22%3A2%2C%22rects%22%3A%5B%5B307.5%2C333.39%2C526.5%2C367.39%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FRHFZGHTF%22%5D%2C%22locator%22%3A%223%22%7D%7D&quot; width=&quot;365&quot; height=&quot;57&quot; src=&quot;attachments/CKJAUHAN.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p> <span style="background-color: #2ea8e580">由于筛选是分别对每个语言对完成的，因此这会导致不同的查询集，这限制了它们的结果在具有非常不同的筛选集的语言对之间的可比性。</span></p><h3 id="3-2This-Work-RankC-Metric"><a href="#3-2This-Work-RankC-Metric" class="headerlink" title="3.2This Work:RankC Metric"></a>3.2This Work:RankC Metric</h3><p><span style="background-color: #2ea8e580">为了确保不同语言对之间的可比性，我们要求基准测试中的所有查询及其相应的候选查询都翻译成所有语言。</span>因此，对于任何语言对 （l， l′），查询集的长度始终相等 |Ql|&#x3D; |Ql′|，第 i 个查询 Ni &#x3D; N ′ i 的候选项数也是如此。基于这些假设，我们提出了一种新的基于排名的一致性（RankC）指标，以有效地评估PLM中知识的跨语言一致性，而与准确性无关。<span style="background-color: #2ea8e580">我们不只是关注正确的预测，而是将所有候选的排名纳入考虑。</span>RankC的灵感来自信息检索的K（MAP@K）指标的平均平均精度（Schutze等人，2008）。与原版MAP@K不同，在 RankC K 中因查询而异。qi 的值 K 等于 Ni，即其候选者的数量。给定语言 l 和 l′，两种语言之间的一致性分数定义为所有翻译查询对 （qi， q′ i） ∈ （Ql， Ql′） 的一致性平均值：</p><p><img src="/../imgs/$%7Bfiilename%7D/4BUNNT2A-1698899462448-17.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/4BUNNT2A-1698899462448-17.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;4BUNNT2A&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FRSQJFTAR%22%2C%22annotationKey%22%3A%22UWV6KRQ7%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%224%22%2C%22position%22%3A%7B%22pageIndex%22%3A3%2C%22rects%22%3A%5B%5B72%2C596.89%2C292.5%2C645.39%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FRHFZGHTF%22%5D%2C%22locator%22%3A%224%22%7D%7D&quot; width=&quot;368&quot; height=&quot;81&quot; src=&quot;attachments/4BUNNT2A.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p>每个查询对的一致性是通过加权平均 P @j 函数计算的，该函数输出具有前 j 个最高概率的候选函数之间的重叠比率3：</p><p><img src="/../imgs/$%7Bfiilename%7D/9E3DW5HT-1698899458937-15.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/9E3DW5HT-1698899458937-15.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;9E3DW5HT&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FRSQJFTAR%22%2C%22annotationKey%22%3A%22IP7IB4WX%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%224%22%2C%22position%22%3A%7B%22pageIndex%22%3A3%2C%22rects%22%3A%5B%5B71.5%2C453.39%2C291%2C536.89%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FRHFZGHTF%22%5D%2C%22locator%22%3A%224%22%7D%7D&quot; width=&quot;366&quot; height=&quot;139&quot; src=&quot;attachments/9E3DW5HT.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p>每个 P @j的权重 wj 定义如下。</p><p><strong>基于排名的权重</strong> 直观地说，排名较高的候选人应该对一致性分数产生更大的影响。为了实现这一目标，RankC 对所有 P @js采用加权平均值，其中 j 较小的 P @j被赋予较高的权重 wj，以强调具有高概率的候选人的影响。但是，预测概率不能直接使用，因为它们对于 qi 和 q′ i 的候选者是不同的。为了解决这个问题，我们引入了基于softmax的归一化权重，而不是值j：</p><p><img src="/../imgs/$%7Bfiilename%7D/SGCTJSZD-1698899456427-13.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/SGCTJSZD-1698899456427-13.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;SGCTJSZD&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FRSQJFTAR%22%2C%22annotationKey%22%3A%22B2LWRTBH%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%224%22%2C%22position%22%3A%7B%22pageIndex%22%3A3%2C%22rects%22%3A%5B%5B71.5%2C223.39%2C292%2C274.89%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FRHFZGHTF%22%5D%2C%22locator%22%3A%224%22%7D%7D&quot; width=&quot;368&quot; height=&quot;86&quot; src=&quot;attachments/SGCTJSZD.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p>其中 Ni 是查询 qi 和 q′ i.4 的候选数量 结合等式 3、4 和 5，RankC 指标变为：</p><p><img src="/../imgs/$%7Bfiilename%7D/ML4DE4BX-1698899454568-11.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/ML4DE4BX-1698899454568-11.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;ML4DE4BX&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FRSQJFTAR%22%2C%22annotationKey%22%3A%22UUK6AGQ7%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%224%22%2C%22position%22%3A%7B%22pageIndex%22%3A3%2C%22rects%22%3A%5B%5B69.5%2C92.89%2C291.5%2C180.89%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FRHFZGHTF%22%5D%2C%22locator%22%3A%224%22%7D%7D&quot; width=&quot;370&quot; height=&quot;147&quot; src=&quot;attachments/ML4DE4BX.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p>附录D给出了RankC计算示例，以及高&#x2F;低RankC的解释</p><p><img src="/../imgs/$%7Bfiilename%7D/UNBA9DMX-1698899452209-9.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/UNBA9DMX-1698899452209-9.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;UNBA9DMX&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FRSQJFTAR%22%2C%22annotationKey%22%3A%22JHHBPXWD%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%224%22%2C%22position%22%3A%7B%22pageIndex%22%3A3%2C%22rects%22%3A%5B%5B299%2C662.89%2C527.5%2C774.89%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FRHFZGHTF%22%5D%2C%22locator%22%3A%224%22%7D%7D&quot; width=&quot;381&quot; height=&quot;187&quot; src=&quot;attachments/UNBA9DMX.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p>     我们在同一数据集上对RankC与以前使用的指标（COverlap，参见公式1)进行了实证比较。附录F中的结果表明，<span style="background-color: #2ea8e580">几乎所有具有高COVERLAP分数的语言对也获得了较高的RankC分数。此外，RankC揭示了一些新的高一致性对，由于探测精度低，它们的COverlap评分较低。</span></p><h2 id="4-Experimental-Setup"><a href="#4-Experimental-Setup" class="headerlink" title="4.Experimental Setup"></a>4.Experimental Setup</h2><p><strong>数据集</strong> 如第 3.2 节所述，RankC 要求将查询及其候选语言翻译成所有评估语言。因此，我们从 X-FACTR（Jiang 等人，2020 年）和 MLAMA（Kassner 等人，2021 年）中提取所有满足此标准的查询。我们将生成的多并行数据集称为平衡多语言模型分析（BMLAMA），并以两个版本发布：BMLAMA-17，包括17种语言的6.7k查询（接近X-FACTR，包括23种语言），BMLAMA-53包括53种语言的3k查询（与MLAMA相同）。详细统计数据如表1所示。</p><p><strong>模型</strong> 多语言知识探索的先前工作（Jiang等人，2020;Kassner 等人，2021 年）专注于仅编码器的 PLM，例如 mBERT（Devlin 等人，2019 年）或 XLM-RoBERTa（Liu 等人，2019 年）。然而，由于纯解码器 PLM 已成为当前 NLP 时代的主流，我们的实验还包括仅解码器的 BLOOM 系列（560m、1.1b、1.7b、3b 参数）（Scao 等人，2022 年）和编码器-解码器 mT5large （1.2b）（Xue 等人，2021 年），此外还包括仅编码器的 XLM-RoBERTa-large（354m）。</p><h2 id="5-Main-Consistency-Result"><a href="#5-Main-Consistency-Result" class="headerlink" title="5.Main Consistency Result"></a>5.Main Consistency Result</h2><p>在查看一致性之前，我们在图 2 中展示了 BMLAMA-17.5 上三个 PLM 的实际探测精度结果，我们首先注意到，<span style="background-color: #2ea8e580">仅编码器 XLM-RoBERTa-large 和编码器解码器 mT5-large 模型在平均探测精度方面优于整个仅解码器的 BLOOM 系列。三种型号的跨语言趋势相似，但是，BLOOM以远高于所有其他语言的英语准确性脱颖而出。</span><span style="background-color: #ff666680">关于模型大小（BLOOM 系列，绿条），我们发现增加参数数量会导致事实探测精度的轻微但一致的提高，</span>这与以前的工作一致（Petroni 等人，2019 年）。</p><p>    我们的XLM-RoBERTa-large结果与Jiang等人（2020）在XFACTR上报告的结果一致，证明了我们的多并行数据集BMLAMA的可靠性。</p><h3 id="5-1Consistency-in-Different-PLMs"><a href="#5-1Consistency-in-Different-PLMs" class="headerlink" title="5.1Consistency in Different PLMs"></a>5.1Consistency in Different PLMs</h3><p>图 3 显示了三种 PLM 的 RankC 结果。第一个观察结果是，所有模型的平均一致性6都相低，BLOOM3b（25%）最低。这一阴性结果与Jiang等人（2020）在mBERT上观察到的正确预测的低重叠率一致。</p><p>     <span style="background-color: #ff666680">我们现在放大了不同语言对之间的比较，这是通过新的RankC指标和平衡数据集BMLAMA实现的。在这里，我们发现欧洲语言英语，法语，荷兰语，西班牙语和加泰罗尼亚语在mT5-large和XLM-RoBERTa-large方面共享了相当多的知识。类似的模式适用于BLOOM-3b，但荷兰语除外，这是意料之中的，因为该语言未包含在此模型的训练语料库中。此外，越南语和土耳其语在所有PLM中都与上述欧洲语言实现了显着的一致性。这些语言的一个共同特点是它们都使用相同的脚本（拉丁语）。另一个值得注意的高一致性对是俄语和乌克兰语，使用相同脚本（西里尔文）并且也密切相关的两种语言。这些观察表明，各种语言属性会影响多语言知识的CLC。我们将在第 6.1 节中检查许多此类属性。</span></p><h3 id="5-2Effect-of-Model-Size"><a href="#5-2Effect-of-Model-Size" class="headerlink" title="5.2Effect of Model Size"></a>5.2Effect of Model Size</h3><p>如上所述（图 2 中的绿条）和之前的工作（Petroni 等人，2019 年）所观察到的，<span style="background-color: #ff666680">当其他因素固定时，检索正确知识的能力会随着模型大小的增长而增长。</span>我们问CLC是否也是如此。<span style="background-color: #5fb23680">然而，图4中的BLOOM结果显示，从我们系列中最小的模型移动到最大的模型时，平均RankC（+2%）只有很小的变化，即参数增加了5倍。</span>虽然这种模式不能安全地推广到其他模型，但它确实表明，在非常大规模的PLM中，跨语言一致性可能仍然是一个问题8。</p><h2 id="6-Typological-Similarity"><a href="#6-Typological-Similarity" class="headerlink" title="6.Typological Similarity"></a>6.Typological Similarity</h2><p>类型学特征已被证明可用于模拟语言之间的细粒度相似性，并指导各种多语言 NLP 任务的迁移学习技术（Ponti 等人，2019 年;尤斯图恩等人，2022 年）。这些特征是否也能解释在多语言PLM中观察到的事实知识一致性的一些差异？<span style="background-color: #2ea8e580">例如，我们可能期望具有相似语法和词序或具有相关词汇的语言共享更高的语言程度。在多语言模型中。我们可能还期望在同一世界地区使用的语言更有可能在训练数据中遇到相同实体和事件的提及。</span></p><p>     为了回答这个问题，我们从lang2vec（Littell等人，2017）获得了四种类型的<span style="background-color: #2ea8e580">类型相似性（句法，遗传，地理和语音）</span>，这是一个开源库，提供基于各种类型学数据库的预先计算的相似性.9接下来，我们计算RankC分数与BMLAMA中所有语言对的类型相似性之间的皮尔逊相关系数（Cohen等人，2009）。</p><p>     表2显示了BMLAMA-17和较小但多语言的BMLAMA-53.10的结果 对于BMLAMA-17，<span style="background-color: #ff666680">我们发现RankC与遗传相似性具有中等相关性，与地理相似性具有弱相关性，但与句法相似性没有显着相关性。正如预期的那样，没有观察到与语音相似性的相关性。更全面的数据集BMLAMA-53上的相关性结果相似，除了句法相似性获得弱正相关。</span>有点令人惊讶的是，在这个更大的数据集中，<span style="background-color: #5fb23680">遗传和地理上的相似性使它们的相关性略有下降，这可能是由于低资源语言的类型向量中存在噪声。</span></p><p>     遗传相关语言的一个重要特征是它们往往有很多单词共同或具有共同祖先。<span style="background-color: #ff666680">因此，RankC与遗传相似性的中等相关性，加上与句法和地理相似性的弱相关性，表明词汇重叠可能是CLC比具有相似的语法和词序或在附近地区使用更重要的因素。</span></p><h3 id="6-2Subword-Vocabulary-Overlap"><a href="#6-2Subword-Vocabulary-Overlap" class="headerlink" title="6.2Subword Vocabulary Overlap"></a>6.2Subword Vocabulary Overlap</h3><p>基于上述观察结果，我们研究了词汇重叠的粗略测量是否也可以很好地预测CLC。具体来说，我们提取了我们评估语言中严格平行语料库的词汇表，并测量它们的成对重叠：</p><p><img src="/../imgs/$%7Bfiilename%7D/9DVJYQ7U.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/9DVJYQ7U.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;9DVJYQ7U&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FRSQJFTAR%22%2C%22annotationKey%22%3A%22Q2E54XNM%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%227%22%2C%22position%22%3A%7B%22pageIndex%22%3A6%2C%22rects%22%3A%5B%5B70.385%2C344.005%2C291.923%2C381.505%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FRHFZGHTF%22%5D%2C%22locator%22%3A%227%22%7D%7D&quot; width=&quot;369&quot; height=&quot;62&quot; src=&quot;attachments/9DVJYQ7U.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p>我们考虑两个语料库：BMLAMA 本身和 Flores-200（Costa-jussà 等人，2022 年)。前者预计非常相关，但由此产生的相关性可能不太可推广，因为它是衡量一致性本身的同一语料库。相比之下，后者是一组混合域的 2k 个句子，从英语翻译成 200 种语言，用于机器翻译评估。因为我们对不同语言使用完全相同的单词表示的程度感兴趣，所以我们在测量词汇重叠之前用模型的分词器对语料库进行分割，这使得这个指标模型依赖于。</p><p>     如表2（右）所示，BMLAMA上的皮尔逊相关分数证明，<span style="background-color: #ff666680">子词词汇重叠对PLM中知识的跨语言一致性有显著的强烈影响，掩盖了遗传的影响</span></p><p><img src="/../imgs/$%7Bfiilename%7D/7UYEHQJN.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/7UYEHQJN.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;7UYEHQJN&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FRSQJFTAR%22%2C%22annotationKey%22%3A%22I4F9IANM%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%227%22%2C%22position%22%3A%7B%22pageIndex%22%3A6%2C%22rects%22%3A%5B%5B294.808%2C500.928%2C528.462%2C596.698%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FRHFZGHTF%22%5D%2C%22locator%22%3A%227%22%7D%7D&quot; width=&quot;389&quot; height=&quot;159&quot; src=&quot;attachments/7UYEHQJN.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p>相似。<span style="background-color: #ff666680">这表明事实知识可能主要以相当肤浅的方式（通过共享使用一些子词嵌入）渗透到语言之间，相反，即使语言相关，在没有这种锚点的情况下，它也可能受到阻碍。</span>例如，<span style="background-color: #2ea8e580">BLOOM-3b中一致性最高的对是乌克兰语-俄语，它们位于语言树中（遗传相似性：0.8），并且总体上共享大量子词词汇（词汇重叠：0.76）。然而，在查询大卫·卡梅伦的工作地点时，BLOOM-3b预测的是俄语查询（“伦敦”）中的正确答案，但乌克兰语（“莫斯科”）中的错误答案。</span>这表明<span style="background-color: #2ea8e580">正确的知识没有从俄语转移到乌克兰语，因为这两个查询之间的子词重叠有限（0.17）。</span>当在Flores上测量词汇重叠时（表2的最后一列），相关性较低，但仍然显着为正，表明我们的发现不仅限于我们的基准。跨语言知识一致性与词汇重叠之间的相关性如图5所示。<span style="background-color: #2ea8e580">CLC对浅词汇重叠的强烈依赖部分解释了为什么增加模型大小没有积极的影响</span>（参见第5.2节)。<span style="background-color: #5fb23680">我们推测，较大的子单词词汇实际上可能导致较低的一致性，因为在任何两种语言之间共享部分单词的机会会降低。我们将对这一假设的进一步调查留给未来的工作。</span></p><h2 id="7-Case-Study-Cross-Lingual-Consistency-and-Knowledge-Incorporation"><a href="#7-Case-Study-Cross-Lingual-Consistency-and-Knowledge-Incorporation" class="headerlink" title="7.Case Study: Cross-Lingual Consistency and Knowledge Incorporation"></a>7.Case Study: Cross-Lingual Consistency and Knowledge Incorporation</h2><p>之前的工作（Jiang et al., 2020；Kassner et al., 2021；Artetxe et al., 2022）和我们的探索结果表明，低资源语言的知识量是有限的。简单地在更大的非英语语料库上训练新的 PLM 非常耗时，而且大多数大学和其他研究机构都无法承担其成本（Ding 等人，2022）。<span style="background-color: #2ea8e580">一个有前景的解决方案是通过微调方法整合外部知识（Hu et al., 2022）或以非常有针对性的方式直接编辑 PLM 的权重</span>（De Cao et al., 2021；Meng et al., 2022）。<span style="background-color: #2ea8e580">为了使该过程在多语言场景中可行并避免意外影响，重要的是要了解以一种语言插入知识是否以及如何影响 PLM 中的其他语言，包括最易受影响和最不易受影响的语言</span>。在本节中，我们将针对这个问题及其与 CLC 的相互作用进行第一个案例研究。</p><p><strong>Rank-One 模型编辑（ROME）</strong>由Meng 等人提出。 (2022)，这种基于神经元可解释性的最先进的模型编辑技术在特异性和泛化方面都优于其他几种编辑技术。简而言之，<span style="background-color: #2ea8e580">该技术直接修改 PLM 早期前馈层中的权重，其中事实关联已通过因果干预找到。</span></p><p>**反事实知识 **遵循孟等人。 （2022），我们考虑将反事实知识插入 PLM 的任务，例如事实上错误的“史蒂夫·乔布斯曾为微软工作”。由于在预训练期间从未观察到此类事实关联，因此这种方法避免了插入模型已认为可能的事实的风险。</p><p><strong>案例研究</strong> 我们研究了 BLOOM-3b，因为 ROME 目前仅适用于仅解码器模型。选择英语作为插入事实的源语言。作为目标语言，我们选择两种与英语具有高度一致性（RankC）的语言（西班牙语和越南语）和两种RankC 较低（匈牙利语和希腊语）。这些语言在脚本和与英语的相关性方面也各不相同。通过确保 PLM 在编辑之前选择最有可能的最初正确答案来挑选六个查询。我们还确保，对于每个编辑的知识，主题和客体实体在所有语言中都是相同的标记。这消除了这样的担忧：例如，西班牙语和越南语仅仅因为所评估的查询中主语和宾语标记的词汇共现而获得与英语一致的预测。对于评估，我们遵循孟等人的设置。 （2022）并将候选集缩小为两个单词——一个正确，一个错误。后者是ROME的编辑目标。根据每个查询，PLM 计算正确和错误答案的 logit 值，分别为 logitC 和 logitW。这些 logits 在不同语言之间差异很大。为了关注原始事实和编辑事实之间的关系，我们按照之前的工作（Sarti et al., 2023）将 logits 标准化为</p><p><img src="/../imgs/$%7Bfiilename%7D/JTSVCJAA.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/JTSVCJAA.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;JTSVCJAA&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FRSQJFTAR%22%2C%22annotationKey%22%3A%22LQTSE2UG%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%228%22%2C%22position%22%3A%7B%22pageIndex%22%3A7%2C%22rects%22%3A%5B%5B300.577%2C424.775%2C526.731%2C775.544%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FRHFZGHTF%22%5D%2C%22locator%22%3A%228%22%7D%7D&quot; width=&quot;377&quot; height=&quot;585&quot; src=&quot;attachments/JTSVCJAA.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p>     表 3 显示了三个查询的结果。一个非常清晰的模式出现了：<span style="background-color: #ff666680">当一个事实被插入到英语中时，它会一致地传播到高 CLC 语言（即西班牙语和越南语）。相反，低 CLC 语言（匈牙利语和希腊语)受到的影响要小得多，即使在模型编辑后，仍然会输出更高的正确答案概率。</span>附录 J 中给出的其余三个查询显示了相同的模式。</p><p>    尽管我们的研究规模较小，但结果表明，<span style="background-color: #5fb23680">CLC 不仅是 PLM 中现有知识的副产品，而且还代表了在将新知识融入其他语言时对语言扰动的敏感性。</span>我们认为这是增强多语言场景中模型编辑优势的一个有前途的方向。</p><h2 id="8-Conclusion"><a href="#8-Conclusion" class="headerlink" title="8.Conclusion"></a>8.Conclusion</h2><p>我们分析了多语言大型 PLM 中事实知识的跨语言一致性 (CLC)。我们提出了一个新的指标 RankC，用于独立于准确性来量化一致性，并将其应用于跨语言平衡的事实知识基准。我们的综合分析表明，<span style="background-color: #ff666680">(i) 不同 PLM 的平均 CLC 较低，并且不受模型大小的明显影响；</span> <span style="background-color: #ff666680">(ii) PLM 内不同语言对的 CLC 与遗传相似性显着相关，但与词汇重叠的相关性明显更强；</span> <span style="background-color: #ff666680">(iii) 通过模型编辑插入到语言 X 中的新事实更有可能传播到具有 X 的 CLC 分数较高的语言。</span></p><h3 id="Limitations"><a href="#Limitations" class="headerlink" title="Limitations"></a>Limitations</h3><p>由于 GPU 资源的限制，我们无法测试大于 BLOOM-7.1b 的模型。鼓励在未来的工作中将我们的分析扩展到更大规模的模型，看看是否得出相同的结论。<span style="background-color: #5fb23680">然而，图4的结果表明，随着模型规模的增加，平均CLC增长极其缓慢。 BMLAMA 中包含的事实虽然被认为具有普遍性，但可能与西方世界更相关，这可能会在评估中引入偏见。我</span>们从 BMLAMA 所建立的基准中继承了这个问题。解决这个问题并非易事，特别是在比较工作中，需要探究跨语言的确切事实集，并且应该在未来的工作中予以关注。</p>]]></content>
      
      
      <categories>
          
          <category> NLP顶会 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> EMNLP2023 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>我们可以编辑多模态大型语言模型吗？</title>
      <link href="/2023/11/02/wo-men-ke-yi-bian-ji-duo-mo-tai-da-xing-yu-yan-mo-xing-ma/"/>
      <url>/2023/11/02/wo-men-ke-yi-bian-ji-duo-mo-tai-da-xing-yu-yan-mo-xing-ma/</url>
      
        <content type="html"><![CDATA[<h1 id="我们可以编辑多模态大型语言模型吗？"><a href="#我们可以编辑多模态大型语言模型吗？" class="headerlink" title="我们可以编辑多模态大型语言模型吗？"></a>我们可以编辑多模态大型语言模型吗？</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>在本文中，我们重点关注编辑多模态大型语言模型（MLLM）。与编辑单模态LLMs相比，多模态模型编辑更具挑战性，需要在编辑过程中进行更高水平的审查和仔细考虑。为了促进这一领域的研究，我们<span style="background-color: #ff666680">构建了一个名为 MMEdit 的新基准，用于编辑多模式LLMs并建立一套创新的评估指标</span>。我们进行了涉及各种模型编辑基线的综合实验，并分析了编辑不同组件对多模式LLMs的影响。根据经验，我们注意到<span style="background-color: #ff666680">以前的基线可以在一定程度上实现多模态 LLM 的编辑，但效果仍然差强人意，这表明这项任务的潜在难度。</span>我们希望我们的工作能够为 NLP 社区提供见解1。</p><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h2><p>随着大型语言模型 (LLM) 的广泛部署（Zhao 等人，2023），在不产生大量再培训成本的情况下保持其知识准确和最新的必要性变得越来越重要（Sinitsin 等人，2020）。<span style="background-color: #2ea8e580">先前的研究引入了知识编辑方法，旨在逐步向语言模型注入一组新的事实</span>（Mitchell 等人，2022a；Han 等人，2023；Hartvigsen 人，2022；Zhong 等人，2023；Gandikota等人，2023；姚等人，2023）。</p><p>      与单模态模型编辑不同，多模态LLMs的编辑任务因其固有的多样性和复杂性而面临相当大的挑战。具体来说，<span style="background-color: #5fb23680">多模式模型的错误输出可能源于各种模式的协同效应。输出不正确可能不仅仅源于LLMs，类似于误读或误识别等人为错误</span>（例如，色盲影响图像中的颜色识别）。如图1所示，在编辑之前，模型将物体错误地识别为“梯子”而不是正确的“障碍物”，从而导致错误的预测。编辑后，模型准确识别了“障碍”。请注意，多模态LLMs（Yin et al., 2023）的效用正在增加，<span style="background-color: #5fb23680">但缺乏相应的数据集资源和用于编辑多模态大语言模型的基准。</span></p><p>     为了促进这一领域的研究，我们第一步构建了一个多模态模型编辑基准：<span style="background-color: #ff666680">称为 MMEdit，它包含两个子任务：编辑 VQA 和编辑图像标题。</span>具体来说，我们<span style="background-color: #ff666680">遵循单模态模型编辑方法（Mitchell et al., 2022a；Cao et al., 2021；Mitchell et al., 2022b）来构建数据集，这扩展了之前的评估原则，即 Reliability2、Locality3 和通用性4，多模式设置。对于可靠性评估，我们从严格的数据收集开始，收集表现不佳的多模态模型数据来创建专用的可靠性编辑数据集（§3.2.1）。对于局部性评估，我们将其分为文本局部性和多模态局部性，以评估多模态 LLM 的稳定性（第 3.2.2 节）。对于通用性评估，与局部性类似，我们将其分为文本通用性和多模态通用性，并利用 ChatGLM (Du et al., 2022) 和稳定扩散 (Rombach et al., 2022) 生成重新措辞的文本以及重新措辞的图像进行评估（第 3.2.3 节）。我们评估了 MMEdit 上的几种知识编辑方法。</span>根据经验，我们注意到<span style="background-color: #5fb23680">当前的编辑方法对于编辑多模态语言模型中的文本模型有效，但对于编辑视觉模块则不那么有效</span>。例如，在编辑BLIP-2模型的语言模块时，MEND的可靠性可以达到92.6%，但在编辑视觉模块时只能达到14.1%，表明该任务的潜在难度和机遇。总的来说，我们的主要贡献如下：</p><ul><li>我们迈出了第一步，研究编辑多模态LLMs，将模型编辑扩展到多模态设置。</li></ul><!----><ul><li>我们提出了MMEdit，一个新的基准，用于评估多模态模型编辑方法的可靠性、局部性和通用性。</li></ul><!----><ul><li>我们使用各种基线进行实验，证明虽然当前的方法可以在一定程度上帮助多模式编辑，但结果仍然达不到完全满意的程度。我们将公开代码和数据集以用于未来的研究目的。</li></ul><h2 id="2-Related-Work"><a href="#2-Related-Work" class="headerlink" title="2 Related Work"></a>2 Related Work</h2><h3 id="2-1-Multimodal-Language-Models"><a href="#2-1-Multimodal-Language-Models" class="headerlink" title="2.1 Multimodal Language Models"></a>2.1 Multimodal Language Models</h3><p>     多模态学习 (MML)（Xu 等人，2022a；Yin 等人，2023）提供了一种构建 AI 模型的整体方法，该模型可以从各种数据模态中提取和关联信息。由于其社会意义，MML 在研究界站稳了脚跟，在过去十年中巩固了自己作为一个重要研究领域的地位。视<span style="background-color: #2ea8e580">觉语言预训练是MML的重要分支之一，旨在学习在各种视觉和语言任务上具有改进性能的多模态基础模型</span>。 Vision Transformer (ViT)（Dosovitskiy et al., 2021）<span style="background-color: #2ea8e580">是一项开创性的工作，贡献了端到端将 Transformers 的编码器应用于图像的解决方案。</span> CLIP（Radford et al., 2021）<span style="background-color: #2ea8e580">提出了一种方法，使用多模态预训练将分类转换为检索任务，使预训练模型能够解决零样本识别问题</span>。最近，LLaMA (Touvron et al., 2023)、BLOOM (Scao et al., 2022) 和 ChatGPT (OpenAI, 2022) 等 LLM 的进步得到了扩大训练数据和增加参数的支持，最近取得了重大成功。这些模型展示了令人印象深刻的语言理解、生成和知识推理能力，增强了它们理解自然语言和生成高质量、基于上下文的文本的能力。大型语言模型的发展刺激了自回归语言模型作为视觉语言任务中的解码器的广泛使用。<span style="background-color: #2ea8e580">利用跨模态迁移，这种方法可以实现语言和多模态领域之间的知识共享</span>（Gao et al., 2023; Liu et al., 2023; Li et al., 2023a; Ye et al., 2023; Zhu et al., 2023；Li 等人，2023b；Zhang 等人，2023）。</p><h3 id="2-2-Model-Editing"><a href="#2-2-Model-Editing" class="headerlink" title="2.2 Model Editing"></a>2.2 Model Editing</h3><p>     LLMs（Zhao et al., 2023）主要从训练语料库中获取知识。然而，数据集的质量并不总是得到保证，可能会将有害或不正确的信息集成到模型中（Hernandez 等人，2023）。<span style="background-color: #2ea8e580">一种解决方案是使用更新的知识重新训练模型，尽管这可能成本高昂且难以实施</span>。或者，<span style="background-color: #2ea8e580">可以考虑使用一些更新的事实进行微调，但它存在过度拟合和灾难性遗忘的风险</span>（Zhai et al., 2023）。为了解决这些问题，（Sinitsin et al., 2020）提出了模型编辑，旨在高效、准确地改变模型中存储的事实知识。这种方法应用于各个领域（Mao et al., 2023; Onoe et al., 2023; Xu et al., 2022b; Wang et al., 2023a; Li et al., 2023c），并且研究数量不断增加调查编辑的影响（Ilharco 等人，2023；Gupta 等人，2023；Hase 等人，2023；Cohen 等人，2023；Wu 等人，2023；Wang 等人，2023b；Gandikota 等人等人，2023；Li 等人，2023d）。目前，模型编辑方法主要有三种类型：<span style="background-color: #2ea8e580">1）元学习方法，2）定位然后编辑方法，3）上下文知识编辑方法。</span></p><p><strong>元学习方法</strong>。 MEND（Mitchell 等人，2022a）和知识编辑器 (KE)（Cao 等人，2021）提出了<span style="background-color: #2ea8e580">涉及外部编辑器的方法，能够学习用于知识更新的最佳参数集 θ，同时施加约束以保持模型稳定性。</span> CaliNET (Dong et al., 2022) 和 T-Patcher (Huang et al., 2023) 从 (Dai et al., 2022) 中汲取灵感，<span style="background-color: #2ea8e580">将额外的可训练参数引入到预训练语言模型的前馈模块中。</span> SERAC（Mitchell 等人，2022b）<span style="background-color: #2ea8e580">利用显式记忆来存储编辑，并学习对它们进行推理，以根据需要调整基本模型的预测。</span></p><p><strong>定位然后编辑方法</strong>。 ROME（Meng et al., 2022a）<span style="background-color: #2ea8e580">提出了采用因果中介分析来识别编辑区域的方法。</span> ROME 发现记忆的事实关联可以精确定位到 GPT 模型中的特定位置。然而，ROME 的一个显着限制是它一次只能编辑一个事实。为了解决这个问题，Meng 等人。 (2022b)提出了一种称为MEMIT的新方法，<span style="background-color: #2ea8e580">它是之前工作ROME的继承者，它对单层的MLP权重进行rankone修改，以将内存直接写入模型中。</span></p><p><strong>上下文知识编辑方法</strong>。 InContext Learning (ICL)（Brown et al., 2020）<span style="background-color: #2ea8e580">表示一种免训练范式，其中知识是从输入上下文中直接串联的演示中获取的</span>。最近出现了一种新颖的编辑范式，它<span style="background-color: #2ea8e580">利用LLMs理解上下文的能力（Zheng et al., 2023），从而实现基于上下文的模型编辑，指导模型的生成过程，并提供高效、轻量级的模型方法编辑</span>。迄今为止的模型编辑方法主要迎合单模态场景，在多模态编辑方面留下了空白。据我们所知，我们是第一个研究LLMs多模式模型编辑的人，并为促进该领域的研究提供了新的基准。</p><h2 id="3-Editing-Multimodal-LLMs"><a href="#3-Editing-Multimodal-LLMs" class="headerlink" title="3 Editing Multimodal LLMs"></a>3 Editing Multimodal LLMs</h2><p>我们在图 2 中说明了多模态编辑的建议任务。我们将介绍任务定义（§3.1）、（§3.2）中的数据集构建细节、多模态模型（§3.3）以及我们在实验。</p><p><img src="/../imgs/$%7Bfiilename%7D/KQ9KJ8DQ.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/KQ9KJ8DQ.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;KQ9KJ8DQ&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F5LR2L362%22%2C%22annotationKey%22%3A%22MS6FUQ8I%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%223%22%2C%22position%22%3A%7B%22pageIndex%22%3A2%2C%22rects%22%3A%5B%5B68.654%2C497.467%2C526.731%2C777.852%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FEQHAEIP8%22%5D%2C%22locator%22%3A%223%22%7D%7D&quot; width=&quot;763&quot; height=&quot;467&quot; src=&quot;attachments/KQ9KJ8DQ.png&quot; ztype=&quot;zimage&quot;&gt;"></p><h3 id="3-1-Task-Definition"><a href="#3-1-Task-Definition" class="headerlink" title="3.1 Task Definition"></a>3.1 Task Definition</h3><p>假设我们有一个由 *θ <em>参数化的多模态 LLM</em> f *（由两部分组成，由 θ<sub>vision</sub> 和 θ<sub>text</sub> 参数化的 f<sub>vision</sub> 和 f<sub>text </sub>），将输入 i<sub>e</sub> 和 x<sub>e</sub> 映射到 y<sub>o</sub> 的预测，其中 i<sub>e </sub>指的是编辑图像输入，xe 指的是编辑文本提示输入和 y<sub>o</sub> 表示为原始输出。我们将 M 表示为特定指标的符号表示，下标表示特定度量，上标表示变化编辑数据。我们准备第 3.2.1 节中所述的编辑数据集，其表示为 Dedit。受到姚等人的启发。 （2023），我们引入了一系列多模式模型编辑指标。</p><p><img src="/../imgs/$%7Bfiilename%7D/ZFVB46CA.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/ZFVB46CA.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;ZFVB46CA&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F5LR2L362%22%2C%22annotationKey%22%3A%22MJQK4385%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%224%22%2C%22position%22%3A%7B%22pageIndex%22%3A3%2C%22rects%22%3A%5B%5B64.853%2C526.008%2C292.5%2C791.596%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FEQHAEIP8%22%5D%2C%22locator%22%3A%224%22%7D%7D&quot; width=&quot;379&quot; height=&quot;442&quot; src=&quot;attachments/ZFVB46CA.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p><strong>可靠性</strong>。需要编辑可靠性才能将预测从 y<sub>o</sub> 更改为 y<sub>e</sub>。直观上，我们需要的是更新后的 θe，其中 f（即 x<sub>e</sub>;θ<sub>e</sub>）&#x3D; y<sub>e</sub>。为了衡量可靠性，我们使用编辑准确性，如下所述：</p><p><img src="/../imgs/$%7Bfiilename%7D/HSTRNPML.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/HSTRNPML.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;HSTRNPML&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F5LR2L362%22%2C%22annotationKey%22%3A%22NS7JGJWI%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%224%22%2C%22position%22%3A%7B%22pageIndex%22%3A3%2C%22rects%22%3A%5B%5B68.824%2C342.919%2C292.059%2C378.214%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FEQHAEIP8%22%5D%2C%22locator%22%3A%224%22%7D%7D&quot; width=&quot;372&quot; height=&quot;59&quot; src=&quot;attachments/HSTRNPML.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p>其中θ<sub>e</sub>指的是编辑后的参数。</p><p><strong>局部性</strong>。为了保持模型的稳定性，必须最大限度地减少编辑对模型更广泛的知识库造成的意外副作用。为了实现这一目标，我们引入了两个指标：M <sup>Text</sup> <sub>loc</sub> (T-Locality) 和 M<sup>Image</sup> <sub>loc</sub> (M-Locality)，这两个指标都是为了在编辑过程中保持模型的稳定性。鉴于多模态语言模型中的知识是从LLMs继承的，保护这些知识至关重要。考虑到这一目标，我们搁置了模型的视觉辨别模块，而是采用基本的问答数据集 D<sub>loc-t</sub>，如第 3.2.2 节中所述。我们定义问题为x，答案为y，如下：</p><p><img src="/../imgs/$%7Bfiilename%7D/J24EN8UP.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/J24EN8UP.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;J24EN8UP&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F5LR2L362%22%2C%22annotationKey%22%3A%22M2ZHI4QM%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%224%22%2C%22position%22%3A%7B%22pageIndex%22%3A3%2C%22rects%22%3A%5B%5B67.941%2C93.214%2C292.941%2C133.361%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FEQHAEIP8%22%5D%2C%22locator%22%3A%224%22%7D%7D&quot; width=&quot;375&quot; height=&quot;67&quot; src=&quot;attachments/J24EN8UP.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p>视觉编码器在多模态语言模型中发挥着关键作用，将将图像转换为矢量表示，以便与自然语言文本共同编码。</p><p><img src="/../imgs/$%7Bfiilename%7D/IPZFZHUW.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/IPZFZHUW.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;IPZFZHUW&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F5LR2L362%22%2C%22annotationKey%22%3A%22ZIQHSJG7%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%224%22%2C%22position%22%3A%7B%22pageIndex%22%3A3%2C%22rects%22%3A%5B%5B301.765%2C653.066%2C528.529%2C777.919%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FEQHAEIP8%22%5D%2C%22locator%22%3A%224%22%7D%7D&quot; width=&quot;378&quot; height=&quot;208&quot; src=&quot;attachments/IPZFZHUW.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p>因此，我们必须考虑对该模块进行任何修改的潜在后果。我们构建表示为 D<sub>loc-v</sub> 的数据集用于测试 MImage loc ，并计算如下：</p><p><img src="/../imgs/$%7Bfiilename%7D/4NC86SS7.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/4NC86SS7.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;4NC86SS7&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F5LR2L362%22%2C%22annotationKey%22%3A%22K2BYGI7E%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%224%22%2C%22position%22%3A%7B%22pageIndex%22%3A3%2C%22rects%22%3A%5B%5B302.647%2C522.478%2C532.941%2C557.772%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FEQHAEIP8%22%5D%2C%22locator%22%3A%224%22%7D%7D&quot; width=&quot;384&quot; height=&quot;59&quot; src=&quot;attachments/4NC86SS7.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p>其中（iv，xv，yv）是范围外数据，θe表示编辑数据更新的参数（即xe，ye)。</p><p><strong>泛化性</strong>。在整个编辑过程中，仅仅修改个别错误的输入是不够的。修订后的模型还应保留泛化能力，并始终为等效输入（例如改写的句子）生成一致的输出，如图 3 所示。虽然以前的单模态模型编辑任务仅需要考虑改写的文本，但多模态场景需要泛化以及图像。为了解决这个问题，我们引入了两个泛化考虑因素：MText gen (TGenerality) 和 MImage gen (M-Generality)，其表示如下：</p><p><img src="/../imgs/$%7Bfiilename%7D/BS3DHYZH.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/BS3DHYZH.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;BS3DHYZH&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F5LR2L362%22%2C%22annotationKey%22%3A%22SSPQQ5PC%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%224%22%2C%22position%22%3A%7B%22pageIndex%22%3A3%2C%22rects%22%3A%5B%5B303.088%2C236.596%2C527.206%2C296.596%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FEQHAEIP8%22%5D%2C%22locator%22%3A%224%22%7D%7D&quot; width=&quot;374&quot; height=&quot;100&quot; src=&quot;attachments/BS3DHYZH.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p>其中 ir 表示重新表述的图像，xr 指重新表述的文本提示，N (x) 表示 x 范围内的对象。</p><h3 id="3-2-Datasets"><a href="#3-2-Datasets" class="headerlink" title="3.2 Datasets"></a>3.2 Datasets</h3><p>我们构建的数据集MMEdit主要包含两个子任务：编辑VQA（E-VQA）和编辑图像标题（E-IC）。</p><h4 id="3-2-1-Reliability-Dataset-Construction"><a href="#3-2-1-Reliability-Dataset-Construction" class="headerlink" title="3.2.1 Reliability Dataset Construction"></a>3.2.1 Reliability Dataset Construction</h4><p>为了对我们的实验进行基准测试，我们选择了两个常见的多模态任务：视觉问答（VQA）（Antol et al., 2015）和图像</p><p><img src="/../imgs/$%7Bfiilename%7D/TT279E4N.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/TT279E4N.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;TT279E4N&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F5LR2L362%22%2C%22annotationKey%22%3A%229KCXYY3D%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%225%22%2C%22position%22%3A%7B%22pageIndex%22%3A4%2C%22rects%22%3A%5B%5B60%2C488.39%2C297%2C778.39%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FEQHAEIP8%22%5D%2C%22locator%22%3A%225%22%7D%7D&quot; width=&quot;395&quot; height=&quot;483&quot; src=&quot;attachments/TT279E4N.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p>字幕（Herdade 等人，2019）。 <span style="background-color: #2ea8e580">VQA 旨在设计一种算法，不仅可以理解图像中的视觉内容，还可以理解用于查询该图像的自然语言，并随后生成这些查询的精确答案</span>。<span style="background-color: #2ea8e580">图像字幕是设计能够理解图像视觉内容的算法，随后用自然语言生成连贯且精确的图像描述</span>。在本研究中，我们选择 BLIP-2 OPT。我们的基础编辑数据源自两个评估数据集的次优条目，即 VQAv2（Goyal 等人，2017）和 COCO Caption（Chen 等人，2015)。</p><p>     除了基本的编辑数据之外，利用其他数据也至关重要。这些数据不仅有助于编辑过程，还验证更改的有效性，评估模型编辑的稳定性和通用性。</p><h4 id="3-2-2-Locality-Dataset-Construction"><a href="#3-2-2-Locality-Dataset-Construction" class="headerlink" title="3.2.2 Locality Dataset Construction"></a>3.2.2 Locality Dataset Construction</h4><p>我们必须仔细考虑多模态模型中编辑对语言功能的影响，<span style="background-color: #5fb23680">类似于我们如何评估手术后个体大脑的各个认知区域。</span></p><p><strong>文本局部性数据集</strong>。为了评估语言模型的稳定性，我们利用之前在 MEND 中使用的 NQ 数据集（Kwiatkowski 等人，2019）作为模型内 LLM 组件稳定性的基准。我们专门使用模型的输出预编辑和后期编辑来构建 KL 散点图，从而促进对模型编辑的约束。此外，我们还计算了保持 top-1 状态的实例比例，进一步量化了模型的稳定性。</p><p><strong>多模态局部性数据集</strong>。同样，验证编辑对视觉模块的影响也至关重要。因此，我们在多模态领域使用简单的数据集 OK-VQA（Marino 等人，2019），作为多模态视觉模块局部性的度量。我们再次在编辑过程之前和之后使用 logits 更新 KL 离散度约束。</p><h4 id="3-2-3-Generality-Dataset-Construction"><a href="#3-2-3-Generality-Dataset-Construction" class="headerlink" title="3.2.3 Generality Dataset Construction"></a>3.2.3 Generality Dataset Construction</h4><p>我们在多模态模型中提出了两种形式的通用性。共性数据集构建的整体流程如图4所示。</p><p><strong>文本泛化数据集</strong>。值得注意的是，LLMs表现出强大的会话能力和强大的解决问题的能力，这使我们能够制定任务指令，从而指导模型生成类似的文本输入。对于 E-VQA 任务，我们利用 ChatGLM（Du et al., 2022；Zeng et al., 2022）生成类似的查询。然而，对于E-IC任务，由于提示的简洁和相对直接，模型生成的输出质量并不令人满意。因此，我们采用手动编写的包含20条提示的模板来随机替换原来的提示。</p><p><strong>视觉泛化数据集</strong>。近年来，<span style="background-color: #2ea8e580">扩散模型（Ho et al., 2020）在图像生成领域取得了巨大成功。超越最初最先进的模型</span>：生成对抗网络（GAN）模型（Goodfellow 等人，2014）。扩散模型在许多图像生成任务中表现出色，并在各个应用领域中表现出了值得称赞的性能。<span style="background-color: #2ea8e580">稳定扩散（Rombach 等人，2022）是一种潜在的文本到图像扩散模型，能够根据给定的文本输入生成逼真的图像</span>。我们利用稳定扩散 2.1 来生成重新解释的图像。该数据集利用 COCO 数据集的标题描述来评估模型的图像泛化能力。</p><h3 id="3-3-Multimodal-Language-Models"><a href="#3-3-Multimodal-Language-Models" class="headerlink" title="3.3 Multimodal Language Models"></a>3.3 Multimodal Language Models</h3><p><strong>BLIP-2 OPT</strong>。 BLIP-2（Li et al., 2023b）<span style="background-color: #2ea8e580">是一种通用且高效的预训练策略，可从现成的冻结预训练图像编码器和冻结大型语言模型引导视觉语言预训练。该模型利用轻量级查询转换器来弥合视觉模态和文本模态之间的差距，并在各种视觉语言任务上实现最先进的性能</span>。我们选择 BLIP-2 OPT 作为基本编辑模型，它在视觉模块中利用 ViT-L，并选择无监督训练的 OPT 模型用于基于解码器的 LLM。迷你GPT-4。</p><p><strong>MiniGPT-4</strong>（Zhu et al., 2023）是一种类似于 BLIP-2 的有效视觉语言模型，利用冷冻视觉编码器与冷冻 Vicuna（Chiang et al., 2023）相结合。据报道，基于 LLaMA 构建的 Vicuna 根据 GPT-4 的评估标准达到了 ChatGPT 90% 的性能。 MiniGPT-4 添加了一个投影层，以使编码的视觉特征与 Vicuna 语言模型保持一致。 MiniGPT-4 采用与 BLIP-2 相同的预训练视觉组件，由 EVA-CLIP（Sun 等人，2023）的 Vit-G&#x2F;14 和 Q-Former 组成。</p><h3 id="3-4-Baselines"><a href="#3-4-Baselines" class="headerlink" title="3.4 Baselines"></a>3.4 Baselines</h3><p><strong>Finetune</strong>。微调已成为一种广泛采用的策略，用于使预训练的语言模型适应特定任务或领域（Cortes 等人，2015）。在我们的探索中，我们深入研究了两种不同的微调方法：一种专注于语言模型的最后一层。以BLIP-2 OPT模型为例，我们对OPT模型的第31个解码器层进行微调。另一个目标是多模态语言模型中的视觉块，具体来说，我们微调 Q-former 模型以过度拟合编辑数据集。</p><p><strong>MEND</strong>。具有梯度分解的模型编辑器网络（Mitchell 等人，2022a）使用单个输入输出对对语言模型进行高效的本地编辑。本质上，MEND 学习转换微调 LLM 的梯度，它利用梯度的低秩分解。</p><p><strong>KE</strong>。 KE（Cao et al., 2021）是一种可以编辑语言模型中错误知识而无需重新训练整个模型的方法。 KE 利用具有约束优化的超网络（双向 LSTM），用于预测推理过程中的权重更新。</p><p><strong>SERAC</strong>。 SERAC（Mitchell 等人，2022b）引入了一种基于内存的模型编辑方法，该方法利用显式内存系统来缓存编辑。该内存随后用于在推理过程中调整基本模型的输出。该系统利用一个小型辅助范围分类器和反事实模型。范围分类器的作用是确定输入是否在内存缓存的范围内。如果在此范围内找到输入，则会将其与最相关的缓存项结合起来，并输入到反事实模型中进行预测。</p><p>**In-Context Knowledge Editing.**。上下文知识编辑（IKE）（Zheng et al., 2023）构造 k 个演示 C &#x3D; {c1, . 。 。 , ck }，遵循 Liu 等人中概述的方法。 （2022）。该方法采用基于余弦相似度的无监督检索器，在将事实 f &#x3D; (x*, y*) 注入语言模型之前从训练集中获取演示。 x* 是探索模型中事实知识的提示（例如，美国总统是），y* 将是编辑目标乔·拜登。上下文演示的排名也取决于余弦相似度：cos(c1, f ) &lt; cos(c2, f ) &lt; · · · &lt; cos(ck, f )。其中 c1, . 。 。 , ck 在上下文中从左到右顺序排列。演示 C 可以被视为外部增强的知识库，主要设计用于指导 LM 内的生成。其最终目标是当提示符x落在目标提示符x*的编辑范围内时，最大化P(y|x,f,C)。</p><h2 id="4-Experiments"><a href="#4-Experiments" class="headerlink" title="4 Experiments"></a>4 Experiments</h2><h3 id="4-1-Results"><a href="#4-1-Results" class="headerlink" title="4.1 Results"></a>4.1 Results</h3><p>在这一部分中，我们对 MMEdit 上的多种编辑方法进行了比较分析。这些比较的结果如表2所示。之后，我们深入研究了实验结果的三个指标，包括可靠性、局部性和通用性三个方面。此外，我们通过文本和视觉方式分析局部性和通用性，并在图 6 中提供了几个编辑案例。</p><p><strong>可靠性</strong>。从结果来看，<span style="background-color: #ff666680">所有模型编辑方法在可靠性方面均优于基本方法</span>。特别是，<span style="background-color: #ff666680">利用外部存储器进行编辑的 IKE 和 SERAC 方法在多模态语言中表现出了值得称赞的性能楷模</span>。我们<span style="background-color: #ff666680">观察到微调方法的性能比模型编辑方法差</span>。请注意，<span style="background-color: #5fb23680">仅微调 LLM 或模态融合模块的参数并不能充分捕获多模态数据的特征</span>。我们分析原因为如下：<span style="background-color: #5fb23680">用于微调的数据与原始模型有较大差异，例如Q-former和OPT模型，需要有效协作。简单地微调这些模块之一可能无法准确捕获特定于任务的特征。另一方面，微调所有模块会产生大量的资源开销</span>。此外，<span style="background-color: #ff666680">根据我们的实验结果，我们观察到微调可能会导致原始模型发生重大变化，通常会导致其他知识的丢失，在多模式数据集中尤其明显。</span></p><p><img src="/../imgs/$%7Bfiilename%7D/WSEXRRE8.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/WSEXRRE8.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;WSEXRRE8&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F5LR2L362%22%2C%22annotationKey%22%3A%229DEQKYBI%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%227%22%2C%22position%22%3A%7B%22pageIndex%22%3A6%2C%22rects%22%3A%5B%5B68.077%2C533.813%2C530.769%2C783.044%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FEQHAEIP8%22%5D%2C%22locator%22%3A%227%22%7D%7D&quot; width=&quot;771&quot; height=&quot;415&quot; src=&quot;attachments/WSEXRRE8.png&quot; ztype=&quot;zimage&quot;&gt;"><br><strong>局部性</strong>。<span style="background-color: #ff666680">几种传统的编辑方法仍然适用于多模式编辑</span>，这对于有效修改模型内的知识并纠正其输出很有价值。然而，IKE和SERAC尽管在可靠性方面表现出色，但由于缺乏对M-Locality的约束而在M-Locality上表现不佳，<span style="background-color: #5fb23680">这表明尽管这些基于外部存储器的编辑技术无疑成功地修复了输出，但它们在稳定内部模型中的知识还有改进的空间。</span>对于T-Locality，大多数模型编辑方法都获得了良好的性能，而IKE再次表现不佳。根本原因是其他三种方法对T-Locality施加了约束，而IKE作为InContext Learning方法缺乏鲁棒的约束机制，导致性能不佳。</p><p><strong>泛化</strong>。我们在 E-VQA 中与 MiniGPT-4 进行了各种方法的文本和图像泛化能力的比较探索。请注意，<span style="background-color: #ff666680">KE 往往表现出较低程度的图像泛化，这主要是由于其在训练阶段对 M 局部性的固有考虑。</span>因此，<span style="background-color: #ff666680">与基于记忆的方法相比，元学习方法的图像泛化效率往往较低。另一方面，基于内存的方法所表现出的卓越图像泛化能力是以牺牲 M-Locality 为代价实现的，导致 M-Locality 水平显着降低。</span>通过对各种编辑方法的评估，<span style="background-color: #5fb23680">我们经常发现图像泛化性能往往不如文本泛化性能强大。</span></p><p><img src="/../imgs/$%7Bfiilename%7D/QNQGNXI7.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/QNQGNXI7.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;QNQGNXI7&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F5LR2L362%22%2C%22annotationKey%22%3A%227YT8KPYF%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%228%22%2C%22position%22%3A%7B%22pageIndex%22%3A7%2C%22rects%22%3A%5B%5B54.231%2C457.659%2C540.577%2C782.467%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FEQHAEIP8%22%5D%2C%22locator%22%3A%228%22%7D%7D&quot; width=&quot;811&quot; height=&quot;542&quot; src=&quot;attachments/QNQGNXI7.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p><img src="/../imgs/$%7Bfiilename%7D/CPEZX96N.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/CPEZX96N.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;CPEZX96N&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F5LR2L362%22%2C%22annotationKey%22%3A%2293WRHX5J%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%228%22%2C%22position%22%3A%7B%22pageIndex%22%3A7%2C%22rects%22%3A%5B%5B55.962%2C212.467%2C303.462%2C451.89%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FEQHAEIP8%22%5D%2C%22locator%22%3A%228%22%7D%7D&quot; width=&quot;413&quot; height=&quot;400&quot; src=&quot;attachments/CPEZX96N.png&quot; ztype=&quot;zimage&quot;&gt;"></p><h3 id="4-2-Editing-Different-Component"><a href="#4-2-Editing-Different-Component" class="headerlink" title="4.2 Editing Different Component"></a>4.2 Editing Different Component</h3><p>我们进一步分析了编辑多模态模型不同区域的变化。与编辑单模态模型相比，由于多模态模型的复杂性和多样性，我们可以尝试编辑更多模块并分析它们对视觉和文本知识的影响。结果如图 7 所示。对于 BLIP-2 OPT 模型，我们研究了在 VQA 数据集上编辑 Q-former 和 OPT 的区别。关于MiniGPT4模型，我们主要关注llama_proj和Vicuna模型在编辑最后几层的区别。选择的分析编辑方法有 MEND、KE 和 FT，这使我们能够指定编辑区域。</p><p>     结果表明，<span style="background-color: #5fb23680">编辑视觉模块比编辑语言模块更具挑战性（另请参阅图 6 中的失败编辑）。我们认为这种困难可能归因于模型的架构</span>。<span style="background-color: #ff666680">编辑LLM的最后一层可以直接修改输出，而修改视觉模块只影响LLM的输入，对模型的影响相对较小</span>。具体来说，<span style="background-color: #5fb23680">各种模态驻留在不同的空间中，这意味着事实知识可以存储在模型内的单独参数中</span>。考虑到LLMs拥有大量参数，这一点对于多模态模型变得更加重要。因此，编辑语言模型可以显着提高性能。值得注意的是，模型中的视觉模块在图像理解中起着至关重要的作用，<span style="background-color: #5fb23680">因此表明未来的工作需要同时考虑来自不同模式的信息。</span></p><h2 id="5-Conclusion"><a href="#5-Conclusion" class="headerlink" title="5 Conclusion"></a>5 Conclusion</h2><p>在本文中，我们介绍了多模式模型编辑，以及新的基准 MMEdit。根据经验，我们分析了各种模型编辑基线的有效性，并探索它们对不同组件（例如视觉和文本）的影响。</p><h2 id="6-Limitations"><a href="#6-Limitations" class="headerlink" title="6 Limitations"></a>6 Limitations</h2><p><strong>楷模</strong>。我们只编辑几个基本的多模式LLMs，留下许多其他的。此外，由于资源限制，我们编辑的多模态LLM的参数数量低于10B，我们无法编辑具有更多参数的LLM，例如65B LLaMA Adapter V2（Gao et al., 2023） 。</p><p><strong>高效的视觉编辑</strong>。在本文中，我们的分析主要集中于比较不同模式模块中现有编辑方法的不同效果。然而，结果并不令人满意。展望未来，我们的主要目标是探索如何跨其他模式高效、准确地编辑信息。这包括研究技术，<span style="background-color: #5fb23680">例如通过查明多模态模型内的知识并识别需要修改的内容来在不同模态之间进行共同编辑。</span></p>]]></content>
      
      
      <categories>
          
          <category> NLP顶会 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> EMNLP2023 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>我们可以通过情景学习来编辑事实知识吗？</title>
      <link href="/2023/11/02/wo-men-ke-yi-tong-guo-qing-jing-xue-xi-lai-bian-ji-shi-shi-zhi-shi-ma/"/>
      <url>/2023/11/02/wo-men-ke-yi-tong-guo-qing-jing-xue-xi-lai-bian-ji-shi-shi-zhi-shi-ma/</url>
      
        <content type="html"><![CDATA[<h1 id="我们可以通过情景学习来编辑事实知识吗？"><a href="#我们可以通过情景学习来编辑事实知识吗？" class="headerlink" title="我们可以通过情景学习来编辑事实知识吗？"></a>我们可以通过情景学习来编辑事实知识吗？</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>之前的研究表明，像 GPT 这样的大型语言模型 (LLM) 在其参数中存储了大量事实知识。然而，存储的知识可能是错误的或过时的。传统的知识编辑方法通过对包含特定知识的文本进行微调来完善LLMs。然而，随着LLMs规模的不断扩大，这些基于梯度的方法带来了巨大的计算成本。模型即服务的趋势也使得修改黑盒 LM 中的知识变得不可能。<span style="background-color: #ff666680">受到上下文学习（ICL）这种基于演示上下文而无需参数更新的新范式的启发</span>，我们探索 ICL 是否可以编辑事实知识。为了回答这个问题，我们对 ICL 策略进行了全面的实证研究。实验表明，<span style="background-color: #ff666680">与 GPT-J (6B) 上基于梯度的方法相比，上下文知识编辑 (IKE) 在没有任何梯度和参数更新的情况下实现了有竞争力的成功率，但副作用要少得多，包括减少对相似但不相关事实的过度编辑以及更少的对先前存储的知识的遗忘</span>。我们还将该方法应用于具有数十或数百个参数的大型 LM，例如 OPT-175B，这显示了我们方法的可扩展性。该代码可在<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FLB4642KE%22%2C%22pageLabel%22%3A%221%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B233.271%2C260.191%2C273.121%2C269.098%5D%2C%5B87.874%2C248.236%2C225.359%2C257.143%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F8YZC667S%22%5D%2C%22locator%22%3A%221%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/LB4642KE?page=1">“https:&#x2F;&#x2F; github.com&#x2F;PKUnlp-icler&#x2F;IKE.”</a></span></p><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h2><p>预训练语言模型 (LM) 为 NLP 研究树立了新范式，并席卷了所有现有的 NLP 基准。由于取得了令人鼓舞的成果，研究人员为 LM 赋予了满足现实世界需求的新技能，例如使用网络浏览器（Nakano 等人，2021）、编码（Chen 等人，2021）、玩策略游戏（FAIR 等人） al.，2022）和对话人才（OpenAI，2022、2023）。然而，语言模型的广泛应用也引发了人们对其生成虚假内容的陷阱的日益关注（Elazar et al., 2021；Cao</p><p><img src="/../imgs/$%7Bfiilename%7D/M6YKHBS2.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/M6YKHBS2.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;M6YKHBS2&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FLB4642KE%22%2C%22annotationKey%22%3A%22FY8NBQWF%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B302.763%2C474.785%2C526.974%2C629.522%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F8YZC667S%22%5D%2C%22locator%22%3A%221%22%7D%7D&quot; width=&quot;374&quot; height=&quot;258&quot; src=&quot;attachments/M6YKHBS2.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p>等人，2021a）、过时（Dhingra 等人，2022）、有偏见（Sheng 等人，2019；Zhao 等人，2021）和攻击性（Gehman 等人，2020）。为了缓解这一缺陷，旨在修改语言学习者所学到的知识的知识编辑（图 1）引起了越来越多的关注（Mitchell 等人，2022a；Meng 等人，2022a)。知识编辑的目标有两个：概括性和特异性。前者需要泛化到描述相同知识的各种提示，后者则不需要干扰其他不相关的知识。</p><p>     以往的知识编辑方法主要采用<span style="background-color: #2ea8e580">基于梯度的方法来修改特定的模型参数以获得所需的模型行为</span>（Mitchell等，2021；Meng等，2022a），例如在选举后更新总统。然而，<span style="background-color: #5fb23680">目标知识神经元的识别通常需要计算开销很大的梯度估计</span>（Dai et al., 2022）。此外，<span style="background-color: #2ea8e580">更新的参数本身会导致超出所需版本的副作用，例如忘记以前学到的事实或对不相关事实进行过度编辑</span>。先前的研究表明，当大规模 LM (LLM) 作为黑盒服务部署时（Sun 等人，2022），<span style="background-color: #2ea8e580">对其参数的微小修改可能会极大地影响其最终用户的行为</span>。因此，传统方法仍然受到编辑 LLM arXiv:2305.12740v1 [cs.CL] 202 年 5 月 22 日的困扰，因为这些限制阻碍了可扩展性和通用性。</p><p>     最近，情境学习（ICL）（Brown et al., 2020）已成为指导LLMs执行复杂任务的新范式。在 <span style="background-color: #2ea8e580">ICL 中，任务描述和演示示例以自然语言表示以形成上下文，并且以上下文为条件的 LM 预测根据预定义规则转换为答案</span>（Brown 等人，2020）。通过这种方式，大型 LM 无需对参数进行任何修改即可适应各种下游任务，使其自然适合大型 LM 上的知识编辑。首先，它通过避免修改参数来减少计算开销，并消除参数更新带来的副作用的风险。最重要的是，<span style="background-color: #2ea8e580">ICL 为人类提供了一种可解释的方式来校准 LM 行为</span>。尽管有这些优点，ICL 是否适用于知识编辑仍不清楚。</p><p>     在本文中，我们研究了 ICL 为LLMs进行知识编辑的潜力。我们专注于两个目标：（1）确保泛化，以便大型语言模型可以泛化到多个文本表面以获取更新的知识；（2）通过对目标知识事实进行准确修改，同时保留其他不相关事实，确保特异性。为了同时实现这些目标，我们设计了演示格式和组织策略，以构建合适的上下文学习演示，以指导LLMs的知识编辑。我们定义了三种类型的演示格式化模板，包括<span style="background-color: #ff666680">（i）复制，旨在将新事实注入语言模型； (ii) 更新，提高注入知识事实的泛化能力； (iii) 保留，指导语言模型保留不相关的知识事实。此外，为了充分利用 ICL 进行知识编辑的潜力，我们从训练语料库中检索相关知识事实作为演示输入。</span> GPT-J（6B）知识编辑基准的实验结果表明，所提出的上下文学习知识编辑（IKE）在强基线下实现了整体可比的知识编辑性能。例如，IKE 的编辑成功率绝对优于 MEND（Mitchell 等人，2021）10％，并且在特异性方面比 ROME 获得了 30 分的增益（Meng 等人，2022a）。由于没有参数修改，IKE适用于OPT-175B等LLM，并表现出更好的记忆能力，即编辑后，近50%的知识事实保留了较高的概率。进一步的分析表明，<span style="background-color: #ff666680">演示选择和保留演示有助于特异性，而更新演示则提高泛化能力</span>。最后，我们讨论了IKE在实际场景中应用时可能遇到的潜在挑战，并提供了相应的讨论。总的来说，这项研究的贡献有四个方面：</p><ul><li>据我们所知，这项工作代表了对 ICL 编辑 LM 知识潜力的首次系统探索。</li><li>我们对ICL 策略进行全面的实证研究，并分析这些策略如何影响最终性能。</li><li>通过设计适当的演示格式和组织策略，IKE 可以以更少的计算开销和副作用实现相当的成功率。</li><li>我们研究将IKE 应用到现实场景的可行性并讨论潜在的挑战。</li></ul><h2 id="2-Related-Work"><a href="#2-Related-Work" class="headerlink" title="2 Related Work"></a>2 Related Work</h2><p>**知识编辑方法 **最近关于知识编辑的研究大多是基于炒作网络或基于归因的。基于炒作网络的方法训练超网络以获得某些编辑的梯度变化。例如，曹等人。 （2021b）使用超网络来预测测试时的参数变化，这会改变事实，同时保留不相关的事实。 MEND（Mitchell 等人，2022a）学会了将原始微调梯度转换为梯度的低秩分解。米切尔等人。 （2022b）使用编辑记忆检索器和反事实模型来生成，而不更新基本模型的参数。基于归因的方法定位神经网络中某些知识的神经元激活，仅更新相关参数。戴等人。 （2022）使用基于梯度的归因评估了不同神经元对特定知识的贡献，并通过用缩放的嵌入向量替换多层感知器（MLP）权重矩阵中的列来更新或删除事实。孟等人。 (2022a)定位了表达事实知识的单层，并通过在MLP模块中编写新的键值对来编辑这些事实知识。</p><p><strong>知识编辑基准</strong> 一些知识编辑基准通常用于评估编辑方法的有效性和特异性。对于 BERT 风格的模型，通常采用事实检查数据集 FEVER (Thorne et al., 2018) 和问答数据集 zsRE (Levy et al., 2017)。在 FEVER 中，每个 x 是一个声明，每个 y 表示相应声明的有效性。在 zsRE 中，每个 x 都是关于事实的问题，每个 y 都是答案，而 xloc 询问与 x 无关的事实。对于 GPT 风格的模型，Mitchell 等人。 (2022a) 引入了维基文本编辑数据集，该数据集要求模型完成带有编辑延续的段落，同时每个标记的分布与不相关的段落 xloc 应保持不变。在我们的实验中，我们使用了一个更具挑战性的 QA 数据集，称为 COUNTERFACT（Meng 等人，2022a）。在 COUNTERFACT 中，问题 x 的编辑答案 y 有时可能与现实世界反事实，并且不相关的超出范围的样本 xloc 比 zsRE 中的困难得多，这使得模型更难预测所需的答案。此外，预先训练的LLMs很难捕获这些所需的事实，从而避免了LLMs在编辑之前了解这些知识的影响。</p><p><strong>情境学习</strong> 情境学习 (ICL) 是一种免训练范例，可从输入情境中串联的演示中学习。给定相关示例和查询，模型通过类比学习来做出预测（Brown 等人，2020；Liu 等人，2022）。现有的知识编辑方法需要重新计算梯度或者以廉价的方式计算并执行这样的知识编辑。斯等人。 （2022）首次探讨了情境学习是否可以更新LLMs的知识，并表明结合各种演示可以提高知识编辑的成功率。然而，他们只关注GPT-3，而没有深入探索知识编辑的潜在能力和副作用。</p><h3 id="3-Task-Formulation"><a href="#3-Task-Formulation" class="headerlink" title="3 Task Formulation"></a>3 Task Formulation</h3><p>知识编辑的目标是通过最大化概率 PM(y*|x*) 来将新事实 (x*, y*) 注入到 LMM 中。 x*是探究M中事实知识的提示（例如，美国总统是），y*将是编辑目标乔·拜登。知识编辑还需要概括性和特异性：</p><ul><li><strong>泛化</strong>：对于编辑中的提示x的范围 Dx*（即与新事实相关的提示），x ∈ Dx* 的预测也应该更新为 y*。例如，预测问题：谁是美国总统？答：将更新为乔·拜登。</li><li><strong>特异性</strong>：对于提示x 超出编辑范围，x &#x2F; ε Dx*，x 的预测应该是它原来的预测yo。例如，俄罗斯总统的预测应该保留。</li></ul><h2 id="4-Method-IKE"><a href="#4-Method-IKE" class="headerlink" title="4 Method: IKE"></a>4 Method: IKE</h2><h3 id="4-1-In-Context-Learning"><a href="#4-1-In-Context-Learning" class="headerlink" title="4.1 In-Context Learning"></a>4.1 In-Context Learning</h3><p>情境学习（ICL）是由 Brown 等人提出的。 （2020）用于小样本学习。对于大型语言模型 M，ICL 的目标是根据 k 个演示 C &#x3D; {(x1, y1),… 来预测输入 x 的 ˆ y ∈ Y，而无需进行任何参数更新。 。 。 ，（xk，yk）}。语言模型 M 预测给定 x 的 y ∈ Y 的概率：PM(y | x, C)。更具体地说，ICL 使用模板 T 将输入和标签转换为自然语言文本。以情感分析为例，输入 xi 和标签 yi 的上下文演示将转换为句子：xi。情感：yi，那么语言模型 M 将在给定 T (x1, y1), 的情况下预测 y ∈ Y。 。 。 ，T（xk，yk），T（x，）。</p><h3 id="4-2-In-Context-Knowledge-Editing"><a href="#4-2-In-Context-Knowledge-Editing" class="headerlink" title="4.2 In-Context Knowledge Editing"></a>4.2 In-Context Knowledge Editing</h3><p>当我们将目标事实 f &#x3D; (x*, y*) 注入 LM 时，我们将构造 k 个演示 C &#x3D; {c1,…。 。 。 ，ck}。知识编辑的目标是当提示x在目标提示x*的编辑范围内时最大化P(y*|x,f,C)，并且最小化P(y*|x,f,C)之间的距离。 | x, f, C) 和 P (y | x) 当 x &#x2F; ∈ Dx* （特异性目标）时。 LM 应确定探测提示 x 是否在 x* 的编辑范围内，即 Dx*。为了通过 ICL 实现这些目标，适当的演示输入至关重要。我们进一步将以f为目标的知识编辑演示构建分解为两个子问题：</p><p>（i）如何设计每个演示的格式； (ii) 如何选择上下文演示并对其进行排名（Dong 等人，2023）。</p><h4 id="4-2-1-Demonstration-Formating"><a href="#4-2-1-Demonstration-Formating" class="headerlink" title="4.2.1 Demonstration Formating"></a>4.2.1 Demonstration Formating</h4><p>每个演示 ci 都包含一个新事实 fi &#x3D; (xi*, y* i )、一个探测提示 xi 及其预测 yi。上下文演示应该教会 LM 复制、更新和保留针对不同提示的预测：</p><ul><li><strong>复制</strong>：要将新事实注入 LM，第一步是教他们将目标提示的预测复制到新事实中。在复制演示中，xi &#x3D; xi* 且 yi &#x3D; y* i。</li><li><strong>更新</strong>：知识编辑不仅仅是教语言模型重复新事实。为了知识编辑的泛化，编辑范围内提示的预测也应该更新。在更新演示中，xi ∈ Dx* i 且 yi &#x3D; y* i。</li><li><strong>保留</strong>：出于知识编辑的特殊性，语言模型应在超出范围的提示中保留其原始预测。在保留演示中，xi &#x2F; ∈ Dx* i 和 yi 应该是它的原始答案 yo i。 IKE 的模板 T 将 f 、 x 和 y 转换为自然语言：T (f, x, y) &#x3D; New Fact: f 。提示：xy。详细信息列于§A。</li></ul><h4 id="4-2-2-Demonstration-Organization"><a href="#4-2-2-Demonstration-Organization" class="headerlink" title="4.2.2 Demonstration Organization"></a>4.2.2 Demonstration Organization</h4><p>当我们在 LM 中编辑知识事实 f 时，我们构建 k 个演示 C &#x3D; {c1,… 。 。 , ck} 来自训练语料库。哪些演示适合上下文编辑？我们关注刘等人。 （2022）使用无监督检索器来选择 k 个最近邻居。更具体地说，我们使用预训练的句子编码器 E 对新事实 f 的提示 x* 及其原始答案 yo 和目标预测 y* 进行编码。这</p><p><img src="/../imgs/$%7Bfiilename%7D/ZLL8JITP.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/ZLL8JITP.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;ZLL8JITP&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FLB4642KE%22%2C%22annotationKey%22%3A%228PRW9YFQ%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%224%22%2C%22position%22%3A%7B%22pageIndex%22%3A3%2C%22rects%22%3A%5B%5B302.885%2C681.505%2C530.769%2C775.544%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F8YZC667S%22%5D%2C%22locator%22%3A%224%22%7D%7D&quot; width=&quot;380&quot; height=&quot;157&quot; src=&quot;attachments/ZLL8JITP.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p>训练语料库中的记录将以相同的方式进行编码，并根据余弦相似度检索 k-NN 事实。上下文演示的排名还取决于余弦相似度：cos(c0, f ) &lt; cos(c1, f ) &lt; 。 。 。 &lt; cos(ck, f )，其中 c1, . 。 。 , ck 从左到右放置在上下文中。</p><h3 id="4-3-Discussion-Gradient-based-methods-and-gradient-free-methods"><a href="#4-3-Discussion-Gradient-based-methods-and-gradient-free-methods" class="headerlink" title="4.3 Discussion:Gradient-based methods and gradient-free methods"></a>4.3 Discussion:Gradient-based methods and gradient-free methods</h3><p>之前的参数更新方法会调整LM M的参数θ。它们根据梯度∇θ − log PM(y*|x*)计算Δθ，将基础模型Mθ更新为编辑后的M′θ+Δθ。然后将通过 PM′(y | x) 评估编辑方法。相反，上下文学习通过为新事实 f &#x3D; (x*, y*) 构建演示 C 来修改 M 中的知识事实，然后通过 PM(y | x, f, C) 来评估编辑方法。将 PM(y | x, f, C) 与 PM′(y | x) 进行比较，可以发现： (i) ICL 不需要对目标事实进行梯度估计，并且在知识编辑后保持原始 LM M 不变。这大大减少了计算开销，从而使编辑适用于具有万亿级参数的LM，并消除了修改参数的副作用。 (ii) 演示 C 以自然文本表示，比显着参数更新 Δθ 更容易解释。它提供了一个人类可理解的界面来校准模型行为。我们在表 1 中重点介绍了这两种方法的特点。</p><h2 id="5-Experiment"><a href="#5-Experiment" class="headerlink" title="5 Experiment"></a>5 Experiment</h2><p>在本节中，我们通过实验来回答以下研究问题：</p><ul><li>与基于梯度的方法相比，IKE 的性能如何？</li><li>演示设计策略如何影响IKE 的性能</li><li>LM 的规模如何影响IKE 的性能，IKE 能否扩展到具有数百或数千亿参数的大型语言模型？</li><li>知识编辑有哪些副作用？与其他参数更新方法相比，IKE 产生的副作用是多还是少？</li></ul><p>     我们首先介绍实验设置，包括比较基线方法、评估基准和不同尺度的语言模型，用于知识编辑（第 5.1 节）。然后我们分析了§5.2中的主要知识编辑结果以及情境学习知识编辑的影响因素（§5.3）。</p><h3 id="5-1-Experimental-Setting"><a href="#5-1-Experimental-Setting" class="headerlink" title="5.1 Experimental Setting"></a>5.1 Experimental Setting</h3><p>我们的目标是评估上下文知识编辑与参数更新方法相比的性能。我们还对不同大小的语言模型进行了实验，以探索上下文知识编辑的扩展能力。</p><h4 id="5-1-1-基线"><a href="#5-1-1-基线" class="headerlink" title="5.1.1 基线"></a>5.1.1 基线</h4><p>遵循之前的知识编辑方法，我们还选择 GPT-J (6B) 作为我们的主要评估骨干。比较的基线包括：</p><p><strong>FT</strong> 在描述编辑事实的文本上微调基本模型，而无需通过应用 Adam 提前停止来训练新的模型编辑器。</p><p><strong>MEND</strong> MEND（Mitchell 等人，2022a）通过使用预训练的超网络将权重矩阵分解为rank-1 形式来转换更新事实的微调梯度。</p><p><strong>ROME</strong> ROME（Meng et al., 2022a）学习定位一组特定 MLP 模块的事实检索，并通过直接在 MLP 模块中写入新的键值对来更新知识。</p><p><strong>PROMPT</strong> 探索上下文演示如何影响 IKE 的性能。我们直接使用新事实作为上下文，通过 P(y|x, f ) 来探测 LM，其中 f &#x3D; (x*, y*)。实施细节见§A</p><h4 id="5-1-2-Evaluation-Setup"><a href="#5-1-2-Evaluation-Setup" class="headerlink" title="5.1.2 Evaluation Setup"></a>5.1.2 Evaluation Setup</h4><p><strong>模型</strong> 为了探索 LM 的规模将如何影响上下文知识编辑的有效性，我们在五个类似 GPT 的自回归转换器语言模型上评估了上下文知识编辑，其规模范围从 1.5B 到 175B 参数：</p><ul><li>GPT- 2 XL (1.5B)（Radford 等人，2019），GPT-2 的 15 亿参数版本。</li><li>GPT-NEO (2.7B)（Gao 等人，2021），EleutherAI 发布的类 GPT-2 因果语言模型的 27 亿参数版本。它是在专门为 LLM 训练设计的 Pile 数据集上进行训练的。</li><li>GPT-J (6B)（Wang 和 Komatsuzaki，2021），一种在具有 60 亿个参数的 Pile 上训练的自回归文本生成模型。</li><li>GPT-NEOX (20B)（Black 等人，2022），一个在 Pile 上训练的 200 亿参数自回归语言模型。</li><li>OPT (175B)（Zhang 等人，2022），开放式预训练 Transformer，由 MetaAI 创建，具有 1750 亿个参数。</li></ul><p><strong>基准</strong> 我们主要评估 COUNTERFACT 的基线（Meng et al., 2022a），这是一个具有挑战性的基准，适用于具有困难编辑目标和难以区分编辑范围的类 GPT 因果语言模型。它包含 21, 919 条不同关系和实体的记录。每条记录的目标是将知识三元组（s*，r*，oc）更改为（s*，r*，o*），其中s*和r*由目标提示x*描述。该记录还包含释义提示 P P 作为范围内提示和邻域提示 P N ，即与目标三元组共享同一对象的知识三元组（s′，r*，oc）作为范围外提示。我们关注孟等人。 (2022a) 使用前 2000 条记录作为测试集，其余记录分为训练集。 COUNTERFACT 的详细信息在 §B 中列出。</p><p><strong>指标</strong> 知识编辑的性能从三个方面来衡量（有效性、泛化性和特异性）。</p><ul><li>**功效 **通过功效得分 (ES, E[I[P(o*) &gt; P(oc)]]) 和功效幅度 (EM, E[P(o*) − P( oc）]）。</li><li>**泛化 **通过释义衡量释义提示的译后编辑准确性分数 (PS) 和释义幅度 (PM)。 PS和PM的定义与ES和EM类似。</li><li>**特异性 **通过邻域得分 (NS, E[I[P(oc) &gt; P(o*)]]) 和邻域量级 (NM, E[P(oc) − P(o*)]) 来衡量邻域提示的准确性，因为邻域提示 (s′, r*, oc) 与目标提示共享相同的原始对象，并且这些事实不应被编辑。</li></ul><p>我们也关注孟等人。 (2022a) 将 ES、PS、NS 的调和平均值报告为分数 (S)</p><p><img src="/../imgs/$%7Bfiilename%7D/QTYQT47T.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/QTYQT47T.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;QTYQT47T&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FLB4642KE%22%2C%22annotationKey%22%3A%22JKFNHCLD%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%226%22%2C%22position%22%3A%7B%22pageIndex%22%3A5%2C%22rects%22%3A%5B%5B64%2C569.39%2C535%2C784.89%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F8YZC667S%22%5D%2C%22locator%22%3A%226%22%7D%7D&quot; width=&quot;785&quot; height=&quot;359&quot; src=&quot;attachments/QTYQT47T.png&quot; ztype=&quot;zimage&quot;&gt;"></p><h3 id="5-2-Main-Results"><a href="#5-2-Main-Results" class="headerlink" title="5.2 Main Results"></a>5.2 Main Results</h3><p>表2的顶行显示了不同方法的知识编辑结果。我们的研究结果是：（i）所有方法在功效方面都表现良好，正如它们接近的 ES 分数所示。然而，在普遍性和特殊性方面存在显着差异。例如，FT 获得了较高的 ES (99.9) 和 PS (96.4) 分数，但在特异性方面表现不佳。这凸显了知识编辑中平衡泛化和特殊性的挑战。 (ii) 在基线方法中，ROME 在所有三个指标方面总体表现最好，但计算开销较高。由于这一限制，它不适用于诸如 OPT175B 等更迫切需要知识编辑的大型 LM。 (iii) 所提出的方法 IKE 在特异性方面表现出色，但在有效性和泛化方面也表现良好。例如，IKE 在 GPTJ 上获得了与 ROME 相当的总分（89.6 比 91.5），同时不需要任何参数对 LM 的修改。这种计算优势使得在 OPT-175B 等大型 LM 上执行知识编辑成为可能，其中 IKE 比 PROMPT 明显提高了 36.0 个点。这些结果证明了 IKE 在知识编辑方面的有效性、效率和可扩展性。</p><p><img src="/../imgs/$%7Bfiilename%7D/P6MNIS5S.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/P6MNIS5S.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;P6MNIS5S&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FLB4642KE%22%2C%22annotationKey%22%3A%22GWHX8CHK%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%226%22%2C%22position%22%3A%7B%22pageIndex%22%3A5%2C%22rects%22%3A%5B%5B303.158%2C339.39%2C531.316%2C561.232%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F8YZC667S%22%5D%2C%22locator%22%3A%226%22%7D%7D&quot; width=&quot;380&quot; height=&quot;369&quot; src=&quot;attachments/P6MNIS5S.png&quot; ztype=&quot;zimage&quot;&gt;"></p><h3 id="5-3-Analysis"><a href="#5-3-Analysis" class="headerlink" title="5.3 Analysis"></a>5.3 Analysis</h3><p>在这一部分中，我们讨论不同演示策略的效果、跨尺度模型的 IKE 可扩展性以及知识编辑引入的副作用。</p><h4 id="5-3-1Ablation-on-Demonstration"><a href="#5-3-1Ablation-on-Demonstration" class="headerlink" title="5.3.1Ablation on Demonstration"></a>5.3.1Ablation on Demonstration</h4><p><strong>演示次数</strong> 演示次数是 ICL 性能的影响因素之一 (Brown et al., 2020)。我们研究了演示数量如何影响第二阶段的 IKE 性能</p><p><img src="/../imgs/$%7Bfiilename%7D/HKQ4CHLZ.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/HKQ4CHLZ.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;HKQ4CHLZ&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FLB4642KE%22%2C%22annotationKey%22%3A%22MUQZEW2N%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%227%22%2C%22position%22%3A%7B%22pageIndex%22%3A6%2C%22rects%22%3A%5B%5B63.947%2C615.706%2C292.895%2C778.732%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F8YZC667S%22%5D%2C%22locator%22%3A%227%22%7D%7D&quot; width=&quot;382&quot; height=&quot;272&quot; src=&quot;attachments/HKQ4CHLZ.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p>表 3 中的块。在没有任何演示的情况下，PROMPT 因其低 NS（37.9）而表现出过度泛化，表明它只是学习复制预测。给定一些演示（4 或 8)，IKE 在有效性和泛化性方面比 PROMPT 表现更差，因为它开始区分提示是否在编辑范围内。随着演示次数的增加，IKE逐渐学会平衡通用性和特殊性，实现更好的权衡。</p><p>**演示组织 **先前的研究（Liu et al., 2022; Rubin et al., 2022; Lu et al., 2022）表明，包括演示选择和演示排序（Dong et al., 2023）在内的演示组织对于 ICL 也至关重要。我们的建议遵循刘等人的简单无监督方法。 （2022），根据输入提示和演示之间的余弦相似度从训练语料库中检索和排序演示。在表 3 第三块中的两项消融研究中，我们发现删除选择程序（即随机选择）会导致 NS 分数从 77.0 明显下降到 45.0，这表明正确提示选择的重要性。然而，随机排序带来的性能差异可以忽略不计。我们推测这是因为所选的提示与目标事实高度相关，并且基于 Transformer 的 LM 中的注意力机制可以很好地处理长程依赖性。我们将进一步的改进作为未来的工作。</p><p>**演示格式 **我们进一步检查演示类型的影响，包括复制、更新和保留。如表 3 中的第四个块所示，删除复制演示会导致性能轻微下降，因为即使没有复制演示，LM 也可以轻松复制演示中的内容。相反，更新演示在教导 LM 修改其知识方面发挥着重要作用，删除更新演示后泛化得分要差得多。此外，删除保留演示会导致特异性急剧下降（通过 NM 分数衡量），从 35.2 降至 -47.6。这表明保留演示对于帮助 LM 识别超出范围的事实并维持对这些提示的原始预测至关重要。</p><h4 id="5-3-2IKE-Benefits-from-Model-Scaling"><a href="#5-3-2IKE-Benefits-from-Model-Scaling" class="headerlink" title="5.3.2IKE Benefits from Model Scaling"></a>5.3.2IKE Benefits from Model Scaling</h4><p>我们进一步评估了 COUNTERFACT 上的 IKE，针对不同尺度的五种类似 GPT 的因果语言模型。正如之前的实验表明，所有方法都表现出很高的知识编辑功效，因此我们重点关注大型语言模型的泛化性和特异性，因为这些指标的定义是为了衡量可能对最终用户造成巨大影响的副作用。如表 4 所示，我们发现 IKE 的性能与 LM 的规模正相关，并且最大的 OPT-175B 实现了最强的泛化和特异性结果。这是令人鼓舞的，因为 IKE 的性能可以随着 LM 规模的增加而增强，使其可插入未来更强大的 LM 主干。</p><h4 id="5-3-3Resilience-to-Over-Editing"><a href="#5-3-3Resilience-to-Over-Editing" class="headerlink" title="5.3.3Resilience to Over-Editing"></a>5.3.3Resilience to Over-Editing</h4><p>过度编辑是知识编辑的常见副作用，指在编辑目标事实时对超出范围的事实产生影响。尽管 COUNTERFACT 已经包含由 (s′, r*, oc) 组成的范围外提示，它们与编辑目标共享相同的关系 r 和原始对象 oc： (s*, r*, oc) → (s*, r*, o*），我们采用Dong等人提出的对比知识评估（CKA）对过度编辑进行更全面的评估。 （2022）。具体来说，对于一个三元组（s，r，o），CKA将r替换为其他相似但不相关的关系r′，并比较PM（o | s，r）和PM（o | s，r′）来评估M是否知道事实（s，r，o）。受此启发，我们将(s*,r’,o*)视为相似但不相关的提示，并考虑P(o*|s*,r’)的变化，发现P(o*|s*,r’ ）在注入（s*，r*，o*）后也会增加。为了进一步探索不同方法中的过度编辑，我们考虑 CKA 分数 P(o*|s*, r*)&#x2F;Er′∈RP(o*|s*, r′)。</p><p><img src="/../imgs/$%7Bfiilename%7D/A9BSU2NB.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/A9BSU2NB.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;A9BSU2NB&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FLB4642KE%22%2C%22annotationKey%22%3A%22W3GR7IZZ%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%228%22%2C%22position%22%3A%7B%22pageIndex%22%3A7%2C%22rects%22%3A%5B%5B61.731%2C622.082%2C298.269%2C782.467%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F8YZC667S%22%5D%2C%22locator%22%3A%228%22%7D%7D&quot; width=&quot;394&quot; height=&quot;267&quot; src=&quot;attachments/A9BSU2NB.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p><img src="/../imgs/$%7Bfiilename%7D/JRUG4L94.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/JRUG4L94.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;JRUG4L94&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FLB4642KE%22%2C%22annotationKey%22%3A%22V8EL5CWL%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%228%22%2C%22position%22%3A%7B%22pageIndex%22%3A7%2C%22rects%22%3A%5B%5B304.038%2C646.313%2C529.038%2C781.89%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F8YZC667S%22%5D%2C%22locator%22%3A%228%22%7D%7D&quot; width=&quot;375&quot; height=&quot;226&quot; src=&quot;attachments/JRUG4L94.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p>CKA评估结果如表5所示。如果CKA得分小于预定义阈值α，则正确事实的困惑度为输给了对比虚假事实的困惑，结果证明这是一次编辑失败。尽管所有基线在编辑功效方面都表现良好，但在更严格的对比评估下它们往往过于概括。 ROME 的平均 CKA 得分最低，错误率最高，这表明它识别与目标提示共享同一主题的范围外提示的能力较差。 IKE 对过度编辑的影响较小。</p><h4 id="5-3-4Maintenance-for-Original-Knowledge"><a href="#5-3-4Maintenance-for-Original-Knowledge" class="headerlink" title="5.3.4Maintenance for Original Knowledge"></a>5.3.4Maintenance for Original Knowledge</h4><p>我们得出的结论是，先前存储在语言模型中的事实知识将在知识编辑过程中被删除或遗忘。我们在表6中考虑编辑前后P(oc|s*, r)的变化。结果表明，所有编辑方法都会导致P(oc|s*, r*)的下降。罗马几乎忘记了所有最初的事实。如果我们想要纠正 LM 的预测，就必须擦除原来的事实知识。然而，如果我们想更新语言模型的预测，例如更新美国总统是从唐纳德·特朗普到乔·拜登的预测（时间感知关系），那么旧知识 2017 年，美国总统是唐纳德·特朗普不应该被忘记。</p><p>    为了评估编辑中这种时间感知知识的遗忘，我们基于 TEMPLAMA (Dhingra et al., 2022) 构建了一个小型基准，以进一步表明 IKE 比 §C 中的其他基准可以导致更少的知识遗忘。</p><h2 id="6-Discussions"><a href="#6-Discussions" class="headerlink" title="6 Discussions"></a>6 Discussions</h2><p>在之前的实验中，我们遵循孟等人之前研究的设置。 （2022a）并主要评估编辑单个事实以进行公平比较的方法。我们的结果表明 IKE 可以获得更好的泛化性和特异性，副作用更少，并且不需要修改参数。尽管如此，为了探讨可行性在将 IKE 应用到现实场景中时，有几个重要问题尚未得到充分探索：(1) IKE 能否扩展以容纳更多的编辑事实？考虑到语言模型的输入长度有限，在上下文中包含大量的编辑事实可能是不可行的。 (2) IKE 能否适应处理不同格式和域的事实和提示？在IKE中，事实和提示的域和格式保持一致。然而，在现实世界中，事实和提示有多种形式。米切尔等人。 (2022b)提出了一种基于检索的方法来编辑多个知识事实。类似地，具有外部存储器来存储事实编辑的 IKE 可以检索正确的事实编辑来构建给定提示的上下文，从而避免永远在上下文中预先添加所有事实编辑。为了验证 IKE 对不同形式的事实或提示的泛化，我们用维基百科中的中性数据替换了事实，或者用生成提示替换了提示，提示 LM 生成与新对象相关的文本。详细讨论可以在§D 中找到。</p><h2 id="7-Conclusion"><a href="#7-Conclusion" class="headerlink" title="7 Conclusion"></a>7 Conclusion</h2><p>在这项工作中，我们研究了上下文学习在大规模语言模型上进行知识编辑的潜力。具体来说，我们设计了提示LM的演示策略，包括三种类型的演示格式和基于检索的演示组织。我们表明，所提出的方法 IKE 在不需要任何参数修改的情况下实现了竞争性知识编辑功效，并保持了良好的泛化和特异性性能。进一步的分析证明了它对于大型 LM 的可扩展性、对过度编辑问题的弹性以及通过多轮编辑维护时间感知知识事实的能力。我们的结果证明 ICL 在 LM 知识编辑方面具有巨大潜力。</p>]]></content>
      
      
      <categories>
          
          <category> NLP顶会 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> EMNLP2023 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>编辑大型语言模型：问题、方法和机遇</title>
      <link href="/2023/11/02/bian-ji-da-xing-yu-yan-mo-xing-wen-ti-fang-fa-he-ji-yu/"/>
      <url>/2023/11/02/bian-ji-da-xing-yu-yan-mo-xing-wen-ti-fang-fa-he-ji-yu/</url>
      
        <content type="html"><![CDATA[<h1 id="编辑大型语言模型：问题、方法和机遇"><a href="#编辑大型语言模型：问题、方法和机遇" class="headerlink" title="编辑大型语言模型：问题、方法和机遇"></a>编辑大型语言模型：问题、方法和机遇</h1><h2 id="Abstruct"><a href="#Abstruct" class="headerlink" title="Abstruct"></a>Abstruct</h2><p>尽管有能力培养有能力的LLMs，但维持其相关性和纠正错误的方法仍然难以捉摸。为此，过去几年见证了LLMs编辑技术的激增，其<span style="background-color: #2ea8e580">目标是有效地改变特定领域内LLMs的行为，而不会对其他输入的性能产生负面影响</span>。本文深入探讨了LLMs模型编辑相关的问题、方法和机遇。特别是，我们<span style="background-color: #ff666680">对任务定义和与模型编辑相关的挑战进行了详尽的概述，并对我们目前掌握的最先进的方法进行了深入的实证分析</span>。我们还<span style="background-color: #ff666680">构建了一个新的基准数据集，以促进更稳健的评估并查明现有技术固有的持久问题</span>。我们的目标是为每种编辑技术的有效性和可行性提供有价值的见解，从而帮助社区做出明智的决定，为特定任务或上下文选择最合适的方法。</p><h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h1><p>大型语言模型（LLM）已经表现出理解和生成类人文本的非凡能力（Brown et al., 2020；OpenAI, 2023；Anil et al., 2023；Touvron et al., 2023；Qiao et al., 2022；赵等人，2023）。尽管LLMs的训练非常熟练，但确保其相关性和修复错误的策略仍不清楚。理想情况下，随着世界形势的发展，我们的目标是更新LLMs，避免与训练全新模型相关的计算负担。如图1所示，解决这个问题模型编辑的概念被提出</p><p><img src="/../imgs/$%7Bfiilename%7D/SWBFWKDL.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/SWBFWKDL.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;SWBFWKDL&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F9227ERUC%22%2C%22annotationKey%22%3A%226BF2NSVY%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B300.5%2C490.39%2C533%2C628.89%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FCU5SMQAC%22%5D%2C%22locator%22%3A%221%22%7D%7D&quot; width=&quot;388&quot; height=&quot;231&quot; src=&quot;attachments/SWBFWKDL.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p>（Sinitsin 等人，2020；De Cao 等人，2021），<span style="background-color: #2ea8e580">能够对模型的行为进行数据有效的改变，特别是在指定的感兴趣领域内，同时确保不会对其他输入产生不利影响。</span>目前，大量关于LLMs模型编辑的工作（De Cao et al., 2021；Meng et al., 2022, 2023；Sinitsin et al., 2020；Huang et al., 2023)在各种编辑任务和设置方面取得了长足的进步。如图 2 所示，<span style="background-color: #2ea8e580">这些工作通过将辅助网络与原始未更改的模型集成或更改导致不良输出的模型参数来操纵特定情况下的模型输出。</span>尽管文献中存在广泛的模型编辑技术，但<span style="background-color: #5fb23680">明显缺乏在统一实验条件下评估这些方法的全面比较分析。缺乏直接比较会削弱我们辨别每种方法相对优缺点的能力，从而阻碍我们理解它们在不同问题领域的适应性。</span></p><p>     为了解决这个问题，本研究致力于建立一个标准的问题定义，并对这些方法进行细致的评估（§2，§3）。我们在规定的条件下进行实验，促进对各自的优缺点进行公正的比较（§4）。<span style="background-color: #2ea8e580">我们最初使用两个流行的模型编辑数据集，ZsRE (Levy et al., 2017) 和 COUNTERFACT (Meng et al., 2022)，以及两个结构上的数据集不同的语言模型，T5（Raffel et al.，2020a）（编码器-解码器）和 GPT-J（Wang 和 Komatsuzaki，2021a）（仅解码器）作为我们的基础模型</span>。我们还评估了较大模型 OPT-13B（Zhang 等人，2022a）和 GPT-NEOX20B（Black 等人，2022）的性能。除了基本编辑设置之外，我们还评估批量和顺序编辑的性能。虽然我们观察到当前的方法在事实模型编辑任务中表现出当大的能力，但<span style="background-color: #2ea8e580">我们重新考虑当前的评估并创建一个更具包容性的评估数据集（§5）：可移植性（强大的泛化能力）、局部性（副作用）和效率（时间）和内存使用情况）</span>。我们发现当前的模型编辑方法在这些层面上有所限制，从而限制了它们的实际应用，未来值得更多的研究。通过系统评估，我们的目标是为每种模型编辑技术的有效性提供有价值的见解，帮助研究人员为特定任务选择合适的方法。</p><h2 id="2-Problem-Definition"><a href="#2-Problem-Definition" class="headerlink" title="2 Problem Definition"></a>2 Problem Definition</h2><p>模型编辑，由 Mitchell 等人阐明。 （2022b），<span style="background-color: #2ea8e580">旨在有效地调整特定编辑描述符（xe，ye）上的初始基础模型（fθ，θ表示模型的参数）行为，而不影响其他样本上的模型行为</span>。最终目标是创建一个编辑模型，表示为 fθe。具体来说，基本模型 fθ 由函数 f : X → Y 表示，该函数将输入 x 与其相应的预测 y 相关联。给定一个由编辑输入 xe 和编辑标签 ye 组成的编辑描述符，使得 fθ(xe) ̸&#x3D; ye，后期编辑模型 fθe 被设计为产生预期输出，其中 fθe(xe) &#x3D; ye。</p><p>     <span style="background-color: #2ea8e580">模型编辑过程通常会影响与编辑示例密切相关的大量输入的预测。这个输入集合称为编辑范围。</span>成功的编辑应该调整编辑范围内示例的模型行为，同时保持范围外示例的性能不变：</p><p><img src="/../imgs/$%7Bfiilename%7D/YCQJYKA2.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/YCQJYKA2.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;YCQJYKA2&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F9227ERUC%22%2C%22annotationKey%22%3A%22WCMI8DSD%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%222%22%2C%22position%22%3A%7B%22pageIndex%22%3A1%2C%22rects%22%3A%5B%5B70.5%2C136.39%2C291.5%2C183.39%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FCU5SMQAC%22%5D%2C%22locator%22%3A%222%22%7D%7D&quot; width=&quot;368&quot; height=&quot;78&quot; src=&quot;attachments/YCQJYKA2.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p>范围内 I(xe, ye) 通常包含 xe 及其等价邻域 N (xe, ye)，其中包括相关的输入&#x2F;输出对。相反，超出范围的 O(xe, ye) 由与编辑示例无关的输入组成。模型fe应该满足以下三个属性：可靠性、泛化性和局部性。</p><p><strong>可靠性</strong> 先前的工作（Huang et al., 2023；De Cao et al., 2021；Meng et al., 2022）定义了当后期编辑模型 fθe 给出案例 (xe, ye) 的目标答案时的可靠编辑被编辑。可靠性以编辑案例的平均准确度来衡量：</p><p><img src="/../imgs/$%7Bfiilename%7D/Q3XB8E8H.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/Q3XB8E8H.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;Q3XB8E8H&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F9227ERUC%22%2C%22annotationKey%22%3A%22WHB9Z2XR%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%222%22%2C%22position%22%3A%7B%22pageIndex%22%3A1%2C%22rects%22%3A%5B%5B302.5%2C616.89%2C530%2C650.39%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FCU5SMQAC%22%5D%2C%22locator%22%3A%222%22%7D%7D&quot; width=&quot;379&quot; height=&quot;56&quot; src=&quot;attachments/Q3XB8E8H.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p><strong>泛化</strong> 编辑后模型 fθe 还应该编辑等效邻居 N (xe, ye)（例如改写的句子)。它是通过模型 fθe 在从等价邻域中均匀抽取的示例上的平均精度来评估的：</p><p><img src="/../imgs/$%7Bfiilename%7D/TSPLLYFE.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/TSPLLYFE.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;TSPLLYFE&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F9227ERUC%22%2C%22annotationKey%22%3A%22ICM3VKEP%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%222%22%2C%22position%22%3A%7B%22pageIndex%22%3A1%2C%22rects%22%3A%5B%5B305%2C503.39%2C527%2C538.89%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FCU5SMQAC%22%5D%2C%22locator%22%3A%222%22%7D%7D&quot; width=&quot;370&quot; height=&quot;59&quot; src=&quot;attachments/TSPLLYFE.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p>**局部性 **在一些工作中，也被称为特异性。编辑应该在本地实现，这意味着编辑后模型 fθe 不应更改范围外 O(xe, ye) 中不相关示例的输出。因此，局部性是通过编辑后模型 fθe 的预测与编辑前 fθ 模型相同的来评估的</p><p><img src="/../imgs/$%7Bfiilename%7D/88F6ZZTR.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/88F6ZZTR.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;88F6ZZTR&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F9227ERUC%22%2C%22annotationKey%22%3A%22KH34VUGC%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%222%22%2C%22position%22%3A%7B%22pageIndex%22%3A1%2C%22rects%22%3A%5B%5B306.5%2C364.39%2C527%2C401.39%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FCU5SMQAC%22%5D%2C%22locator%22%3A%222%22%7D%7D&quot; width=&quot;368&quot; height=&quot;62&quot; src=&quot;attachments/88F6ZZTR.png&quot; ztype=&quot;zimage&quot;&gt;"></p><h3 id="3-Current-Methods"><a href="#3-Current-Methods" class="headerlink" title="3 Current Methods"></a>3 Current Methods</h3><p>目前LLMs的模型编辑方法可以分为两种主要范式，如图2所示：<span style="background-color: #2ea8e580">修改模型参数或保留模型参数。</span>更多比较见表 6。</p><h3 id="3-1-Methods-for-Preserving-LLMs-Parameters"><a href="#3-1-Methods-for-Preserving-LLMs-Parameters" class="headerlink" title="3.1 Methods for Preserving LLMs Parameters"></a>3.1 Methods for Preserving LLMs Parameters</h3><p>**基于内存的模型 **<span style="background-color: #2ea8e580">这种方法将所有编辑示例显式存储在内存中，并使用检索器为每个新输入提取最相关的编辑事实，以指导模型生成编辑事实。 </span>SERAC（Mitchell 等人，2022b）提出了一种采用独特的反事实模型，同时保持原始模型不变的方法。具体来说，<span style="background-color: #2ea8e580">它采用范围分类器来计算新输入落入存储的编辑示例范围内的可能性。如果输入与内存中任何缓存的编辑相匹配，则反事实模型的预测将基于输入和最可能的编辑。否则，如果输入超出了所有编辑的范围，给出了原始模型的预测。</span>此外，<span style="background-color: #5fb23680">最近的研究表明LLMs拥有强大的情境学习能力。模型本身可以生成与所提供的知识相对应的输出，而不是求助于用新事实训练的额外模型，并给出精炼的知识上下文作为提示。</span><span style="background-color: #2ea8e580">这种方法通过用编辑后的事实提示模型并从编辑记忆中检索编辑演示来编辑语言模型</span>，包括以下工作：MemPrompt (Madaan et al., 2022)、IKE (Zheng et al., 2023) 和MeLLo（Zhong 等人，2023）。</p><p><img src="/../imgs/$%7Bfiilename%7D/Y5M6Y7UX.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/Y5M6Y7UX.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;Y5M6Y7UX&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F9227ERUC%22%2C%22annotationKey%22%3A%226XZYF4BM%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%223%22%2C%22position%22%3A%7B%22pageIndex%22%3A2%2C%22rects%22%3A%5B%5B79%2C517.39%2C515%2C782.89%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FCU5SMQAC%22%5D%2C%22locator%22%3A%223%22%7D%7D&quot; width=&quot;727&quot; height=&quot;443&quot; src=&quot;attachments/Y5M6Y7UX.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p>**附加参数 **<span style="background-color: #2ea8e580">此范例在语言模型中引入了额外的可训练参数。这些参数在修改后的知识数据集上进行训练，而原始模型参数保持静态。</span> T-Patcher（Huang et al., 2023）在模型前馈网络（FFN）的最后一层针对一个错误集成了一个神经元（补丁），仅在遇到其对应错误时才生效。 CaliNET（Dong et al., 2022）整合了多个神经元以用于多个编辑案例。不同的是，GRACE（Hartvigsen et al., 2022）维护一个离散的密码本作为适配器，随着时间的推移添加和更新元素以编辑模型的预测。</p><h3 id="3-2-Methods-for-Modifying-LLMs-Paramete"><a href="#3-2-Methods-for-Modifying-LLMs-Paramete" class="headerlink" title="3.2 Methods for Modifying LLMs Paramete"></a>3.2 Methods for Modifying LLMs Paramete</h3><p>该范例将更新部分参数 θ，它应用更新 Δ 矩阵来编辑模型。</p><p>**定位然后编辑 **<span style="background-color: #2ea8e580">该范例首先识别与特定知识相对应的参数，并通过直接更新目标参数来修改它们。</span>知识神经元（KN）方法（Dai et al., 2022）<span style="background-color: #2ea8e580">引入了知识归因技术来精确定位体现知识的“知识神经元”（FFN 矩阵中的键值对），然后更新这些神经元。 </span>ROME（Meng et al., 2022）<span style="background-color: #2ea8e580">应用因果中介分析来定位编辑区域。 ROME 不是修改 FFN 中的知识神经元，而是改变整个矩阵。 ROME 将模型编辑视为具有线性等式约束的最小二乘法，并使用拉格朗日乘子来求解。</span>然而，<span style="background-color: #2ea8e580">KN 和 ROME 一次只能编辑一个事实关联。</span>为此，<span style="background-color: #2ea8e580">MEMIT（Meng et al., 2023）对ROME的设置进行了扩展，实现了多病例同步编辑的情况。</span>基于 MEMIT，PMET（Li et al., 2023a）涉及注意力值以获得更好的性能。</p><p><strong>元学习</strong> <span style="background-color: #2ea8e580">元学习方法采用超网络来学习编辑 LLM 所需的 Δ</span>。<span style="background-color: #2ea8e580">知识编辑器（KE）（De Cao et al., 2021）利用超网络（特别是双向 LSTM）来预测每个数据点的权重更新，从而能够在不干扰其他知识的情况下对编辑目标知识进行约束优化</span>。然而，这种方法在编辑LLMs方面存在不足。为了克服这个限制，<span style="background-color: #2ea8e580">模型编辑器网络梯度分解（MEND）（Mitchell et al., 2022a）学习通过采用梯度的低秩分解来变换微调语言模型的梯度，这可以应用于具有更好性能的LLM。</span></p><h2 id="4-Preliminary-Experiments"><a href="#4-Preliminary-Experiments" class="headerlink" title="4 Preliminary Experiments"></a>4 Preliminary Experiments</h2><p>考虑到大量以事实知识为中心的研究和数据集，我们将其用作主要比较基础。我们最初的对照实验使用两个著名的事实知识数据集（表 1）进行，促进了方法的直接比较，突出了它们独特的优势和局限性（Wang 等人，2023b）。</p><h3 id="4-1-Experiment-Setting"><a href="#4-1-Experiment-Setting" class="headerlink" title="4.1 Experiment Setting"></a>4.1 Experiment Setting</h3><p>我们使用两个著名的模型编辑数据集：ZsRE 和 COUNTERFACT，其详细信息请参见附录 B。以前的研究通常使用较小的语言模型 (&lt;1B)，并证明了当前编辑方法在 BERT 等较小模型上的有效性（Devlin 等人， 2019）。然而，这些方法是否适用于更大的模型仍有待探索。因此，考虑到编辑任务和未来的发展，我们专注于基于生成的模型并选择更大的模型：T5-XL（3B）和GPT-J（6B），代表编码器-解码器和仅解码器结构。</p><p>     我们从每种方法类型中选择了有影响力的作品。除了现有的模型编辑技术之外，我们还检查了微调的结果，这是模型更新的基本方法。为了避免重新训练所有层的计算成本，我们采用了Meng等人提出的方法。 (2022)，由 ROME 识别的微调层，我们将其表示为 FT-L。该策略确保与其他直接编辑进行公平比较方法，增强我们分析的有效性。更多详细信息请参见附录 A。</p><h3 id="4-2-Experiment-Results"><a href="#4-2-Experiment-Results" class="headerlink" title="4.2 Experiment Results"></a>4.2 Experiment Results</h3><p>基本模型表 1 <span style="background-color: #ff666680">揭示了 SERAC 和 ROME 在 ZsRE 和 COUNTERFACT 数据集上的卓越性能，SERAC 在多个指标上超过 90%。虽然 MEMIT 缺乏通用性，但它在可靠性和局部性方面表现出色。 KE、CaliNET 和 KN 表现不佳，在较小的模型中表现尚可，但在较大的模型中表现平平。 MEND 在这两个数据集上表现良好，在 T5 上的结果达到了 80% 以上，尽管不如 ROME 和 SERAC 那样令人印象深刻。 T-Patcher 模型的性能因模型架构和大小的不同而有所不同。例如，它在 ZsRE 数据集的 T5-XL 上表现不佳，而在 GPT-J 上表现完美。在 COUNTERFACT 数据集的情况下，T-Patcher 在 T5 上实现了令人满意的可靠性和局部性，但缺乏泛化性。相反，在 GPT-J 上，该模型在可靠性和泛化性方面表现出色，但在局部性方面表现不佳。</span><span style="background-color: #5fb23680">这种不稳定性可归因于模型架构，因为 T-Patcher 在 T5 的最终解码器层添加了一个神经元；</span><span style="background-color: #ff666680">然而，编码器可能仍然保留原始知识。 FT-L 在 PLM 上的表现不如 ROME，即使修改相同的位置。它在 ZsRE 数据集上显示出令人印象深刻的性能，但在 GPT-J 上的 COUNTERFACT 数据集上与 ROME 的可靠性和泛化能力相当。然而，其较低的局部性得分表明对不相关知识领域的潜在影响。 IKE 表现出良好的可靠性，但在局部性方面遇到困难，因为预先设置的提示可能会影响不相关的输入。它的泛化能力也可以提高。情境学习</span></p><p><img src="/../imgs/$%7Bfiilename%7D/B7WY2DBH.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/B7WY2DBH.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;B7WY2DBH&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F9227ERUC%22%2C%22annotationKey%22%3A%22AYAJST64%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%225%22%2C%22position%22%3A%7B%22pageIndex%22%3A4%2C%22rects%22%3A%5B%5B67%2C654.39%2C531.5%2C770.39%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FCU5SMQAC%22%5D%2C%22locator%22%3A%225%22%7D%7D&quot; width=&quot;774&quot; height=&quot;193&quot; src=&quot;attachments/B7WY2DBH.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p>该方法可能会遇到上下文调解失败的问题（Hernandez et al., 2023)，因为预先训练的语言模型可能无法始终生成与提示对齐的文本。</p><p><strong>模型缩放</strong> 由于计算限制，我们使用更大的模型进行实验，在 OPT-13B 和 GPT-NEOX-20B 上测试 IKE、ROME 和 MEMIT。结果（表 2）令人惊讶地<span style="background-color: #ff666680">显示 ROME 和 MEMIT 在 GPT-NEOX-20B 模型上表现良好，但在 OPT-13B 上表现不佳。这是由于这两种方法都依赖于矩阵求逆运算。然而，在 OPT-13B 模型中，矩阵是不可逆的。</span>我们甚至根据经验发现，<span style="background-color: #5fb23680">用最小二乘法逼近解会产生不令人满意的结果。我们认为这是 ROME 和 MEMIT 的局限性，因为它们不能应用于不同的模型。</span> <span style="background-color: #ff666680">MEMIT 由于依赖多层矩阵计算而表现较差，并且对于较大模型，其可靠性和泛化性比 ROME 下降得更多。 IKE 的性能受到模型本身的上下文学习能力的影响。 OPT的结果比GPT-J的结果还要差，这可能归因于OPT本身的上下文学习能力。</span><span style="background-color: #5fb23680">此外，随着模型大小的增加，其泛化和局部性的性能都会下降。</span></p><p><strong>批量编辑</strong> 鉴于许多研究通常将更新限制为几十个事实或仅关注单个编辑案例，我们进行了进一步的批量编辑分析。然而，通常需要同时修改具有多个知识片段的模型。我们重点关注支持批量编辑的方法（FT、SERAC、MEND 和 MEMIT），并在图 3 中展示了它们的性能。值得注意的是，<span style="background-color: #ff666680">MEMIT 支持LLMs的大规模知识编辑，允许以最少的时间和内存进行数百甚至数千个同时编辑成本。其在可靠性和泛化方面的性能在最多 1000 次编辑时仍然保持稳健，但局部性在此级别下降。而 FT-L、SERAC、和MEND还支持批量编辑，它们需要大量内存来处理更多情况，超出了我们当前的能力。因此，我们将测试限制为 100 次编辑。 SERAC 可以完美地进行最多 100 次编辑的批量编辑。 MEND 和 FT-L 在批量编辑中的性能并不那么强，随着编辑数量的增加，模型的性能迅速下降。</span></p><p><img src="/../imgs/$%7Bfiilename%7D/WVMGDVMU.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/WVMGDVMU.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;WVMGDVMU&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F9227ERUC%22%2C%22annotationKey%22%3A%22UTUV86Q8%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%225%22%2C%22position%22%3A%7B%22pageIndex%22%3A4%2C%22rects%22%3A%5B%5B303%2C516.89%2C528%2C639.39%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FCU5SMQAC%22%5D%2C%22locator%22%3A%225%22%7D%7D&quot; width=&quot;375&quot; height=&quot;204&quot; src=&quot;attachments/WVMGDVMU.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p><strong>顺序编辑</strong> 请注意，默认评估过程是更新单个模型知识，评估新模型，然后回滚更新，然后对每个测试点重复该过程。在实际场景中，模型在进行新的编辑时应保留先前的更改。因此，进行连续编辑的能力是模型编辑的一个重要特征（Huang et al., 2023）。我们评估了具有强大的单编辑性能的顺序编辑方法，并在图 4 中报告了结果。<span style="background-color: #ff666680">冻结模型参数的方法（如 SERAC 和 T-Patcher)通常在顺序编辑中表现出稳定的性能。然而，那些改变模型参数的人却很困难</span>。 <span style="background-color: #ff666680">ROME 在 n &#x3D; 10 之前表现良好，然后在 n &#x3D; 100 时下降。MEMIT 的性能也会在超过 100 次编辑后下降，但不如 ROME 大幅下降。同样，MEND 在 n &#x3D; 1 时表现良好，但在 n &#x3D; 10 时表现明显下降。随着编辑过程的继续，这些模型越来越偏离其原始状态，导致性能次优。</span></p><h2 id="5-Comprehensive-Study"><a href="#5-Comprehensive-Study" class="headerlink" title="5 Comprehensive Study"></a>5 Comprehensive Study</h2><p>考虑到上述几点，我们认为以前的评估指标可能无法充分评估模型编辑能力。因此，我们提出对可移植性、局部性和效率进行更全面的评估。</p><h3 id="5-1-Portability-Robust-Generalization"><a href="#5-1-Portability-Robust-Generalization" class="headerlink" title="5.1 Portability - Robust Generalization"></a>5.1 Portability - Robust Generalization</h3><p>几项研究使用通过反向翻译生成的样本来评估泛化性（De Cao 等人，2021）。然而，这些释义的句子通常只涉及微小的措辞变化，并不能反映实质性的事实修改。正如 Jacques Thibodeau (2022) 中所述，验证这些方法是否能够处理编辑对实际应用程序的影响至关重要。因此，我们引入了一种称为可移植性的新评估指标，以衡量模型编辑在将知识转移到相关内容方面的有效性，称为鲁棒泛化。因此我们考虑三个方面：（1）<strong>主语替换</strong>：由于大多数改写的句子保留了主语描述，但更多地改写了关系，我们通过替换来测试泛化能力问题中的主题带有别名或同义词。这测试模型是否可以将编辑的属性推广到同一主题的其他描述。 (2)<strong>反向关系</strong>：当编辑主体和关系的目标时，目标实体的属性也发生变化。我们通过过滤合适的关系（例如一对一）并询问相反的问题来检查目标实体是否也更新来测试模型处理此问题的能力。 （3）<strong>一跳</strong>：修改后的知识应该可以被编辑后的语言模型用于下游任务。例如，如果我们更改“瓦茨·汉弗莱 (Watts Humphrey) 就读哪所大学？”这个问题的答案。从“三一学院”到“密歇根大学”，当被问到“Watts Humphrey 在大学学习期间住在哪个城市？”时，模型应该回答“密歇根州的安娜堡”而不是“爱尔兰的都柏林”。因此，我们构建了一个推理数据集来评估编辑后模型使用编辑知识的能力。</p><p>     我们将一个新部分 P (xe, ye) 合并到现有数据集 ZsRE 中，可移植性计算为应用于 P (xe, ye) 中的推理示例时编辑模型 (fθe) 的平均准确度：</p><p><img src="/../imgs/$%7Bfiilename%7D/AKCEUPGK.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/AKCEUPGK.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;AKCEUPGK&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F9227ERUC%22%2C%22annotationKey%22%3A%22J5ARE9LF%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%226%22%2C%22position%22%3A%7B%22pageIndex%22%3A5%2C%22rects%22%3A%5B%5B306.5%2C154.39%2C526.5%2C190.39%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FCU5SMQAC%22%5D%2C%22locator%22%3A%226%22%7D%7D&quot; width=&quot;367&quot; height=&quot;60&quot; src=&quot;attachments/AKCEUPGK.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p><em><em>数据集构建 *<em>对于一跳数据集<span style="background-color: #ff666680">，在原始编辑中，我们将主题 s 的答案从 o 更改为 o</em>。然后，我们提示模型生成链接的三元组 (o*, r</em>, o′*)。随后，GPT-4 根据这个三元组和 s 创建一个问题和答案。尤其，如果模型可以回答这个新问题，意味着它具有三元组 (o</em>, r*, o′*) 的预先存在的知识。我们通过要求模型从 o* 和 r* 预测 o’* 来过滤未知的三元组。如果成功，则推断该模型具有先验知识。最后，人类评估者验证三元组的准确性和问题的流畅性</span>。其他详细信息，例如我们使用的演示和数据集构建的其他部分，可以在附录 B 中找到。</p><p>**结果 **我们根据新提出的评估指标和数据集进行实验，结果如表3所示。如表所示，<span style="background-color: #ff666680">当前模型编辑方法在可移植性方面的性能有些欠佳。尽管 SERAC 在之前的指标上显示出无可挑剔的结果，但在所有三个可移植性方面的准确度均低于 20%。 SERAC的瓶颈在于分类器的准确性和附加模型的能力。对于主题替换场景，包括SERAC、MEND、ROME和MEMIT，只能适应特定的主题实体表达，而不能泛化到主题实体的概念。然而，FT-L、IKE 和 T-patcher 在面对替换主题时表现出了出色的性能。</span>关于反向关系，我们的结果表明，<span style="background-color: #ff666680">当前的编辑方法主要编辑单向关系，IKE 是一个明显的例外，在 GPT-J 和 GPT-NEOX-20B 上都达到了 90% 以上。其他方法改变主体实体的属性，同时保持客体实体不受影响</span>。在一跳推理环境中，<span style="background-color: #ff666680">大多数编辑方法都难以将改变的知识转移到相关事实。</span>出乎意料的是，<span style="background-color: #5fb23680">ROME、MEMIT和IKE在可移植性方面表现出相对值得称赞的表现（超过50%）。他们不仅能够编辑原始案件，而且能够在某些方面修改与案件相关的事实</span>。综上所述，在我们的评估中，IKE 在三个场景中都表现出了相对较好的性能。然而，很明显，当前的模型编辑技术在管理编辑的后果方面继续面临挑战，即确保知识的变化在相关上下文中连贯一致地反映。事实上，这一领域需要在未来的研究中进一步调查和创新。</p><h3 id="5-2-Locality-Side-Effect-of-Model-Editing"><a href="#5-2-Locality-Side-Effect-of-Model-Editing" class="headerlink" title="5.2 Locality - Side Effect of Model Editing"></a>5.2 Locality - Side Effect of Model Editing</h3><p>在上一节中，COUNTERFACT 和 ZsRE 从以下方面评估模型编辑的局部性：COUNTERFACT 使用与目标知识相同分布的三元组，而 ZsRE 使用来自不同自然问题数据集的问题。值得注意的是，一些方法（例如 T-Patcher）在这两个数据集上表现出不同的性能。这凸显出模型编辑对语言模型的影响是多方面的，需要进行彻底、全面的评估才能充分理解其效果。为了彻底检查模型编辑的潜在副作用，我们提出了三个不同层面的评估：（1）其他关系：尽管Meng等人。 (2022)引入了本质的概念，但他们没有明确评价它。我们认为，已更新的主题的其他属性在编辑后应保持不变。 (2)分散邻里的注意力：HoelscherObermaier等人。 （2023a）发现，如果我们将编辑后的案例连接在其他不相关的输入之前，模型往往会受到编辑后的事实的影响，并继续产生与编辑后的案例一致的结果。 (3) 其他任务：基于 Skill Neuron 的断言（Wang 等人，2022），即大语言模型（LLM）中的前馈网络拥有特定于任务的知识能力，我们引入了一个新的挑战来评估模型编辑是否可能对性能产生负面影响关于其他任务。数据集构建的详细信息请参见附录 B.3。</p><p><img src="/../imgs/$%7Bfiilename%7D/ND8H464M.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/ND8H464M.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;ND8H464M&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F9227ERUC%22%2C%22annotationKey%22%3A%22DX678K73%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%227%22%2C%22position%22%3A%7B%22pageIndex%22%3A6%2C%22rects%22%3A%5B%5B297.5%2C600.89%2C529%2C776.89%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FCU5SMQAC%22%5D%2C%22locator%22%3A%227%22%7D%7D&quot; width=&quot;386&quot; height=&quot;293&quot; src=&quot;attachments/ND8H464M.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p><strong>结果</strong> 表 4 列出了我们的结果。值得注意的是，当前的编辑方法在其他属性方面表现出色，表明它们仅修改目标特征而不影响其他属性。<span style="background-color: #5fb23680">然而，它们在 Distract-Neighbor 设置中通常表现不佳，</span>如与表 1 中的结果相比性能下降所反映的那样。IKE 是一个例外，它的性能保持相对稳定，因为它继承了以下事实：</p><p><img src="/../imgs/$%7Bfiilename%7D/EQ2WM2DI.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/EQ2WM2DI.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;EQ2WM2DI&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F9227ERUC%22%2C%22annotationKey%22%3A%22S55AHZG9%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%228%22%2C%22position%22%3A%7B%22pageIndex%22%3A7%2C%22rects%22%3A%5B%5B62.727%2C578.708%2C296.591%2C783.254%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FCU5SMQAC%22%5D%2C%22locator%22%3A%228%22%7D%7D&quot; width=&quot;390&quot; height=&quot;341&quot; src=&quot;attachments/EQ2WM2DI.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p>完全需要在输入之前连接编辑后的事实。对于常识推理任务，参数保留方法在很大程度上保持了其在其他任务上的性能。相反，改变参数的方法往往会对性能产生负面影响，MEMIT 除外。尽管参数发生了变化，MEMIT 在常识性任务中仍然保持着强劲的性能，展示了其值得称赞的局部性。</p><h3 id="5-3-Efficiency"><a href="#5-3-Efficiency" class="headerlink" title="5.3 Efficiency"></a>5.3 Efficiency</h3><p>模型编辑应最大限度地减少进行编辑所需的时间和内存，而不影响模型的性能。</p><p>时间分析表5说明了不同模型编辑技术从提供编辑案例到获得发布后编辑模型所需的时间。我们观察到，一旦超网络经过训练，KE 和 MEND 就会以相当快的速度执行编辑过程。同样，SERAC 还可以快速编辑知识，在经过训练的分类器和反事实模型的情况下，在大约 5 秒内完成该过程。然而，这些方法需要数小时至数天的额外训练和额外的数据集。在我们的实验中，在 ZsRE 数据集上训练 MEND 需要超过 7 个小时，在 3× V100 上训练 SERAC 需要超过 36 个小时。另一方面，ROME 和 MEMIT 需要预先计算维基文本的协方差统计数据。然而，这种计算非常耗时，可能需要数小时至数天才能完成。相比之下，其他方法（例如 KN、CaliNET 和 T-Patcher）可能更快，因为它们不需要任何预计算或预训练。然而，KN 和 CaliNET 在较大模型上的性能</p><p><img src="/../imgs/$%7Bfiilename%7D/K9ABI2KM.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/K9ABI2KM.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;K9ABI2KM&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F9227ERUC%22%2C%22annotationKey%22%3A%22GC2LNVEQ%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%228%22%2C%22position%22%3A%7B%22pageIndex%22%3A7%2C%22rects%22%3A%5B%5B302.045%2C605.981%2C532.5%2C781.89%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FCU5SMQAC%22%5D%2C%22locator%22%3A%228%22%7D%7D&quot; width=&quot;384&quot; height=&quot;293&quot; src=&quot;attachments/K9ABI2KM.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p>不能令人满意，T-Patcher 是最慢的，因为需要针对每个相应的错误进行单独的神经元训练。考虑到时间方面，需要一种更加省时的模型编辑方法。</p><p><strong>内存分析</strong> 图 5 显示了每种模型编辑方法的内存 VRAM 使用情况。从该图中，我们观察到大多数方法消耗的内存量相似，但 MEND 除外，它需要超过 60GB 的内存用于训练。引入额外训练的方法（例如 MEND 和 SERAC）会导致额外的计算开销，从而显着增加内存消耗。</p><h2 id="6-Relationship-with-Relevant-Works"><a href="#6-Relationship-with-Relevant-Works" class="headerlink" title="6 Relationship with Relevant Works"></a>6 Relationship with Relevant Works</h2><h3 id="6-1Knowledge-in-LLMs"><a href="#6-1Knowledge-in-LLMs" class="headerlink" title="6.1Knowledge in LLMs"></a>6.1Knowledge in LLMs</h3><p>多种模型编辑方法旨在了解 PLM 中存储的知识如何精确且直接地改变模型参数。现有工作研究了 PLM 如何存储知识的原则（Geva 等人，2021、2022；Haviv 等人，2023；Hao 等人，2021；Hernandez 等人，2023；Yao 等人， 2023；Cao et al., 2023；Lamparth and Reuel, 2023；Cheng et al., 2023；Li et al., 2023b；Chen et al., 2023；Ju and Zhang, 2023），这些都有助于模型编辑过程。此外，一些模型编辑技术与知识增强相似（Zhang et al., 2019；Lewis et al., 2020；Zhang et al., 2022b；Yasunaga et al., 2021；Yao et al., 2022；Pan et al. ., 2023）方法，因为更新模型的知识也可以被视为将知识灌输到模型中。</p><h3 id="6-2Lifelong-Learning-and-Unlearning"><a href="#6-2Lifelong-Learning-and-Unlearning" class="headerlink" title="6.2Lifelong Learning and Unlearning"></a>6.2Lifelong Learning and Unlearning</h3><p>模型编辑包括终身学习和忘却，允许自适应地添加、修改和删除知识。持续学习（Biesialska et al., 2020）可以提高模型跨任务和领域的适应性，已在 PLM 中的模型编辑中显示出有效性（Zhu et al., 2020）。此外，模型忘记敏感知识并与机器遗忘概念保持一致至关重要（Hase 等人，2023；Wu 等人，2022；Tarun 等人，2021；Gandikota 等人，2023）。</p><h3 id="6-3Security-and-Privacy-for-LLMs"><a href="#6-3Security-and-Privacy-for-LLMs" class="headerlink" title="6.3Security and Privacy for LLMs"></a>6.3Security and Privacy for LLMs</h3><p>过去的研究（Carlini 等人，2020；Shen 等人，2023）表明，LLMs可以根据某些提示生成不可靠或个人的样本。删除大型语言模型 (LLM) 中存储的潜在有害信息和隐私信息的任务对于增强基于 LLM 的应用程序的隐私和安全性至关重要（Sun 等人，2023）。模型编辑可以抑制有害语言的生成（Geva et al., 2022；Hu et al., 2023），可以帮助解决这些问题。</p><h2 id="7-Conclusion"><a href="#7-Conclusion" class="headerlink" title="7 Conclusion"></a>7 Conclusion</h2><p>我们系统地分析了编辑大语言模型（LLM）的方法。我们的目标是通过检查现有编辑技术的特征、优势和局限性，帮助研究人员更好地理解现有编辑技术。我们的分析显示了很大的改进空间，特别是在可移植性、局部性和效率方面。改进的LLMs编辑可以帮助他们更好地适应用户不断变化的需求和价值观。我们希望我们的工作能够促进开放问题和进一步研究的进展。</p>]]></content>
      
      
      <categories>
          
          <category> NLP顶会 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> EMNLP2023 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>知识神经元中心之旅：语言无关知识神经元和简并知识神经元的发现</title>
      <link href="/2023/11/02/zhi-shi-shen-jing-yuan-zhong-xin-zhi-lu-yu-yan-wu-guan-zhi-shi-shen-jing-yuan-he-jian-bing-zhi-shi-shen-jing-yuan-de-fa-xian/"/>
      <url>/2023/11/02/zhi-shi-shen-jing-yuan-zhong-xin-zhi-lu-yu-yan-wu-guan-zhi-shi-shen-jing-yuan-he-jian-bing-zhi-shi-shen-jing-yuan-de-fa-xian/</url>
      
        <content type="html"><![CDATA[<h1 id="知识神经元中心之旅：语言无关知识神经元和简并知识神经元的发现"><a href="#知识神经元中心之旅：语言无关知识神经元和简并知识神经元的发现" class="headerlink" title="知识神经元中心之旅：语言无关知识神经元和简并知识神经元的发现"></a>知识神经元中心之旅：语言无关知识神经元和简并知识神经元的发现</h1><h2 id="Abstruct"><a href="#Abstruct" class="headerlink" title="Abstruct"></a>Abstruct</h2><p>预训练语言模型 (PLM) 包含大量事实知识，但这些知识如何存储在参数中仍不清楚。本文深入研究了理解事实知识如何存储在多语言 PLM 中的复杂任务，并介绍了适应架构的多语言集成梯度方法，与现有方法相比，该方法<span style="background-color: #ff666680">成功地更精确地定位了知识神经元，并且在各种架构和语言中更加通用。</span>此外，我们对知识神经元进行了深入的探索，得到了以下两个重要发现：<span style="background-color: #ff666680">（1）语言无关的知识神经元的发现，它以超越语言的形式存储事实知识。我们设计了跨语言知识编辑实验，证明 PLM 可以基于语言无关的神经元完成这项任务；</span> <span style="background-color: #ff666680">（2）退化知识神经元的发现，这是一种新型神经元，表明不同的知识神经元可以存储相同的事实。</span>其<span style="background-color: #ff666680">功能重叠的特性赋予 PLM 强大的事实知识掌握能力。</span>我们设计了事实检查实验，证明<span style="background-color: #ff666680">退化知识神经元可以帮助 PLM 检测错误事实。</span>实验证实了这些发现，揭示了多语言 PLM 中事实知识存储的机制，并为该领域提供了宝贵的见解。源代码将公开以供进一步研究。</p><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h2><p>预训练语言模型 (PLM)（Devlin 等人，2018 年；Radford 等人，2019 年；Shliazhko 等人，2022 年；OpenAI 2023；Touvron 等人，2023 年）因其卓越的性能而彻底改变了自然语言处理领域涵盖广泛的任务。这些模型在维基百科等广泛的语料库上进行训练，被广泛认为封装了大量事实知识（Petroni 等人，2019b；Jiang 等人，2020），但知识如何存储在参数中仍不清楚（Kandpal 等人） .2023）。研究知识存储机制将有助于更深入地理解和掌握 PLM 中的知识（Zhen 等人，2022 年；Zhao 等人，2023 年）。在本文中，我们对知识定位任务（Hase et al. 2023; Andreas 2022）进行了深入研究，该任务旨在确定模型参数中特定事实知识的存储位置，其中此类参数被称为知识神经元（Dai 等人，2022）。</p><p><img src="/../imgs/$%7Bfiilename%7D/35MAP8RY.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/35MAP8RY.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;35MAP8RY&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FEYHEHWWX%22%2C%22annotationKey%22%3A%22KFEQGR8B%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B310.588%2C334.059%2C565.588%2C579.353%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F77ALXKTW%22%5D%2C%22locator%22%3A%221%22%7D%7D&quot; width=&quot;425&quot; height=&quot;409&quot; src=&quot;attachments/35MAP8RY.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p>最近，一些已建立的方法致力于阐明 PLM 中的知识存储机制。一种策略是基于梯度的方法（Ancona et al. 2019），<span style="background-color: #2ea8e580">它通过使用积分梯度计算每个神经元的归因得分来评估每个神经元的贡献。另一种是因果启发方法，它采用跟踪算法来跟踪模型层之间的因果影响（Cao 等人，2023）。</span>尽管在知识本地化任务中取得了成功，这些方法仍然面临两个主要挑战：<span style="background-color: #2ea8e580">（1）缺乏针对不同 PLM 架构的通用方法：观察到事实知识出现在各种 PLM 架构中，包括自动编码模型（例如， BERT）（Devlin 等人，2018 年）和自回归模型（例如 GPT）（Shliazhko 等人，2022 年）。</span>然而，虽然有些方法适合自编码模型并且在自回归模型中表现不佳（Meng et al. 2022a），但其他方法是专门为自回归模型设计的并且不能很好地适应自编码模型（Li et al. 2022），在跨两种 PLM 架构都表现良好的通用方法中留下了空白。(2)缺乏多层次探索多种语言：实质性知识与语言无关，当前的大型语言模型支持多语言。然而，现有的方法仅关注英语数据集，可能无法提供跨语言知识存储机制的全面见解，限制了得出多语言结论的能力。</p><p>     为了更精确地定位知识神经元，我们遵循基于梯度的方法，提出了一种新颖的知识定位方法，称为架构适应多语言集成梯度（AMIG）。<span style="background-color: #ff666680">首先，针对不同 PLM 架构中缺乏通用方法，我们设计了一种架构适配技术，使得集成梯度算法（Lundstrom、Huang 和 Razaviyayn 2022）中的基线向量在不同 PLM 架构之间普遍兼容。其次，针对多语言探索的缺乏，我们引入了多语言阈值调整技术，针对不同语言调整综合梯度计算中的阈值。</span>多语言数据集上的实验结果表明，与之前最先进的模型相比，我们的方法可以更精确地定位知识神经元。此外，我们还对知识神经元进行了深入的探索，得出了以下两个重要发现。</p><p>**      与语言无关的知识神经元**：我们在多语言 PLM 中发现了一种新型神经元，能够跨语言存储事实知识。我们将它们命名为与语言无关的知识神经元，因为它们的存在超越了特定语言的界限。如图1a所示，<span style="background-color: #ff666680">这些神经元是通过将源自不同语言的知识神经元相交而获得的，封装了跨多种语言一致的知识表示。独立于语言的知识神经元可以帮助跨语言的知识编辑任务：对某些知识的单次编辑可以同时影响所有语言的相应知识。</span>例如，如果我们将事实⟨Tanzania, Capital, Dar es Salaam⟩对应的语言无关神经元编辑为⟨Tanzania, Capital, Dodoma⟩，则该事实在所有语言中都会相应更改。我们设计实验来验证与语言无关的知识神经元的作用。与现有的跨语言知识编辑模型相比，我们的方法的编辑性能更为优越。该实验证明了我们的方法在跨语言知识编辑应用中的潜力。</p><p>      <strong>退化知识神经元</strong>：我们发现了一个有趣的现象，对应于一种全新类型的神经元。<span style="background-color: #ff666680">给定事实及其相应的知识神经元，知识神经元的某些子集表现出独特的属性。即使该子集中的某些元素被抑制，模型仍然可以正确地表达事实；然而，如果子集中的所有元素都被抑制，模型就无法再正确地表达事实。这一现象表明，一些知识神经元存储着相同的事实知识，模型需要激活至少一个神经元才能正确表达事实。</span>它与生物系统中的“简并”现象非常相似（Tononi, Sporns, and Edelman 1999; Mason 2015），因此我们将此类神经元命名为简并知识神经元。与冗余不同，<span style="background-color: #ff666680">简并知识神经元不能简单地删除，因为它们仅部分重叠。一个退化的知识神经元可能存储多条事实知识，删除它对特定知识没有影响，但可能会影响其他知识。</span></p><p>     图1b说明了简并知识神经元的获取过程。具体来说，<span style="background-color: #ff666680">我们首先对知识神经元进行定位，然后对它们进行聚合和过滤以获得简并的知识神经元。</span>对于查询“坦桑尼亚的首都是”，PLM 必须激活至少一个相应的简并知识神经元来预测正确的事实 Dodoma。直观上，<span style="background-color: #ff666680">简并知识神经元的功能重叠特性赋予 PLM 对事实知识的强大理解，确保其对事实的掌握保持稳定且不易出错</span>。受此启发，我们设计了一个实验，使用简并知识神经元进行事实检查。我们的实验表明，<span style="background-color: #5fb23680">简并知识神经元可以帮助 PLM 检测错误事实，从而说明它们的存在增强了 PLM 对事实知识的稳定掌握。</span></p><p>总的来说，主要贡献总结如下：（1）我们提出了一种新颖的知识本地化方法，称为架构适应的多语言集成梯度，它可以有效解决传统方法的两个挑战：缺乏针对不同 PLM 架构的通用方法和缺乏对多种语言的探索，从而实现知识神经元更精确的定位。 （2）我们发现了独立于语言的知识神经元，它们以超越语言障碍的形式存储事实知识。实验结果表明它们有利于跨语言知识编辑任务。 （3）我们发现了简并知识神经元，这是一种具有功能重叠特性的新型神经元，使得模型对事实知识的掌握更加稳健。实验证明它们可以帮助检测不正确的事实。</p><h2 id="2-Methodology"><a href="#2-Methodology" class="headerlink" title="2 Methodology"></a>2 Methodology</h2><p>图 2 示意性地展示了我们提出的框架。它由三个主要模块组成，包括知识神经元定位（模块1）、语言无关知识神经元检测（模块2）和简并知识神经元检测（模块3）。我们详细说明了每个模块。</p><h3 id="2-1KnowLedge-Neuron-Localization"><a href="#2-1KnowLedge-Neuron-Localization" class="headerlink" title="2.1KnowLedge Neuron Localization"></a>2.1KnowLedge Neuron Localization</h3><p>图 2 的模块 1 展示了知识定位模块，该模块旨在查明 PLM 中知识神经元的确切位置。使用填空完形填空任务（Petroni 等人，2019a），我们评估对 PLM 对特定事实的理解。例如，给定一个事实 ⟨Tanzania, Capital, Dodoma⟩ 以及相应的查询“坦桑尼亚的首都是”，Petroni 等人 (2019a) 描述，如果模型能够预测正确答案，则模型知道一个事实。在本研究中，我们通过引入架构适应多语言集成梯度方法来扩展此分析，以定位专门负责处理事实信息的神经元。</p><p><img src="/../imgs/$%7Bfiilename%7D/MXWX28JU.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/MXWX28JU.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;MXWX28JU&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FEYHEHWWX%22%2C%22annotationKey%22%3A%228TICA8HS%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%223%22%2C%22position%22%3A%7B%22pageIndex%22%3A2%2C%22rects%22%3A%5B%5B49.615%2C585.462%2C563.654%2C764.885%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F77ALXKTW%22%5D%2C%22locator%22%3A%223%22%7D%7D&quot; width=&quot;857&quot; height=&quot;299&quot; src=&quot;attachments/MXWX28JU.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p>从数学上来说，给定一个查询 q，PLM 预测的正确答案的概率可以定义为：</p><p><img src="/../imgs/$%7Bfiilename%7D/WXFG2TDF.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/WXFG2TDF.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;WXFG2TDF&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FEYHEHWWX%22%2C%22annotationKey%22%3A%22HCSPGJUY%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%223%22%2C%22position%22%3A%7B%22pageIndex%22%3A2%2C%22rects%22%3A%5B%5B55.385%2C522%2C295.962%2C544.5%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F77ALXKTW%22%5D%2C%22locator%22%3A%223%22%7D%7D&quot; width=&quot;401&quot; height=&quot;38&quot; src=&quot;attachments/WXFG2TDF.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p>其中 y* 是正确答案，w(l) j 是第 l 层的第 j 个神经元，^ w(l) j 是 w(l) j 分配的值。为了计算每个神经元的归因分数，我们使用积分梯度（Sundararajan、Taly 和 Yan 2017）。考虑一个神经元 w(l) j ，我们可以计算它的归因分数：</p><p><img src="/../imgs/$%7Bfiilename%7D/9PTK8AY8.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/9PTK8AY8.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;9PTK8AY8&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FEYHEHWWX%22%2C%22annotationKey%22%3A%22WI26DVZD%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%223%22%2C%22position%22%3A%7B%22pageIndex%22%3A2%2C%22rects%22%3A%5B%5B50.192%2C407.769%2C302.308%2C456.808%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F77ALXKTW%22%5D%2C%22locator%22%3A%223%22%7D%7D&quot; width=&quot;420&quot; height=&quot;82&quot; src=&quot;attachments/9PTK8AY8.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p>其中 w(l) j 是 w(l) j 的值，w′(l) j 是 w(l) j 的基线向量，并且 ∂ F(w′(l) j +α(w(l)) j −w′(l) j )) ∂ w(l) j 计算梯度。当 α 从 0 变为 1 时，(w′(l) j +α(w(l) j −w′(l) j )) 从 w′(l) j 变为 w(l) j ，因此 Attr (w(l) j )可以通过对梯度进行积分来累积因w(l) j 变化而引起的概率变化。理想的基线向量 w′(l) j 应该缺乏信息（Liu et al. 2022)，当前的方法用零向量对其进行近似。然而，这样的设置没有考虑各种 PLM 架构之间的差异，导致性能不佳。为了缓解这个问题，我们设计了一种架构适应技术来计算各种 PLM 架构的基线向量。</p><p>     首先，为了最小化基线向量中的信息内容，我们遵循Enguehard（2023）的方法，将输入查询q分成m个单词，然后将每个单词分别输入到PLM中以计算神经元的激活分数对应每个词qi。随后，我们精心设计了不同 PLM 架构的基线向量。设qi对应的基线句子为q′ i，q′ i包含m个单词，长度与q一致，记为q′ i &#x3D; (q′ i1 . . . q′ ik . . . q′ im) ， 在哪里：</p><p><img src="/../imgs/$%7Bfiilename%7D/YTVPUQLA.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/YTVPUQLA.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;YTVPUQLA&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FEYHEHWWX%22%2C%22annotationKey%22%3A%22BS72ACK6%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%223%22%2C%22position%22%3A%7B%22pageIndex%22%3A2%2C%22rects%22%3A%5B%5B53.654%2C87.577%2C296.538%2C128.538%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F77ALXKTW%22%5D%2C%22locator%22%3A%223%22%7D%7D&quot; width=&quot;405&quot; height=&quot;68&quot; src=&quot;attachments/YTVPUQLA.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p>其中 ⟨mask⟩ 用于屏蔽自动编码模型，⟨eos⟩ 代表自回归模型中的“序列结束”，qk 是查询的第 k 个单词。在此设计中，第 l 层中的第 i 个神经元（用 w(l) j 表示）对应于 qi，其相关基线向量 w’(l) j 对应于 q’ i。然后，我们可以根据方程（2）计算使用 qi 作为输入时每个神经元的归因得分 Attri(w(l) j )。为了计算积分，我们使用黎曼近似：</p><p><img src="/../imgs/$%7Bfiilename%7D/J2V52PJA.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/J2V52PJA.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;J2V52PJA&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FEYHEHWWX%22%2C%22annotationKey%22%3A%22SMECCLTE%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%223%22%2C%22position%22%3A%7B%22pageIndex%22%3A2%2C%22rects%22%3A%5B%5B317.885%2C419.308%2C562.5%2C460.846%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F77ALXKTW%22%5D%2C%22locator%22%3A%223%22%7D%7D&quot; width=&quot;408&quot; height=&quot;69&quot; src=&quot;attachments/J2V52PJA.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p>其中 N 是近似步数。然后对每个单词 qi 的归因进行求和并标准化，得出查询的最终归因分数：</p><p><img src="/../imgs/$%7Bfiilename%7D/TJE9KG2X.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/TJE9KG2X.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;TJE9KG2X&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FEYHEHWWX%22%2C%22annotationKey%22%3A%22RUKKVDNU%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%223%22%2C%22position%22%3A%7B%22pageIndex%22%3A2%2C%22rects%22%3A%5B%5B320.192%2C349.5%2C562.5%2C388.731%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F77ALXKTW%22%5D%2C%22locator%22%3A%223%22%7D%7D&quot; width=&quot;404&quot; height=&quot;65&quot; src=&quot;attachments/TJE9KG2X.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p>其中 n 是第 l 层中的神经元数量。最后，我们可以找到归因分数大于阈值τ的神经元，并将其视为知识神经元，记为N。</p><h3 id="2-2-Language-Indepent-Knowledge-Neuron-Dectection"><a href="#2-2-Language-Indepent-Knowledge-Neuron-Dectection" class="headerlink" title="2.2 Language-Indepent Knowledge Neuron Dectection"></a>2.2 Language-Indepent Knowledge Neuron Dectection</h3><p><strong>解释</strong> 许多 PLM 支持多语言，并且这些模型中的事实知识的很大一部分是与语言无关的（Xu 等人，2023 年；Wang、Lipton 和 Tsvetkov，2020 年）。这种必要性对于探索多语言 PLM 中事实知识的存储机制变得越来越重要。我们将存储多种语言共有的事实知识的神经元定义为与语言无关的知识神经元，记为 L。为了识别这些类型的知识神经元，我们设计了一种检测算法，如下所示。</p><p><strong>算法</strong> 如图 2 的模块 2 所示，<span style="background-color: #ff666680">给定 K 种语言中具有相同语义的事实三元组，让相应的查询用 qk 表示，其中 k &#x3D; 1, 2, …。 。 。 ，K。对于每个查询，我们使用知识神经元定位模块来获取相应的知识神经元，其中神经元 w(l) i 的属性得分记为攻击 (w(l) i )。多语言PLM对不同语言的敏感度不同，导致不同语言查询的归因分数存在显着差异。</span>因此，很难通过设置统一的阈值来获得所有语言的知识神经元。为了解决这个问题，我们设计了一种多语言阈值调整技术。<span style="background-color: #ff666680">我们为不同的语言设置不同的缩放因子τk，并记录查询qk对应的神经元的最大归因得分，然后确定动态阈值：</span></p><p><img src="/../imgs/$%7Bfiilename%7D/P9A52SBQ.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/P9A52SBQ.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;P9A52SBQ&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FEYHEHWWX%22%2C%22annotationKey%22%3A%22CMF6JKKR%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%224%22%2C%22position%22%3A%7B%22pageIndex%22%3A3%2C%22rects%22%3A%5B%5B51.923%2C615.462%2C295.962%2C635.077%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F77ALXKTW%22%5D%2C%22locator%22%3A%224%22%7D%7D&quot; width=&quot;407&quot; height=&quot;33&quot; src=&quot;attachments/P9A52SBQ.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p>然后，我们使用阈值过滤来识别第 k 种语言的知识神经元 Nk ，如下所示：</p><p><img src="/../imgs/$%7Bfiilename%7D/363QLBKW.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/363QLBKW.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;363QLBKW&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FEYHEHWWX%22%2C%22annotationKey%22%3A%22UBY826H3%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%224%22%2C%22position%22%3A%7B%22pageIndex%22%3A3%2C%22rects%22%3A%5B%5B54.231%2C568.731%2C295.962%2C590.077%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F77ALXKTW%22%5D%2C%22locator%22%3A%224%22%7D%7D&quot; width=&quot;403&quot; height=&quot;36&quot; src=&quot;attachments/363QLBKW.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p>最后，我们计算所有语言的知识神经元的交集：</p><p><img src="/../imgs/$%7Bfiilename%7D/IECZZKEA.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/IECZZKEA.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;IECZZKEA&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FEYHEHWWX%22%2C%22annotationKey%22%3A%22KA6FW74N%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%224%22%2C%22position%22%3A%7B%22pageIndex%22%3A3%2C%22rects%22%3A%5B%5B55.962%2C509.308%2C294.808%2C545.077%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F77ALXKTW%22%5D%2C%22locator%22%3A%224%22%7D%7D&quot; width=&quot;398&quot; height=&quot;60&quot; src=&quot;attachments/IECZZKEA.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p>其中 L 代表独立于语言的知识神经元，编码在所有考虑的语言中一致的事实知识。通过上述算法，我们最终可以得到它们。</p><h3 id="2-3Degenerate-Knowledge-Neuron-Detection"><a href="#2-3Degenerate-Knowledge-Neuron-Detection" class="headerlink" title="2.3Degenerate Knowledge Neuron Detection"></a>2.3Degenerate Knowledge Neuron Detection</h3><p>**解释 **通过进行深入分析，我们发现了一个有趣的现象：<span style="background-color: #ff666680">不同的神经元组负责存储相同的事实知识。例如，对于表示为 ⟨h, r, t⟩ 的特定事实，假设我们定位 10 个标记为 N &#x3D; {1, 2, … 的知识神经元。 。 。 ，10}。如果我们抑制集合 A &#x3D; {1, 2} 或 B &#x3D; {3, 4, 5}（N 的两个子集）的神经元，我们观察到预测概率没有显着下降。相反，同时抑制这两组神经元（即 A∪B）会导致预测概率的大幅损失。这表明 A 组和 B 组都包含相同的事实知识，至少其中一个必须是活跃的，模型才能准确理解事实。</span>此外，<span style="background-color: #5fb23680">这两组神经元并不相互冗余。也就是说，除了事实⟨h，r，t⟩之外，A还可以存储事实⟨h1，r1，t1⟩，而B可以存储⟨h2，r2，t2⟩，从而在PLM中发挥附加作用。</span>鉴于这种行为与生物神经网络中的退化现象相似（Tononi、Sporns 和 Edelman 1999；Mason 2015），我们为这些神经元创造了术语“退化知识神经元”。接下来详细介绍这个概念。算法 正式地，令 N &#x3D; {n1, . 。 。 , nk} 是所有局部知识神经元 1 的集合，我们将退化知识神经元定义为 D &#x3D; {d1D, . 。 。 , dDm}，其中每个 dD i &#x3D; {ni1, . 。 。 ,niv}包含v个知识神经元，并且满足以下条件：</p><p><img src="/../imgs/$%7Bfiilename%7D/SUFF78G3.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/SUFF78G3.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;SUFF78G3&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FEYHEHWWX%22%2C%22annotationKey%22%3A%22BIA5YB3C%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%224%22%2C%22position%22%3A%7B%22pageIndex%22%3A3%2C%22rects%22%3A%5B%5B53.654%2C117%2C297.115%2C163.154%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F77ALXKTW%22%5D%2C%22locator%22%3A%224%22%7D%7D&quot; width=&quot;406&quot; height=&quot;77&quot; src=&quot;attachments/SUFF78G3.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p><img src="/../imgs/$%7Bfiilename%7D/GVDGBVQB.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/GVDGBVQB.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;GVDGBVQB&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FEYHEHWWX%22%2C%22annotationKey%22%3A%22MLUF5LZR%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%224%22%2C%22position%22%3A%7B%22pageIndex%22%3A3%2C%22rects%22%3A%5B%5B313.269%2C513.346%2C565.962%2C745.269%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F77ALXKTW%22%5D%2C%22locator%22%3A%224%22%7D%7D&quot; width=&quot;421&quot; height=&quot;386&quot; src=&quot;attachments/GVDGBVQB.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p>其中 Ps(ni) 是并集 Sv j&#x3D;1 nij 的真子集，即 Ps(ni) ⊊ Sv j&#x3D;1 nij。 Prob(X)是当神经元集合X被激活时模型的预测概率，Tlow和Thigh是可接受的预测概率差的预定义阈值。式(9)表明，抑制dD i 的任意真子集，即Ps(ni)，不会导致预测概率显着下降；而等式（10)表明，抑制dD i 中的所有神经元将导致预测概率显着下降。这表明这些神经元存储相同的知识。</p><p>    一般情况下，<span style="background-color: #ff666680">考虑到我们有n个知识神经元，我们需要评估所有可能的子集，找到D的复杂度是O(2n)。为了使问题易于处理，我们通过假设每个 dD i 仅包含两个知识神经元来简化问题。这个假设将问题复杂度降低到 O(n2)。</span></p><p>    为了进一步减少计算量，我们设计了两步过滤过程。如图2的算法1和模块3所示，我们<span style="background-color: #ff666680">首先抑制每个神经元并记录不会导致预测概率显着下降的神经元，这些神经元被视为潜在的简并知识神经元Pd</span>。对于Pd中的元素，进行二次过滤：<span style="background-color: #ff666680">抑制其中的神经元对，如果该操作导致模型的预测概率显着下降，则将该神经元对记录为退化知识神经元dD i </span>。最后我们可以将退化的知识神经元返回为D。</p><h2 id="3-Experiments"><a href="#3-Experiments" class="headerlink" title="3 Experiments"></a>3 Experiments</h2><h3 id="3-1Experimental-Settings"><a href="#3-1Experimental-Settings" class="headerlink" title="3.1Experimental Settings"></a>3.1Experimental Settings</h3><p><strong>模型选择和数据集</strong> 在我们的实验中，我们选择了两种不同的多语言 PLM：m-BERT (Devlin et al. 2018) 和 m-GPT (Shliazhko et al. 2022)。 m-BERT 是一种自动编码模型，针对多种多语言数据集进行了预训练，而 m-GPT 是一种自回归模型，旨在处理 61 种语言的广泛语料库。关于数据集，我们采用 mLAMA (Kassner, Dufter, and Sch utze 2021)，它是原始 LAMA (Petroni et al. 2019a, 2020) 的多语言扩展，用于本地化多语言 PLM 中的知识。</p><p>**评估指标 **我们对这两种方法应用相同的神经元编辑操作，其中检测到的知识神经元被抑制或增强，然后计算 PLM 对相关和不相关事实的预测概率。为了全面比较不同方法的知识定位精度，我们提出了一种新的评估指标来评估整个数据集知识定位的结果：</p><p><img src="/../imgs/$%7Bfiilename%7D/KX4LAIXX.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/KX4LAIXX.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;KX4LAIXX&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FEYHEHWWX%22%2C%22annotationKey%22%3A%22V2QVIJNH%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%225%22%2C%22position%22%3A%7B%22pageIndex%22%3A4%2C%22rects%22%3A%5B%5B54.808%2C575.077%2C295.962%2C609.115%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F77ALXKTW%22%5D%2C%22locator%22%3A%225%22%7D%7D&quot; width=&quot;402&quot; height=&quot;57&quot; src=&quot;attachments/KX4LAIXX.png&quot; ztype=&quot;zimage&quot;&gt;"></p><p>其中SRx是编辑成功率，x代表我们抑制或增强神经元的编辑操作。给定一个查询，它本身被认为是相关事实，并且随机选择不同类型的事实作为其不相关事实。 ΔP robrx 和 ΔP robix 分别表示相关事实和不相关事实在操作 x 下预测概率的平均变化。总体而言，<span style="background-color: #ff666680">我们希望相关事实随着知识神经元的变化而变化，而不相关事实保持不变；因此，成功率越高，定位效果越好</span>2。由于我们分别对神经元进行抑制和增强操作，因此将这两种情况的成功率总结为最终的成功率：SR &#x3D; SRenhance + SRsuppress。</p><h3 id="3-2Localization-of-Knowledge-Neurons"><a href="#3-2Localization-of-Knowledge-Neurons" class="headerlink" title="3.2Localization of Knowledge Neurons"></a>3.2Localization of Knowledge Neurons</h3><p>我们使用模块1在英语和中文数据集上的m-BERT和m-GPT模型上进行实验，并以Dai等人（2022）提出的方法作为基线，我们将其表示为B-KN。我们的研究结果如表 1 和图 3 所示，从中我们得出了一些重要的见解。</p><p>      (1) 我们的方法在所有设置下都取得了更好的结果。在表1中，我们使用AMIG来表示我们的方法，表中的结果代表平均成功率SR。在所有设置下，我们的方法都优于 B-KN，特别是对于中国数据集，m-BERT 和 m-GPT 的成功率分别提高了 84.34% 和 44.49%。这表明我们的方法定位的知识神经元更加精确。</p><p>    <span style="background-color: #5fb23680">（2）在m-BERT中，知识神经元主要位于最后层，而在m-GPT中，知识神经元位于前、中、最后层，如图3所示，其中x和y轴代表PLM分别是层数和知识神经元的百分比。这可能是由于自动编码模型（例如 m-BERT）共享编码空间并在最后几层中编码高级特征，而自回归模型（例如 m-GPT）逐渐细化每层的特征来预测下一个单词。</span></p><p>      (3)汉语和英语的知识神经元分布较为相似，但也存在差异。相似之处可能是由于事实具有相同的含义语言之间存在差异，而差异可能是由于语言之间固有的结构和句法差异或预训练语料库质量的差异造成的。</p><h2 id="3-3-Language-Independence-Neurons-and-Cross-Lingual-Knowledge-Editing"><a href="#3-3-Language-Independence-Neurons-and-Cross-Lingual-Knowledge-Editing" class="headerlink" title="3.3 Language-Independence Neurons and Cross-Lingual Knowledge Editing"></a>3.3 Language-Independence Neurons and Cross-Lingual Knowledge Editing</h2><p><strong>语言无关神经元</strong>的定位通过我们对模块 2 的实验，我们捕获了图 3 中的结果。结果表明，<span style="background-color: #ff666680">无论是 m-BERT 还是 m-GPT，语言无关的知识神经元主要集中在最后一两个层。</span><span style="background-color: #5fb23680">这可能是因为独立于语言的事实充当高级特征，而 PLM 只能在最后几层成功地对它们进行编码。</span>跨语言知识编辑实验设置我们基于与语言无关的知识神经元设计跨语言编辑实验。与知识本地化实验的设置类似，我们抑制或者增强语言无关的知识神经元并计算编辑成功率SR。为了证明独立于语言的知识神经元的作用，我们设计了两个比较实验。（1）编辑一种语言的知识神经元，观察另一种语言相应事实的变化。 （2）依次编辑两种语言的知识神经元，观察两种语言对应事实的变化。跨语言知识编辑实验结果我们对表2的分析揭示了两个见解：</p><p><span style="background-color: #ff666680">（1）独立于语言的知识神经元促进跨语言编辑。与仅编辑中文或英文相比，编辑与语言无关的知识神经元在所有设置下都有更高的成功率；在中国数据集中，m-BERT 和 m-GPT 的成功率分别提高了 213.05% 和 277.36%。这意味着用一种语言编辑事实知识并期望其他语言发生相应变化的挑战；然而，利用独立于语言的知识神经元可以实现这一点。</span></p><p><span style="background-color: #ff666680">（2） 单独编辑每种语言并不能保证获得更好的结果。尽管人们可以直观地编辑每种语言以实现跨语言的更改，但我们的实验表明，这种方法不仅依赖更多的计算资源，而且可能表现不佳。与使用语言无关神经元相比，顺序编辑导致 mBERT 和 m-GPT 的成功率分别降低 42.97% 和 58.80%，这可能是由于多次编辑造成的混乱。这强调了语言独立神经元的重要性。</span></p><h3 id="3-4Degenerate-Knowledge-Neurons-and-Fact-Checking-Experiment"><a href="#3-4Degenerate-Knowledge-Neurons-and-Fact-Checking-Experiment" class="headerlink" title="3.4Degenerate Knowledge Neurons and Fact-Checking Experiment"></a>3.4Degenerate Knowledge Neurons and Fact-Checking Experiment</h3><p>多语言PLM中简并知识神经元的识别我们使用模块3设置了一个实验来研究简并知识神经元，结果如图4所示。<span style="background-color: #5fb23680">根据我们的观察，m-BERT和m-GPT中的简并知识神经元表现出分布模式类似于知识神经元。</span>这不仅表明了简并性之间存在很强的相关性。单语言 PLM 中简并知识神经元的识别在我们的单语言 PLM 实验中，我们成功识别了简并知识神经元，并证明它们本质上存在于 PLM 中。关于简并知识神经元的一个可能的问题是：<span style="background-color: #5fb23680">PLM 是否以多种语言存储相同的事实，从而利用多个神经元集来获取相同的信息？为了消除这种观念并证明简并知识神经元的存在与 PLM 中多语言的支持无关，</span>我们将探索扩展到单语言 PLM，特别是 BERT 和 GPT-2。这些简并知识神经元的分布如图 5 所示，进一步证实了我们的结论。事实检查实验设置 PLM 可能会隐藏虚假事实（Edwards 2023；Pitt 2022），而当前的解决方案通常依赖外部数据进行事实检查（Vladika 和 Matthes 2023）。考虑到简并知识神经元功能重叠的性质，我们设计了一个事实检查实验，以在不依赖外部数据的情况下基于简并知识神经元检测错误事实。接下来，我们详细介绍我们的实验设置。</p><p>     首先，mLAMA 数据集被修改以包含错误的事实属性。<span style="background-color: #2ea8e580">对于与某个事实关系名称相关的事实三元组，例如 ⟨Tanzania, Capital, Dodoma⟩ ，我们从相同的关系名称中随机选择一个对象（例如，达累斯萨拉姆）作为错误事实。</span>然后，为了验证我们的发现的实际意义，<span style="background-color: #ff666680">我们将数据集中的每种类型的查询按比例分为两部分。对于每种类型，第一段用于获取简并知识神经元，并识别数量超过 t% 特定阈值的神经元。随后，我们将第二部分中的查询以及相应的正确或错误事实作为输入并计算简并知识神经元的平均激活分数。如果平均激活分数超过预定义的阈值 λ，则该事实被分类为正确；否则，它被归类为 false。</span>我们使用原始PLM直接评估事实的正确性进行比较分析。这种配置可以防止 PLM 使用查询本身的简并知识神经元进行事实检查，从而使实验更加令人信服。我们在表3中将我们的方法表示为“with DKN”。最后，由于当前的事实核查方法必须依赖于外部数据，因此我们使用PLM直接执行事实核查作为我们方法的基线，表示为“wo表 3 中的“DKN”。我们使用 Precision、Recall 和 F1-score 作为评估指标。</p><p>事实核查实验结果 表 3 中的结果使我们得出以下结论。</p><p>（1）<span style="background-color: #ff666680">退化的知识神经元可以帮助 PLM 检测错误的事实。</span>在各种设置下，我们的方法比基线方法更好，特别是对于中国数据集和自回归模型。例如，在 m-GPT 和中文数据集的背景下，我们的方法的 F1 分数与基线相比增加了 167150%。<span style="background-color: #5fb23680">这一实质性改进表明简并知识神经元的存在增强了 PLM 对事实知识的稳定掌握。</span></p><p>（2）<span style="background-color: #5fb23680">使用PLM进行事实检查，他们经常判断一个事实是正确的，从而导致极高的召回率。这与观察结果一致，即如果提出错误的前提，生成语言模型可能会产生不正确的信息</span>（Edwards 2022；Lakshmanan 2022；Metz 2022）。</p><p>（3）<span style="background-color: #5fb23680">自回归模型比自编码模型表现出更高的召回率。</span>这可能是由于自回归设计更注重一致性而不是准确性，并且自动编码在评估中可能更加保守（Zhou et al. 2023）。 (4)简并知识神经元的存在与PLM中多语言的支持无关。在单语言 PLM 中，即 BERT 和 GPT-2，事实检查也可以基于简并知识神经元进行。这一结果进一步证明了简并知识神经元的存在及其有用性。</p><h2 id="4-Related-Work"><a href="#4-Related-Work" class="headerlink" title="4 Related Work"></a>4 Related Work</h2><p>知识定位现有的方法大致分为两类：（1）基于梯度的方法：Dai et al.（2022）首先引入了知识神经元的概念，并通过评估每个神经元的贡献来定位它们（​​Geva et al. 2021）使用积分梯度计算他们的归因得分。 （2）Causal-inspired方法，由Meng等人（2022a）提出，将知识神经元定义为PLM中对预测某些事实知识具有最强因果效应的神经元激活，该方法启发了知识编辑算法的创建例如 ROME（Meng 等人，2022a）、MEMIT（Meng 等人，2022b）和 MEND（Mitchell 等人，2022）。然而，当前的方法缺乏针对不同 PLM 架构和多种语言探索的通用方法。公理归因方法 Sundararajan、Taly 和 Yan（2017）介绍了公理归因方法，强调敏感性和实现不变性作为归因方法的核心公理，从而产生了积分梯度（IG）。后续研究包括Discretized IG (Sanyal and Ren 2021)，它使用插值策略来提高梯度精度； Sequential IG (Enguehard 2023) 专为单词重要性评估而设计；有效 Shapley 值以及 Shapley IG，由 Liu 等人 (2022) 开发，用于提高效率和效果。我们改进了 IG 的基线向量，以最大限度地减少其信息内容。</p><h2 id="5-Conclusion"><a href="#5-Conclusion" class="headerlink" title="5 Conclusion"></a>5 Conclusion</h2><p>     在这项研究中，我们使用适应架构的多语言集成梯度方法探索多语言 PLM 中的事实知识本地化。我们进一步设计了两个模块，导致了语言无关知识神经元和简并知识神经元的两个发现。前者肯定了多语言PLM中的一部分知识以超越语言的形式存在，而后者则引入了一种新型神经元，类似于生物系统中观察到的退化现象，这些神经元可以用来检测不正确的信息。事实。</p>]]></content>
      
      
      <categories>
          
          <category> NLP顶会 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> EMNLP2023 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2023/11/02/hello-world/"/>
      <url>/2023/11/02/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
