
<!DOCTYPE html><html lang="zh-CN">

<head>
  <meta charset="utf-8">
  <meta name="hexo-theme" content="https://github.com/xaoxuu/hexo-theme-stellar/tree/1.27.0" theme-name="Stellar" theme-version="1.27.0">
  
  <meta name="generator" content="Hexo 7.0.0">
  <meta http-equiv='x-dns-prefetch-control' content='on' />
  
  <meta name="renderer" content="webkit">
  <meta name="force-rendering" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  <meta name="HandheldFriendly" content="True" >
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="theme-color" content="#f8f8f8">
  
  <title>我们可以通过情景学习来编辑事实知识吗？ - humbleyl</title>

  
    <meta name="description" content="我们可以通过情景学习来编辑事实知识吗？Abstract之前的研究表明，像 GPT 这样的大型语言模型 (LLM) 在其参数中存储了大量事实知识。然而，存储的知识可能是错误的或过时的。传统的知识编辑方法通过对包含特定知识的文本进行微调来完善LLMs。然而，随着LLMs规模的不断扩大，这些基于梯度的方法带来了巨大的计算成本。模型即服务的趋势也使得修改黑盒 LM 中的知识变得不可能。受到上下文学习（IC">
<meta property="og:type" content="article">
<meta property="og:title" content="我们可以通过情景学习来编辑事实知识吗？">
<meta property="og:url" content="http://humble2967738843.github.io/2023/11/02/wo-men-ke-yi-tong-guo-qing-jing-xue-xi-lai-bian-ji-shi-shi-zhi-shi-ma/index.html">
<meta property="og:site_name" content="humbleyl">
<meta property="og:description" content="我们可以通过情景学习来编辑事实知识吗？Abstract之前的研究表明，像 GPT 这样的大型语言模型 (LLM) 在其参数中存储了大量事实知识。然而，存储的知识可能是错误的或过时的。传统的知识编辑方法通过对包含特定知识的文本进行微调来完善LLMs。然而，随着LLMs规模的不断扩大，这些基于梯度的方法带来了巨大的计算成本。模型即服务的趋势也使得修改黑盒 LM 中的知识变得不可能。受到上下文学习（IC">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://humble2967738843.github.io/2023/11/02/imgs/$%7Bfiilename%7D/M6YKHBS2.png">
<meta property="og:image" content="http://humble2967738843.github.io/2023/11/02/imgs/$%7Bfiilename%7D/ZLL8JITP.png">
<meta property="og:image" content="http://humble2967738843.github.io/2023/11/02/imgs/$%7Bfiilename%7D/QTYQT47T.png">
<meta property="og:image" content="http://humble2967738843.github.io/2023/11/02/imgs/$%7Bfiilename%7D/P6MNIS5S.png">
<meta property="og:image" content="http://humble2967738843.github.io/2023/11/02/imgs/$%7Bfiilename%7D/HKQ4CHLZ.png">
<meta property="og:image" content="http://humble2967738843.github.io/2023/11/02/imgs/$%7Bfiilename%7D/A9BSU2NB.png">
<meta property="og:image" content="http://humble2967738843.github.io/2023/11/02/imgs/$%7Bfiilename%7D/JRUG4L94.png">
<meta property="article:published_time" content="2023-11-02T04:21:08.000Z">
<meta property="article:modified_time" content="2024-05-26T09:35:38.721Z">
<meta property="article:author" content="yuan long">
<meta property="article:tag" content="EMNLP2023">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://humble2967738843.github.io/2023/11/02/imgs/$%7Bfiilename%7D/M6YKHBS2.png">
<meta name="twitter:creator" content="@humbleyl">
  
  
  
  <meta name="keywords" content="EMNLP2023">

  <!-- feed -->
  
    <link rel="alternate" href="/atom.xml" title="humbleyl" type="application/atom+xml">
  

  <link rel="stylesheet" href="/css/main.css?v=1.27.0">

  
    <link rel="shortcut icon" href="solar:documents-bold-duotone">
  

  

  
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --></head>
<body>

<div class="l_body s:aa content tech" id="start" layout="post" ><aside class="l_left"><div class="leftbar-container">


<header class="header"><div class="logo-wrap"><a class="avatar" href="/about/"><div class="bg" style="opacity:0;background-image:url(https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/avatar/round/rainbow64@3x.webp);"></div><img no-lazy class="avatar" src="https://s2.loli.net/2024/04/10/32Y4obwgxJCeOMr.png" onerror="javascript:this.classList.add('error');this.src='https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/image/2659360.svg';"></a><a class="title" href="/"><div class="main" ff="title">humbleyl</div><div class="sub normal cap">院龙的博客</div><div class="sub hover cap" style="opacity:0"> humbleyl</div></a></div></header>

<div class="nav-area">
<div class="search-wrapper" id="search-wrapper"><form class="search-form"><a class="search-button" onclick="document.getElementById(&quot;search-input&quot;).focus();"><svg t="1705074644177" viewBox="0 0 1025 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="1560" width="200" height="200"><path d="M1008.839137 935.96571L792.364903 719.491476a56.783488 56.783488 0 0 0-80.152866 0 358.53545 358.53545 0 1 1 100.857314-335.166073 362.840335 362.840335 0 0 1-3.689902 170.145468 51.248635 51.248635 0 1 0 99.217358 26.444296 462.057693 462.057693 0 1 0-158.255785 242.303546l185.930047 185.725053a51.248635 51.248635 0 0 0 72.568068 0 51.248635 51.248635 0 0 0 0-72.978056z" p-id="1561"></path><path d="M616.479587 615.969233a50.428657 50.428657 0 0 0-61.498362-5.534852 174.655348 174.655348 0 0 1-177.525271 3.484907 49.403684 49.403684 0 0 0-58.833433 6.76482l-3.074918 2.869923a49.403684 49.403684 0 0 0 8.609771 78.10292 277.767601 277.767601 0 0 0 286.992355-5.739847 49.403684 49.403684 0 0 0 8.404776-76.667958z" p-id="1562"></path></svg></a><input type="text" class="search-input" id="search-input" placeholder="站内搜索"></form><div id="search-result"></div><div class="search-no-result">没有找到内容！</div></div>


<nav class="menu dis-select"><a class="nav-item active" title="博客" href="/" style="color:#1BCDFC"><svg t="1716731776385" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="17107" width="300" height="300"><path d="M1017.771 511.331c0 280.666-227.523 508.191-508.191 508.191s-508.19-227.525-508.19-508.191c0-280.665 227.523-508.19 508.191-508.19s508.19 227.523 508.19 508.19zM191.726 479.984h26.423v188.788h40.113v-188.788h23.558v-37.567h-23.558v-84.048h-40.113v84.048h-26.423v37.567zM274.182 598.096h46.958l-17.669 18.465c15.493 11.884 29.502 23.241 42.023 34.065l25.787-28.334c-10.932-8.701-21.703-16.766-32.314-24.195h92.165v16.555c0 4.882-1.221 9.022-3.662 12.417-2.443 3.395-8.332 5.093-17.669 5.093-8.703 0-21.437-0.532-38.205-1.591 4.88 16.766 8.063 29.393 9.551 37.885 31.622 0 51.998-1.036 61.126-3.104 9.126-2.068 16.023-6.475 20.692-13.212 4.669-6.74 7.004-15.734 7.004-26.981v-27.061h36.929v-31.2h-36.929v-12.417h20.375v-126.389h-81.5v-15.281h94.871v-31.2h-25.15c-7.217-9.973-14.326-19.314-21.33-28.017l-28.334 14.007 10.029 14.007h-30.085v-25.151h-37.567v25.151h-91.687v31.2h91.687v15.281h-78.636v128.3h38.205v-16.236h40.432v14.964h37.567v-14.964h43.298v9.551h-21.012v17.191h-156.951v31.2zM330.85 456.107h40.432v16.555h-40.432v-16.555zM330.85 498.13h40.432v16.555h-40.432v-16.555zM452.146 472.662h-43.298v-16.555h43.298v16.555zM408.85 498.13h43.298v16.555h-43.298v-16.555zM605.279 670.683v-15.281h139.442v15.281h43.298v-109.039c9.443 1.591 19.205 3.131 29.289 4.615l15.919-39.158c-42.449-2.547-79.008-7.323-109.675-14.326 23.241-12.838 42.819-27.697 58.738-44.571v-10.188h38.205v-75.771h-113.179c-3.715-11.247-7.059-20.692-10.029-28.334l-54.441 5.411 9.87 22.923h-123.526v75.771h43.616v-39.796h204.069v19.739h-119.068c3.82-4.14 7.427-8.382 10.825-12.735h-49.346c-22.711 23.558-52.107 43.086-88.186 58.579 8.063 8.703 16.023 18.465 23.877 29.289 15.068-7.642 29.076-15.703 42.023-24.195 9.973 9.129 20.587 17.139 31.836 24.036-30.563 7.537-68.026 14.062-112.382 19.579 5.731 11.461 11.037 23.666 15.919 36.611 10.188-1.696 20.057-3.447 29.609-5.253v106.81h43.296zM774.487 559.257h-190.062c35.339-7.534 65.687-15.81 91.052-24.832 27.061 9.445 60.063 17.725 99.010 24.832zM744.721 619.108h-139.442v-23.558h139.442v23.558zM628.359 470.433h96.305c-14.54 11.249-30.777 20.534-48.709 27.857-17.723-7.323-33.586-16.607-47.596-27.857z" fill="#272636" p-id="17108"></path></svg></a><a class="nav-item" title="文档" href="/wiki/" style="color:#3DC550"><svg t="1716731927468" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="29342" width="300" height="300"><path d="M931.607098 176.851787H459.277181l-13.308673-44.020995c-5.11872-17.147713-20.858785-28.92077-38.774307-28.92077H92.136966c-22.394401 0-40.565859 18.043489-40.565859 40.437891V879.268183c0 22.394401 18.043489 40.565859 40.437891 40.565858H931.607098c22.394401 0 40.437891-18.171457 40.565859-40.565858V217.289678c0-22.266433-18.171457-40.437891-40.565859-40.437891z" fill="#FFA000" p-id="29343"></path><path d="M867.87903 869.414646H155.865034c-22.394401 0-40.565859-18.043489-40.565859-40.43789V279.226193c0-22.394401 18.043489-40.565859 40.437891-40.565858h712.141964c22.394401 0 40.565859 18.043489 40.565859 40.43789V828.976756c0 22.394401-18.171457 40.565859-40.565859 40.43789z" fill="#FFFFFF" p-id="29344"></path><path d="M931.607098 919.834041H92.136966c-22.394401 0-40.565859-18.043489-40.565859-40.43789V355.367158c0-22.394401 18.043489-40.565859 40.437891-40.565858H931.607098c22.394401 0 40.565859 18.043489 40.565859 40.43789v524.028993c-0.127968 22.394401-18.171457 40.565859-40.565859 40.565858z" fill="#FFCA28" p-id="29345"></path><path d="M379.553112 482.311422H156.76081c-11.133217 0-20.218945-9.085729-20.218945-20.346913 0-11.133217 9.085729-20.218945 20.218945-20.218945h222.92027c11.133217 0 20.218945 9.085729 20.346913 20.218945-0.127968 11.261185-9.213697 20.346913-20.474881 20.346913 0.127968 0 0 0 0 0z m0 137.693577H156.76081c-11.133217 0-20.218945-9.085729-20.218945-20.346914 0-11.133217 9.085729-20.218945 20.218945-20.218945h222.92027c11.133217 0 20.218945 9.085729 20.346913 20.218945-0.127968 11.261185-9.213697 20.346913-20.474881 20.346914 0.127968 0 0 0 0 0z" fill="#FFFFFF" p-id="29346"></path><path d="M844.972757 768.703824l-109.540615-72.301924c-3.327168-2.303424-7.806048-2.303424-11.133217 0l-109.540615 72.429892c-4.734816 3.071232-11.005249 1.791552-14.07648-2.815296-1.151712-1.663584-1.663584-3.583104-1.663585-5.630592V313.393652c0-11.133217 8.701825-20.218945 19.32317-20.218946h222.92027c10.621345 0 19.323169 9.085729 19.323169 20.218946v446.864284c0.127968 5.502624-4.350912 10.109473-9.981505 10.23744-1.91952 0-3.967008-0.63984-5.630592-1.791552z" fill="#F44336" p-id="29347"></path></svg></a><a class="nav-item" title="在线简历" href="/explore/" style="color:#FA6400"><svg t="1716732005879" class="icon" viewBox="0 0 1160 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="31680" width="300" height="300"><path d="M1052.97035029 374.93800508L595.69272266 590.84097031c-14.55525615 8.49056572-32.74932656 8.49056572-47.30458272 0L89.89757422 374.93800508C64.42587617 361.59568701 54.72237237 331.2722375 68.06469043 305.80053945c4.85175234-9.70350381 12.12937998-16.98113232 21.83288379-21.83288466L548.38813994 68.06469043c14.55525615-8.49056572 32.74932656-8.49056572 47.30458272 0l458.49056572 215.90296436c25.47169805 13.34231807 35.17520185 43.66576846 21.83288379 69.13746649-6.06469043 9.70350381-13.34231807 16.98113232-23.04582188 21.8328838z m-817.52021542 120.0808626L547.17520185 641.78436641c14.55525615 8.49056572 32.74932656 8.49056572 47.30458272 0l311.72506699-146.76549873v298.3827498c0 92.18328838-150.40431299 167.38544443-335.98382695 167.38544444S235.45013487 886.79784395 235.45013487 793.40161748V495.01886768z" fill="#2F77F1" p-id="31681"></path><path d="M1056.60916455 424.66846396c13.34231807 0 24.25875996 10.9164419 24.25875996 24.25875997v145.55256064c0 13.34231807-10.9164419 24.25875996-24.25875996 24.25875996s-24.25875996-10.9164419-24.25875996-24.25875996v-145.55256064c0-13.34231807 10.9164419-24.25875996 24.25875996-24.25875997z" fill="#AFFCFE" p-id="31682"></path></svg></a><a class="nav-item" title="社交" href="/friends/" style="color:#F44336"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><path fill="currentColor" d="m13.629 20.472l-.542.916c-.483.816-1.69.816-2.174 0l-.542-.916c-.42-.71-.63-1.066-.968-1.262c-.338-.197-.763-.204-1.613-.219c-1.256-.021-2.043-.098-2.703-.372a5 5 0 0 1-2.706-2.706C2 14.995 2 13.83 2 11.5v-1c0-3.273 0-4.91.737-6.112a5 5 0 0 1 1.65-1.651C5.59 2 7.228 2 10.5 2h3c3.273 0 4.91 0 6.113.737a5 5 0 0 1 1.65 1.65C22 5.59 22 7.228 22 10.5v1c0 2.33 0 3.495-.38 4.413a5 5 0 0 1-2.707 2.706c-.66.274-1.447.35-2.703.372c-.85.015-1.275.022-1.613.219c-.338.196-.548.551-.968 1.262" opacity=".5"/><path fill="currentColor" d="M10.99 14.308c-1.327-.978-3.49-2.84-3.49-4.593c0-2.677 2.475-3.677 4.5-1.609c2.025-2.068 4.5-1.068 4.5 1.609c0 1.752-2.163 3.615-3.49 4.593c-.454.335-.681.502-1.01.502c-.329 0-.556-.167-1.01-.502"/></svg></a></nav>
</div>
<div class="widgets">
<widget class="widget-wrapper post-list"><div class="widget-header dis-select"><span class="name">专栏：自然语言处理论文阅读</span></div><div class="widget-body"><a class="item" href="/2024/05/06/ji-yu-lian-shi-tui-li-de-wen-dang-ji-shi-jian-lun-yuan-ti-qu/"><span class="title">基于链式推理的文档级事件论元提取</span></a><a class="item" href="/2023/11/06/wang-diao-ni-xiang-wang-diao-de-dong-xi-llms-de-gao-xiao-wang-que/"><span class="title">忘掉你想忘掉的东西：LLMs的高效忘却</span></a><a class="item" href="/2023/11/02/qing-jing-xue-xi-chuang-jian-ren-wu-xiang-liang/"><span class="title">情境学习创建任务向量</span></a><a class="item" href="/2023/11/02/bian-ji-da-xing-yu-yan-mo-xing-wen-ti-fang-fa-he-ji-yu/"><span class="title">编辑大型语言模型：问题、方法和机遇</span></a><a class="item" href="/2023/11/02/zhi-shi-shen-jing-yuan-zhong-xin-zhi-lu-yu-yan-wu-guan-zhi-shi-shen-jing-yuan-he-jian-bing-zhi-shi-shen-jing-yuan-de-fa-xian/"><span class="title">知识神经元中心之旅：语言无关知识神经元和简并知识神经元的发现</span></a><a class="item active" href="/2023/11/02/wo-men-ke-yi-tong-guo-qing-jing-xue-xi-lai-bian-ji-shi-shi-zhi-shi-ma/"><span class="title">我们可以通过情景学习来编辑事实知识吗？</span><svg class="active-icon" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><path fill="currentColor" d="M21 11.098v4.993c0 3.096 0 4.645-.734 5.321c-.35.323-.792.526-1.263.58c-.987.113-2.14-.907-4.445-2.946c-1.02-.901-1.529-1.352-2.118-1.47a2.225 2.225 0 0 0-.88 0c-.59.118-1.099.569-2.118 1.47c-2.305 2.039-3.458 3.059-4.445 2.945a2.238 2.238 0 0 1-1.263-.579C3 20.736 3 19.188 3 16.091v-4.994C3 6.81 3 4.666 4.318 3.333C5.636 2 7.758 2 12 2c4.243 0 6.364 0 7.682 1.332C21 4.665 21 6.81 21 11.098" opacity=".5"/><path fill="currentColor" d="M9 5.25a.75.75 0 0 0 0 1.5h6a.75.75 0 0 0 0-1.5z"/></svg></a><a class="item" href="/2023/11/02/wo-men-ke-yi-bian-ji-duo-mo-tai-da-xing-yu-yan-mo-xing-ma/"><span class="title">我们可以编辑多模态大型语言模型吗？</span></a><a class="item" href="/2023/11/02/duo-yu-yan-mo-xing-zhong-shi-shi-zhi-shi-de-kua-yu-yan-yi-zhi-xing/"><span class="title">多语言模型中事实知识的跨语言一致性</span></a></div></widget>

<widget class="widget-wrapper post-list"><div class="widget-header dis-select"><span class="name">最近更新</span></div><div class="widget-body fs14"><a class="item title" href="/2023/11/02/duo-yu-yan-mo-xing-zhong-shi-shi-zhi-shi-de-kua-yu-yan-yi-zhi-xing/"><span class="title">多语言模型中事实知识的跨语言一致性</span></a><a class="item title" href="/2024/05/06/ji-yu-lian-shi-tui-li-de-wen-dang-ji-shi-jian-lun-yuan-ti-qu/"><span class="title">基于链式推理的文档级事件论元提取</span></a><a class="item title" href="/2023/11/02/zhi-shi-shen-jing-yuan-zhong-xin-zhi-lu-yu-yan-wu-guan-zhi-shi-shen-jing-yuan-he-jian-bing-zhi-shi-shen-jing-yuan-de-fa-xian/"><span class="title">知识神经元中心之旅：语言无关知识神经元和简并知识神经元的发现</span></a><a class="item title" href="/2023/11/02/wo-men-ke-yi-tong-guo-qing-jing-xue-xi-lai-bian-ji-shi-shi-zhi-shi-ma/"><span class="title">我们可以通过情景学习来编辑事实知识吗？</span></a><a class="item title" href="/2023/11/02/wo-men-ke-yi-bian-ji-duo-mo-tai-da-xing-yu-yan-mo-xing-ma/"><span class="title">我们可以编辑多模态大型语言模型吗？</span></a><a class="item title" href="/2023/11/06/wang-diao-ni-xiang-wang-diao-de-dong-xi-llms-de-gao-xiao-wang-que/"><span class="title">忘掉你想忘掉的东西：LLMs的高效忘却</span></a><a class="item title" href="/2023/11/02/qing-jing-xue-xi-chuang-jian-ren-wu-xiang-liang/"><span class="title">情境学习创建任务向量</span></a><a class="item title" href="/2023/11/06/ji-yu-ti-shi-de-ling-yang-ben-guan-xi-chou-qu-fang-fa-tan-suo/"><span class="title">基于提示的零样本关系抽取方法探索</span></a><a class="item title" href="/2023/11/02/bian-ji-da-xing-yu-yan-mo-xing-wen-ti-fang-fa-he-ji-yu/"><span class="title">编辑大型语言模型：问题、方法和机遇</span></a><a class="item title" href="/2023/11/03/bing-fa-bian-cheng/"><span class="title">并发编程</span></a></div></widget>
</div>
<footer class="footer dis-select"><div class="social-wrap"><a class="social" href="https://github.com/Humble2967738843" target="_blank" rel="external nofollow noopener noreferrer"><svg t="1716701113980" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="4745" width="200" height="200"><path d="M512 512m-469.333333 0a469.333333 469.333333 0 1 0 938.666666 0 469.333333 469.333333 0 1 0-938.666666 0Z" fill="#434A54" p-id="4746"></path><path d="M610.688 808.149333c0-12.074667 0.426667-51.498667 0.426667-100.437333 0-34.133333-11.733333-56.448-24.832-67.84 81.493333-9.045333 167.125333-39.978667 167.125333-180.608 0-39.936-14.208-72.618667-37.674667-98.261333 3.84-9.216 16.341333-46.421333-3.584-96.853334 0 0-30.72-9.813333-100.565333 37.546667a351.658667 351.658667 0 0 0-91.733333-12.373333 350.549333 350.549333 0 0 0-91.605334 12.373333c-69.973333-47.36-100.693333-37.546667-100.693333-37.546667-19.882667 50.432-7.338667 87.637333-3.541333 96.853334a141.653333 141.653333 0 0 0-37.717334 98.261333c0 140.288 85.461333 171.690667 166.784 180.906667-10.453333 9.173333-19.968 25.301333-23.253333 48.981333-20.906667 9.386667-73.856 25.514667-106.496-30.421333 0 0-19.370667-35.157333-56.149333-37.76 0 0-35.712-0.426667-2.474667 22.272 0 0 23.978667 11.264 40.618667 53.546666 0 0 21.504 65.365333 123.349333 43.221334 0.170667 30.592 0.512 59.392 0.512 68.138666a19.968 19.968 0 0 1-2.218667 9.173334 339.925333 339.925333 0 0 0 187.904 3.114666 19.2 19.2 0 0 1-4.181333-12.288z" fill="#FFFFFF" p-id="4747"></path><path d="M180.138667 843.861333A467.882667 467.882667 0 0 0 512 981.333333c259.2 0 469.333333-210.133333 469.333333-469.333333 0-129.621333-52.522667-246.954667-137.472-331.861333L180.138667 843.861333z" fill="#231F20" opacity=".1" p-id="4748"></path></svg></a><a class="social" href="https://" target="_blank" rel="external nofollow noopener noreferrer"><svg t="1716701237965" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="12408" width="200" height="200"><path d="M276.822886 874.188342c-47.901937-0.484303-85.721573-1.942714-96.222136 64.483801-4.204628 59.150968 41.545465 67.092431 120.596869 81.461911 86.981861 4.49631 137.949214 16.482801 205.118694-49.93821l-227.814878-96.106564" fill="" p-id="12409"></path><path d="M270.939709 875.64125c-24.792995 0-64.296684-0.968605-81.098684 43.647779 2.102314 5.332833 12.327704 2.982864 18.794246-1.562977 9.691557-4.589869 5.162226 1.799625-5.552971 10.412507-11.661788 8.12858-37.660036 34.54509 6.461038 61.633019 46.801249 21.645028 193.974228 61.280799 285.678041-16.169105 0 0-180.892553-56.256158-222.493052-97.944713h-1.788618v-0.01651z" fill="#F0971C" p-id="12410"></path><path d="M764.482659 865.94419c47.896434-0.484303 85.710567-1.948218 96.222136 64.4838 4.204628 59.150968-64.731455 68.859035-120.602373 81.461912-59.734332 5.51995-137.949214 16.488305-205.118693-49.93821l227.820381-96.106564" fill="" p-id="12411"></path><path d="M770.360332 867.402601c24.787491 0 64.29118-0.974109 81.087678 43.642275-2.09681 5.332833-12.316698 2.982864-18.777736-1.562976-9.708067-4.589869-5.16773 1.799625 5.547467 10.412507 11.661788 8.123077 37.66554 34.54509-6.461038 61.633019-46.801249 21.645028-193.974228 61.275295-285.683544-16.174609 0 0 180.903559-56.250655 222.504059-97.939209l1.783114-0.011007z" fill="#F0971C" p-id="12412"></path><path d="M825.598354 441.216247c51.259035 54.307941 83.206502 107.641773 108.412255 245.337829 3.417636 83.393619-7.567229 91.153468-31.947466 113.453405-17.638524-2.905816-36.124577-30.059786-54.616134-94.070291-18.491557-63.993994-21.848655-264.720943-21.848655-264.720943z" fill="" p-id="12413"></path><path d="M847.452513 380.128069c0-15.21701-4.716448-29.894683-13.466917-43.741337C832.994977 150.420008 697.560835 0 530.619501 0 363.683671 0 228.249529 150.420008 227.25891 336.386732c-8.744965 13.852157-13.466916 28.52983-13.466917 43.735833 0 22.228392 10.043777 43.334083 28.078549 62.342963 39.349592 136.000997 153.744086 234.385984 288.748959 234.385984 135.015881 0 249.404871-98.384988 288.759967-234.385984 18.034771-19.003377 28.073045-40.109067 28.073045-62.337459zM198.035646 442.184853C146.771107 496.48729 114.834648 549.826626 89.623392 687.517178c-3.423139 83.393619 25.899186 111.031892 31.936459 113.458909 6.042777 2.410506 36.135584-30.06529 54.62714-94.064788 18.486053-63.988491 21.848655-264.726446 21.848655-264.726446z" fill="" p-id="12414"></path><path d="M864.254513 621.585973c0 200.82601-158.394492 363.634261-353.810621 363.634261-195.394116 0-353.805118-162.80825-353.805118-363.634261 0-200.831514 158.405499-363.639764 353.805118-363.639764 195.410626 0 353.810621 162.802747 353.810621 363.639764z" fill="" p-id="12415"></path><path d="M220.50619 696.245633c0 149.952216 134.702185 271.517691 300.86203 271.517691 166.154342 0 300.86203-121.565475 300.86203-271.517691s-134.707688-271.517691-300.86203-271.51769c-166.154342 0.005503-300.86203 121.565475-300.86203 271.51769z" fill="#FFFFFF" p-id="12416"></path><path d="M232.068916 322.672161s-23.950969 19.636272-18.909818 60.361724c-25.211256 30.544089-20.797498 62.54659-9.454909 95.281048 18.909818 62.788741 146.650152 162.665161 309.684043 162.665161 223.544209-15.018886 289.090173-123.392617 338.890797-180.122071 0 0 29.003126-47.280049-18.909818-129.457407l-72.491305 7.275547-528.80899-16.004002z" fill="" p-id="12417"></path><path d="M302.980734 572.85852c-3.147967 33.086678-15.128955 139.996494 3.786366 166.545086 20.170106 26.190869 44.43477 38.909317 96.112067 30.907316 23.323577-7.638774 28.364727-29.817635 26.163352-61.809129l-0.946592-92.364225-125.115193-43.279048z" fill="" p-id="12418"></path><path d="M223.246902 372.126068s83.200998 144.002998 271.033388 151.273041c83.206502 1.458411 167.662284 8.728455 292.458278-87.26804 24.583864-25.453408 29.003126-33.455409 29.003126-33.455409s8.189118 65.457909-112.820509 147.635268c0 0 82.562599 0.731957 141.812629-170.182859 0 0 29.003126 111.274043-72.480298 164.36022-93.288803 56.008504-154.432015 93.090679-309.480417 84.362224-101.874168-25.326829-254.005746-65.457909-264.726446-192.730451 0 0 6.306942-29.817635 14.49606-24.000499 0 0 0.627392 69.095683 52.943088 92.364225-0.011007 0.005503-52.326703-77.807627-42.238899-132.35772z" fill="#E71F19" p-id="12419"></path><path d="M321.059532 589.605486s-36.240149 138.185862 4.413759 161.459908c41.2813 19.273045 66.498059 14.182364 94.229891 4.727454 11.661788-16.004002 1.260288-111.63727 4.721951-121.455406-6.306942-4.006504-24.892057-8.370731-28.051031-8.370731 0 0-2.834271 40.719949-0.313696 65.463413-5.046654-19.273045-8.827517-19.273045-8.827517-71.275045-30.235897-10.550093-66.173356-30.549593-66.173357-30.549593z" fill="#E71F19" p-id="12420"></path><path d="M506.316313 242.426509c0 50.60963-22.487054 91.637771-50.218886 91.637771s-50.218885-41.028141-50.218885-91.637771 22.487054-91.637771 50.218885-91.63777c27.731832-0.005503 50.218885 41.022638 50.218886 91.63777z m147.492178 0c0 50.60963-22.498061 91.637771-50.218885 91.637771-27.731832 0-50.218885-41.028141-50.218886-91.637771s22.487054-91.637771 50.218886-91.63777c27.726328-0.005503 50.218885 41.022638 50.218885 91.63777z" fill="#FFFFFF" p-id="12421"></path><path d="M499.530572 243.395115c0 19.553721-8.469793 35.398123-18.915322 35.398123-10.440025 0-18.915322-15.844402-18.915321-35.398123 0-19.548217 8.469793-35.398123 18.915321-35.398123 10.445528 0.005503 18.915322 15.855409 18.915322 35.398123z m74.791742 10.54459c-1.794121-18.238398 8.662414-44.368729 29.151719-37.638023 14.86479 6.730706 14.028267 32.547341 13.703565 39.096434-0.324703 6.538086-8.97611 11.089431-12.922076 0-1.893183-10.36848-10.093308-41.63352-17.176235-2.371982-2.360976 9.091682-11.969981 8.915572-12.756973 0.913571z" fill="" p-id="12422"></path><path d="M676.779847 358.472035c-37.032644-15.618761-89.452905-25.381863-147.624261-25.381863-56.872544 0-108.236144 9.32833-145.109189 24.347216-30.57711 12.44878-57.648529 34.567103-56.597371 47.02689 3.153471 12.503815 13.13671 20.626891 68.176608 29.118699-19.53721-18.915322-15.21701-14.600625-15.21701-43.5212 0 28.920575 23.48868 43.669792 61.357847 59.42614 24.853533 10.340963 55.386615 16.455284 88.418259 16.455284 34.677172 0 66.602625-6.73621 92.072542-18.023764 35.805377-15.855409 53.108191-28.661913 53.108191-56.6414 0 27.979486 5.773108 19.030894-17.242276 42.310443 53.366853-9.383364 70.17986-19.757348 71.5227-32.525327 0.022014-11.238023-25.55247-31.072419-52.86604-42.591118z" fill="#F0971C" p-id="12423"></path></svg></a><a class="social" href="https://www.kaggle.com/humbleyll" target="_blank" rel="external nofollow noopener noreferrer"><svg t="1716701307894" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="13418" width="200" height="200"><path d="M803.1909 1017.952189c-0.927971 3.935877-4.991844 6.015812-11.999625 6.015812H657.27546c-7.967751 0-14.975532-3.487891-20.991344-10.591669l-220.921096-281.111215-61.790069 58.622168v218.073185c0 10.015687-4.991844 15.007531-14.975532 15.007531H234.88866c-10.079685 0-15.103528-4.991844-15.103528-15.007531V15.071529C219.785132 5.11984 224.808975 0 234.88866 0h103.708759c9.983688 0 14.975532 5.11984 14.975532 15.071529v611.948877l264.663729-267.607638c7.03978-7.03978 14.07956-10.495672 21.11934-10.495672h138.203681c6.143808 0 10.079685 2.55992 12.15962 7.67976 1.951939 6.367801 1.439955 10.87966-1.535952 13.43958l-279.67126 270.679542 291.670885 362.964657c4.063873 4.447861 4.991844 8.863723 2.975907 15.263523z" fill="#20BEFF" p-id="13419"></path></svg></a><a class="social" href="https://" target="_blank" rel="external nofollow noopener noreferrer"><svg t="1716701358358" class="icon" viewBox="0 0 1025 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="14411" width="200" height="200"><path d="M1024.16 694.816c0-149.92-143.104-271.392-319.584-271.392-176.576 0-319.68 121.504-319.68 271.392S528 966.208 704.576 966.208c55.456 0 107.648-12.096 153.184-33.248l125.984 54.528-14.592-140.544c34.784-43.392 55.04-95.808 55.04-152.128zM596.832 621.28c-25.152 0-45.472-20.352-45.472-45.472s20.32-45.472 45.472-45.472c25.12 0 45.44 20.384 45.44 45.472s-20.384 45.472-45.44 45.472z m215.392 0c-25.056 0-45.44-20.352-45.44-45.472s20.384-45.472 45.44-45.472c25.184 0 45.536 20.384 45.536 45.472s-20.352 45.472-45.536 45.472zM704.576 387.488c49.376 0 96.416 8.8 139.264 24.64 0.32-5.728 0.992-11.232 0.992-16.992 0-198.08-189.152-358.624-422.432-358.624C189.184 36.512 0.032 197.024 0.032 395.136c0 74.496 26.816 143.776 72.704 201.12L53.472 781.92l166.432-72.096c41.216 19.2 86.784 32.16 134.88 38.784-3.616-17.504-5.824-35.424-5.824-53.792 0.032-169.44 159.552-307.296 355.616-307.296z m-139.808-209.6c33.184 0 60 26.88 60 60 0 33.184-26.816 60.064-60 60.064s-60.032-26.88-60.032-60.064c0-33.152 26.88-60 60.032-60zM280.032 297.952c-33.184 0-60-26.88-60-60.064 0-33.152 26.848-60 60-60 33.184 0 60.032 26.88 60.032 60s-26.88 60.064-60.032 60.064z" fill="#51C332" p-id="14412"></path></svg></a></div></footer>
</div></aside><div class="l_main" id="main">





<div class="article banner top">
  <div class="content">
    <div class="top bread-nav footnote"><div class="left"><div class="flex-row" id="breadcrumb"><a class="cap breadcrumb" href="/">主页</a>
<span class="sep"></span><a class="cap breadcrumb" id="menu" href="/topic">专栏</a><span class="sep"></span><a class="cap breadcrumb" id="proj" href="/2024/05/06/ji-yu-lian-shi-tui-li-de-wen-dang-ji-shi-jian-lun-yuan-ti-qu/">自然语言处理论文阅读</a></div>
<div class="flex-row" id="post-meta"><span class="text created">发布于：<time datetime="2023-11-02T04:21:08.000Z">2023-11-02</time></span><span class="sep updated"></span><span class="text updated">更新于：<time datetime="2024-05-26T09:35:38.721Z">2024-05-26</time></span></div></div></div>
    
    <div class="bottom only-title">
      
      <div class="text-area">
        <h1 class="text title"><span>我们可以通过情景学习来编辑事实知识吗？</span></h1>
        
      </div>
    </div>
    
  </div>
  </div><article class="md-text content"><h1 id="我们可以通过情景学习来编辑事实知识吗？"><a href="#我们可以通过情景学习来编辑事实知识吗？" class="headerlink" title="我们可以通过情景学习来编辑事实知识吗？"></a>我们可以通过情景学习来编辑事实知识吗？</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>之前的研究表明，像 GPT 这样的大型语言模型 (LLM) 在其参数中存储了大量事实知识。然而，存储的知识可能是错误的或过时的。传统的知识编辑方法通过对包含特定知识的文本进行微调来完善LLMs。然而，随着LLMs规模的不断扩大，这些基于梯度的方法带来了巨大的计算成本。模型即服务的趋势也使得修改黑盒 LM 中的知识变得不可能。<span style="background-color: #ff666680">受到上下文学习（ICL）这种基于演示上下文而无需参数更新的新范式的启发</span>，我们探索 ICL 是否可以编辑事实知识。为了回答这个问题，我们对 ICL 策略进行了全面的实证研究。实验表明，<span style="background-color: #ff666680">与 GPT-J (6B) 上基于梯度的方法相比，上下文知识编辑 (IKE) 在没有任何梯度和参数更新的情况下实现了有竞争力的成功率，但副作用要少得多，包括减少对相似但不相关事实的过度编辑以及更少的对先前存储的知识的遗忘</span>。我们还将该方法应用于具有数十或数百个参数的大型 LM，例如 OPT-175B，这显示了我们方法的可扩展性。该代码可在<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FLB4642KE%22%2C%22pageLabel%22%3A%221%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B233.271%2C260.191%2C273.121%2C269.098%5D%2C%5B87.874%2C248.236%2C225.359%2C257.143%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F8YZC667S%22%5D%2C%22locator%22%3A%221%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/LB4642KE?page=1">“https:// github.com/PKUnlp-icler/IKE.”</a></span></p>
<h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h2><p>预训练语言模型 (LM) 为 NLP 研究树立了新范式，并席卷了所有现有的 NLP 基准。由于取得了令人鼓舞的成果，研究人员为 LM 赋予了满足现实世界需求的新技能，例如使用网络浏览器（Nakano 等人，2021）、编码（Chen 等人，2021）、玩策略游戏（FAIR 等人） al.，2022）和对话人才（OpenAI，2022、2023）。然而，语言模型的广泛应用也引发了人们对其生成虚假内容的陷阱的日益关注（Elazar et al., 2021；Cao</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="../imgs/$%7Bfiilename%7D/M6YKHBS2.png" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;M6YKHBS2&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FLB4642KE%22%2C%22annotationKey%22%3A%22FY8NBQWF%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B302.763%2C474.785%2C526.974%2C629.522%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F8YZC667S%22%5D%2C%22locator%22%3A%221%22%7D%7D&quot; width=&quot;374&quot; height=&quot;258&quot; src=&quot;attachments/M6YKHBS2.png&quot; ztype=&quot;zimage&quot;&gt;"></p>
<p>等人，2021a）、过时（Dhingra 等人，2022）、有偏见（Sheng 等人，2019；Zhao 等人，2021）和攻击性（Gehman 等人，2020）。为了缓解这一缺陷，旨在修改语言学习者所学到的知识的知识编辑（图 1）引起了越来越多的关注（Mitchell 等人，2022a；Meng 等人，2022a)。知识编辑的目标有两个：概括性和特异性。前者需要泛化到描述相同知识的各种提示，后者则不需要干扰其他不相关的知识。</p>
<pre><code> 以往的知识编辑方法主要采用&lt;span style=&quot;background-color: #2ea8e580&quot;&gt;基于梯度的方法来修改特定的模型参数以获得所需的模型行为&lt;/span&gt;（Mitchell等，2021；Meng等，2022a），例如在选举后更新总统。然而，&lt;span style=&quot;background-color: #5fb23680&quot;&gt;目标知识神经元的识别通常需要计算开销很大的梯度估计&lt;/span&gt;（Dai et al., 2022）。此外，&lt;span style=&quot;background-color: #2ea8e580&quot;&gt;更新的参数本身会导致超出所需版本的副作用，例如忘记以前学到的事实或对不相关事实进行过度编辑&lt;/span&gt;。先前的研究表明，当大规模 LM (LLM) 作为黑盒服务部署时（Sun 等人，2022），&lt;span style=&quot;background-color: #2ea8e580&quot;&gt;对其参数的微小修改可能会极大地影响其最终用户的行为&lt;/span&gt;。因此，传统方法仍然受到编辑 LLM arXiv:2305.12740v1 \[cs.CL] 202 年 5 月 22 日的困扰，因为这些限制阻碍了可扩展性和通用性。

 最近，情境学习（ICL）（Brown et al., 2020）已成为指导LLMs执行复杂任务的新范式。在 &lt;span style=&quot;background-color: #2ea8e580&quot;&gt;ICL 中，任务描述和演示示例以自然语言表示以形成上下文，并且以上下文为条件的 LM 预测根据预定义规则转换为答案&lt;/span&gt;（Brown 等人，2020）。通过这种方式，大型 LM 无需对参数进行任何修改即可适应各种下游任务，使其自然适合大型 LM 上的知识编辑。首先，它通过避免修改参数来减少计算开销，并消除参数更新带来的副作用的风险。最重要的是，&lt;span style=&quot;background-color: #2ea8e580&quot;&gt;ICL 为人类提供了一种可解释的方式来校准 LM 行为&lt;/span&gt;。尽管有这些优点，ICL 是否适用于知识编辑仍不清楚。

 在本文中，我们研究了 ICL 为LLMs进行知识编辑的潜力。我们专注于两个目标：（1）确保泛化，以便大型语言模型可以泛化到多个文本表面以获取更新的知识；（2）通过对目标知识事实进行准确修改，同时保留其他不相关事实，确保特异性。为了同时实现这些目标，我们设计了演示格式和组织策略，以构建合适的上下文学习演示，以指导LLMs的知识编辑。我们定义了三种类型的演示格式化模板，包括&lt;span style=&quot;background-color: #ff666680&quot;&gt;（i）复制，旨在将新事实注入语言模型； (ii) 更新，提高注入知识事实的泛化能力； (iii) 保留，指导语言模型保留不相关的知识事实。此外，为了充分利用 ICL 进行知识编辑的潜力，我们从训练语料库中检索相关知识事实作为演示输入。&lt;/span&gt; GPT-J（6B）知识编辑基准的实验结果表明，所提出的上下文学习知识编辑（IKE）在强基线下实现了整体可比的知识编辑性能。例如，IKE 的编辑成功率绝对优于 MEND（Mitchell 等人，2021）10％，并且在特异性方面比 ROME 获得了 30 分的增益（Meng 等人，2022a）。由于没有参数修改，IKE适用于OPT-175B等LLM，并表现出更好的记忆能力，即编辑后，近50%的知识事实保留了较高的概率。进一步的分析表明，&lt;span style=&quot;background-color: #ff666680&quot;&gt;演示选择和保留演示有助于特异性，而更新演示则提高泛化能力&lt;/span&gt;。最后，我们讨论了IKE在实际场景中应用时可能遇到的潜在挑战，并提供了相应的讨论。总的来说，这项研究的贡献有四个方面：
</code></pre><ul>
<li>据我们所知，这项工作代表了对 ICL 编辑 LM 知识潜力的首次系统探索。</li>
<li>我们对ICL 策略进行全面的实证研究，并分析这些策略如何影响最终性能。</li>
<li>通过设计适当的演示格式和组织策略，IKE 可以以更少的计算开销和副作用实现相当的成功率。</li>
<li>我们研究将IKE 应用到现实场景的可行性并讨论潜在的挑战。</li>
</ul>
<h2 id="2-Related-Work"><a href="#2-Related-Work" class="headerlink" title="2 Related Work"></a>2 Related Work</h2><p><strong>知识编辑方法 </strong>最近关于知识编辑的研究大多是基于炒作网络或基于归因的。基于炒作网络的方法训练超网络以获得某些编辑的梯度变化。例如，曹等人。 （2021b）使用超网络来预测测试时的参数变化，这会改变事实，同时保留不相关的事实。 MEND（Mitchell 等人，2022a）学会了将原始微调梯度转换为梯度的低秩分解。米切尔等人。 （2022b）使用编辑记忆检索器和反事实模型来生成，而不更新基本模型的参数。基于归因的方法定位神经网络中某些知识的神经元激活，仅更新相关参数。戴等人。 （2022）使用基于梯度的归因评估了不同神经元对特定知识的贡献，并通过用缩放的嵌入向量替换多层感知器（MLP）权重矩阵中的列来更新或删除事实。孟等人。 (2022a)定位了表达事实知识的单层，并通过在MLP模块中编写新的键值对来编辑这些事实知识。</p>
<p><strong>知识编辑基准</strong> 一些知识编辑基准通常用于评估编辑方法的有效性和特异性。对于 BERT 风格的模型，通常采用事实检查数据集 FEVER (Thorne et al., 2018) 和问答数据集 zsRE (Levy et al., 2017)。在 FEVER 中，每个 x 是一个声明，每个 y 表示相应声明的有效性。在 zsRE 中，每个 x 都是关于事实的问题，每个 y 都是答案，而 xloc 询问与 x 无关的事实。对于 GPT 风格的模型，Mitchell 等人。 (2022a) 引入了维基文本编辑数据集，该数据集要求模型完成带有编辑延续的段落，同时每个标记的分布与不相关的段落 xloc 应保持不变。在我们的实验中，我们使用了一个更具挑战性的 QA 数据集，称为 COUNTERFACT（Meng 等人，2022a）。在 COUNTERFACT 中，问题 x 的编辑答案 y 有时可能与现实世界反事实，并且不相关的超出范围的样本 xloc 比 zsRE 中的困难得多，这使得模型更难预测所需的答案。此外，预先训练的LLMs很难捕获这些所需的事实，从而避免了LLMs在编辑之前了解这些知识的影响。</p>
<p><strong>情境学习</strong> 情境学习 (ICL) 是一种免训练范例，可从输入情境中串联的演示中学习。给定相关示例和查询，模型通过类比学习来做出预测（Brown 等人，2020；Liu 等人，2022）。现有的知识编辑方法需要重新计算梯度或者以廉价的方式计算并执行这样的知识编辑。斯等人。 （2022）首次探讨了情境学习是否可以更新LLMs的知识，并表明结合各种演示可以提高知识编辑的成功率。然而，他们只关注GPT-3，而没有深入探索知识编辑的潜在能力和副作用。</p>
<h3 id="3-Task-Formulation"><a href="#3-Task-Formulation" class="headerlink" title="3 Task Formulation"></a>3 Task Formulation</h3><p>知识编辑的目标是通过最大化概率 PM(y*|x*) 来将新事实 (x*, y*) 注入到 LMM 中。 x*是探究M中事实知识的提示（例如，美国总统是），y*将是编辑目标乔·拜登。知识编辑还需要概括性和特异性：</p>
<ul>
<li><strong>泛化</strong>：对于编辑中的提示x的范围 Dx*（即与新事实相关的提示），x ∈ Dx* 的预测也应该更新为 y*。例如，预测问题：谁是美国总统？答：将更新为乔·拜登。</li>
<li><strong>特异性</strong>：对于提示x 超出编辑范围，x / ε Dx*，x 的预测应该是它原来的预测yo。例如，俄罗斯总统的预测应该保留。</li>
</ul>
<h2 id="4-Method-IKE"><a href="#4-Method-IKE" class="headerlink" title="4 Method: IKE"></a>4 Method: IKE</h2><h3 id="4-1-In-Context-Learning"><a href="#4-1-In-Context-Learning" class="headerlink" title="4.1 In-Context Learning"></a>4.1 In-Context Learning</h3><p>情境学习（ICL）是由 Brown 等人提出的。 （2020）用于小样本学习。对于大型语言模型 M，ICL 的目标是根据 k 个演示 C = {(x1, y1),… 来预测输入 x 的 ˆ y ∈ Y，而无需进行任何参数更新。 。 。 ，（xk，yk）}。语言模型 M 预测给定 x 的 y ∈ Y 的概率：PM(y | x, C)。更具体地说，ICL 使用模板 T 将输入和标签转换为自然语言文本。以情感分析为例，输入 xi 和标签 yi 的上下文演示将转换为句子：xi。情感：yi，那么语言模型 M 将在给定 T (x1, y1), 的情况下预测 y ∈ Y。 。 。 ，T（xk，yk），T（x，）。</p>
<h3 id="4-2-In-Context-Knowledge-Editing"><a href="#4-2-In-Context-Knowledge-Editing" class="headerlink" title="4.2 In-Context Knowledge Editing"></a>4.2 In-Context Knowledge Editing</h3><p>当我们将目标事实 f = (x*, y*) 注入 LM 时，我们将构造 k 个演示 C = {c1,…。 。 。 ，ck}。知识编辑的目标是当提示x在目标提示x*的编辑范围内时最大化P(y*|x,f,C)，并且最小化P(y*|x,f,C)之间的距离。 | x, f, C) 和 P (y | x) 当 x / ∈ Dx* （特异性目标）时。 LM 应确定探测提示 x 是否在 x* 的编辑范围内，即 Dx*。为了通过 ICL 实现这些目标，适当的演示输入至关重要。我们进一步将以f为目标的知识编辑演示构建分解为两个子问题：</p>
<p>（i）如何设计每个演示的格式； (ii) 如何选择上下文演示并对其进行排名（Dong 等人，2023）。</p>
<h4 id="4-2-1-Demonstration-Formating"><a href="#4-2-1-Demonstration-Formating" class="headerlink" title="4.2.1 Demonstration Formating"></a>4.2.1 Demonstration Formating</h4><p>每个演示 ci 都包含一个新事实 fi = (xi*, y* i )、一个探测提示 xi 及其预测 yi。上下文演示应该教会 LM 复制、更新和保留针对不同提示的预测：</p>
<ul>
<li><strong>复制</strong>：要将新事实注入 LM，第一步是教他们将目标提示的预测复制到新事实中。在复制演示中，xi = xi* 且 yi = y* i。</li>
<li><strong>更新</strong>：知识编辑不仅仅是教语言模型重复新事实。为了知识编辑的泛化，编辑范围内提示的预测也应该更新。在更新演示中，xi ∈ Dx* i 且 yi = y* i。</li>
<li><strong>保留</strong>：出于知识编辑的特殊性，语言模型应在超出范围的提示中保留其原始预测。在保留演示中，xi / ∈ Dx* i 和 yi 应该是它的原始答案 yo i。 IKE 的模板 T 将 f 、 x 和 y 转换为自然语言：T (f, x, y) = New Fact: f 。提示：xy。详细信息列于§A。</li>
</ul>
<h4 id="4-2-2-Demonstration-Organization"><a href="#4-2-2-Demonstration-Organization" class="headerlink" title="4.2.2 Demonstration Organization"></a>4.2.2 Demonstration Organization</h4><p>当我们在 LM 中编辑知识事实 f 时，我们构建 k 个演示 C = {c1,… 。 。 , ck} 来自训练语料库。哪些演示适合上下文编辑？我们关注刘等人。 （2022）使用无监督检索器来选择 k 个最近邻居。更具体地说，我们使用预训练的句子编码器 E 对新事实 f 的提示 x* 及其原始答案 yo 和目标预测 y* 进行编码。这</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="../imgs/$%7Bfiilename%7D/ZLL8JITP.png" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;ZLL8JITP&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FLB4642KE%22%2C%22annotationKey%22%3A%228PRW9YFQ%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%224%22%2C%22position%22%3A%7B%22pageIndex%22%3A3%2C%22rects%22%3A%5B%5B302.885%2C681.505%2C530.769%2C775.544%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F8YZC667S%22%5D%2C%22locator%22%3A%224%22%7D%7D&quot; width=&quot;380&quot; height=&quot;157&quot; src=&quot;attachments/ZLL8JITP.png&quot; ztype=&quot;zimage&quot;&gt;"></p>
<p>训练语料库中的记录将以相同的方式进行编码，并根据余弦相似度检索 k-NN 事实。上下文演示的排名还取决于余弦相似度：cos(c0, f ) &lt; cos(c1, f ) &lt; 。 。 。 &lt; cos(ck, f )，其中 c1, . 。 。 , ck 从左到右放置在上下文中。</p>
<h3 id="4-3-Discussion-Gradient-based-methods-and-gradient-free-methods"><a href="#4-3-Discussion-Gradient-based-methods-and-gradient-free-methods" class="headerlink" title="4.3 Discussion:Gradient-based methods and gradient-free methods"></a>4.3 Discussion:Gradient-based methods and gradient-free methods</h3><p>之前的参数更新方法会调整LM M的参数θ。它们根据梯度∇θ − log PM(y*|x*)计算Δθ，将基础模型Mθ更新为编辑后的M′θ+Δθ。然后将通过 PM′(y | x) 评估编辑方法。相反，上下文学习通过为新事实 f = (x*, y*) 构建演示 C 来修改 M 中的知识事实，然后通过 PM(y | x, f, C) 来评估编辑方法。将 PM(y | x, f, C) 与 PM′(y | x) 进行比较，可以发现： (i) ICL 不需要对目标事实进行梯度估计，并且在知识编辑后保持原始 LM M 不变。这大大减少了计算开销，从而使编辑适用于具有万亿级参数的LM，并消除了修改参数的副作用。 (ii) 演示 C 以自然文本表示，比显着参数更新 Δθ 更容易解释。它提供了一个人类可理解的界面来校准模型行为。我们在表 1 中重点介绍了这两种方法的特点。</p>
<h2 id="5-Experiment"><a href="#5-Experiment" class="headerlink" title="5 Experiment"></a>5 Experiment</h2><p>在本节中，我们通过实验来回答以下研究问题：</p>
<ul>
<li>与基于梯度的方法相比，IKE 的性能如何？</li>
<li>演示设计策略如何影响IKE 的性能</li>
<li>LM 的规模如何影响IKE 的性能，IKE 能否扩展到具有数百或数千亿参数的大型语言模型？</li>
<li><p>知识编辑有哪些副作用？与其他参数更新方法相比，IKE 产生的副作用是多还是少？</p>
<p> 我们首先介绍实验设置，包括比较基线方法、评估基准和不同尺度的语言模型，用于知识编辑（第 5.1 节）。然后我们分析了§5.2中的主要知识编辑结果以及情境学习知识编辑的影响因素（§5.3）。</p>
</li>
</ul>
<h3 id="5-1-Experimental-Setting"><a href="#5-1-Experimental-Setting" class="headerlink" title="5.1 Experimental Setting"></a>5.1 Experimental Setting</h3><p>我们的目标是评估上下文知识编辑与参数更新方法相比的性能。我们还对不同大小的语言模型进行了实验，以探索上下文知识编辑的扩展能力。</p>
<h4 id="5-1-1-基线"><a href="#5-1-1-基线" class="headerlink" title="5.1.1 基线"></a>5.1.1 基线</h4><p>遵循之前的知识编辑方法，我们还选择 GPT-J (6B) 作为我们的主要评估骨干。比较的基线包括：</p>
<p><strong>FT</strong> 在描述编辑事实的文本上微调基本模型，而无需通过应用 Adam 提前停止来训练新的模型编辑器。</p>
<p><strong>MEND</strong> MEND（Mitchell 等人，2022a）通过使用预训练的超网络将权重矩阵分解为rank-1 形式来转换更新事实的微调梯度。</p>
<p><strong>ROME</strong> ROME（Meng et al., 2022a）学习定位一组特定 MLP 模块的事实检索，并通过直接在 MLP 模块中写入新的键值对来更新知识。</p>
<p><strong>PROMPT</strong> 探索上下文演示如何影响 IKE 的性能。我们直接使用新事实作为上下文，通过 P(y|x, f ) 来探测 LM，其中 f = (x*, y*)。实施细节见§A</p>
<h4 id="5-1-2-Evaluation-Setup"><a href="#5-1-2-Evaluation-Setup" class="headerlink" title="5.1.2 Evaluation Setup"></a>5.1.2 Evaluation Setup</h4><p><strong>模型</strong> 为了探索 LM 的规模将如何影响上下文知识编辑的有效性，我们在五个类似 GPT 的自回归转换器语言模型上评估了上下文知识编辑，其规模范围从 1.5B 到 175B 参数：</p>
<ul>
<li>GPT- 2 XL (1.5B)（Radford 等人，2019），GPT-2 的 15 亿参数版本。</li>
<li>GPT-NEO (2.7B)（Gao 等人，2021），EleutherAI 发布的类 GPT-2 因果语言模型的 27 亿参数版本。它是在专门为 LLM 训练设计的 Pile 数据集上进行训练的。</li>
<li>GPT-J (6B)（Wang 和 Komatsuzaki，2021），一种在具有 60 亿个参数的 Pile 上训练的自回归文本生成模型。</li>
<li>GPT-NEOX (20B)（Black 等人，2022），一个在 Pile 上训练的 200 亿参数自回归语言模型。</li>
<li>OPT (175B)（Zhang 等人，2022），开放式预训练 Transformer，由 MetaAI 创建，具有 1750 亿个参数。</li>
</ul>
<p><strong>基准</strong> 我们主要评估 COUNTERFACT 的基线（Meng et al., 2022a），这是一个具有挑战性的基准，适用于具有困难编辑目标和难以区分编辑范围的类 GPT 因果语言模型。它包含 21, 919 条不同关系和实体的记录。每条记录的目标是将知识三元组（s*，r*，oc）更改为（s*，r*，o*），其中s*和r*由目标提示x*描述。该记录还包含释义提示 P P 作为范围内提示和邻域提示 P N ，即与目标三元组共享同一对象的知识三元组（s′，r*，oc）作为范围外提示。我们关注孟等人。 (2022a) 使用前 2000 条记录作为测试集，其余记录分为训练集。 COUNTERFACT 的详细信息在 §B 中列出。</p>
<p><strong>指标</strong> 知识编辑的性能从三个方面来衡量（有效性、泛化性和特异性）。</p>
<ul>
<li><strong>功效 </strong>通过功效得分 (ES, E[I[P(o*) &gt; P(oc)]]) 和功效幅度 (EM, E[P(o*) − P( oc）]）。</li>
<li><strong>泛化 </strong>通过释义衡量释义提示的译后编辑准确性分数 (PS) 和释义幅度 (PM)。 PS和PM的定义与ES和EM类似。</li>
<li><strong>特异性 </strong>通过邻域得分 (NS, E[I[P(oc) &gt; P(o*)]]) 和邻域量级 (NM, E[P(oc) − P(o*)]) 来衡量邻域提示的准确性，因为邻域提示 (s′, r*, oc) 与目标提示共享相同的原始对象，并且这些事实不应被编辑。</li>
</ul>
<p>我们也关注孟等人。 (2022a) 将 ES、PS、NS 的调和平均值报告为分数 (S)</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="../imgs/$%7Bfiilename%7D/QTYQT47T.png" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;QTYQT47T&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FLB4642KE%22%2C%22annotationKey%22%3A%22JKFNHCLD%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%226%22%2C%22position%22%3A%7B%22pageIndex%22%3A5%2C%22rects%22%3A%5B%5B64%2C569.39%2C535%2C784.89%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F8YZC667S%22%5D%2C%22locator%22%3A%226%22%7D%7D&quot; width=&quot;785&quot; height=&quot;359&quot; src=&quot;attachments/QTYQT47T.png&quot; ztype=&quot;zimage&quot;&gt;"></p>
<h3 id="5-2-Main-Results"><a href="#5-2-Main-Results" class="headerlink" title="5.2 Main Results"></a>5.2 Main Results</h3><p>表2的顶行显示了不同方法的知识编辑结果。我们的研究结果是：（i）所有方法在功效方面都表现良好，正如它们接近的 ES 分数所示。然而，在普遍性和特殊性方面存在显着差异。例如，FT 获得了较高的 ES (99.9) 和 PS (96.4) 分数，但在特异性方面表现不佳。这凸显了知识编辑中平衡泛化和特殊性的挑战。 (ii) 在基线方法中，ROME 在所有三个指标方面总体表现最好，但计算开销较高。由于这一限制，它不适用于诸如 OPT175B 等更迫切需要知识编辑的大型 LM。 (iii) 所提出的方法 IKE 在特异性方面表现出色，但在有效性和泛化方面也表现良好。例如，IKE 在 GPTJ 上获得了与 ROME 相当的总分（89.6 比 91.5），同时不需要任何参数对 LM 的修改。这种计算优势使得在 OPT-175B 等大型 LM 上执行知识编辑成为可能，其中 IKE 比 PROMPT 明显提高了 36.0 个点。这些结果证明了 IKE 在知识编辑方面的有效性、效率和可扩展性。</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="../imgs/$%7Bfiilename%7D/P6MNIS5S.png" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;P6MNIS5S&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FLB4642KE%22%2C%22annotationKey%22%3A%22GWHX8CHK%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%226%22%2C%22position%22%3A%7B%22pageIndex%22%3A5%2C%22rects%22%3A%5B%5B303.158%2C339.39%2C531.316%2C561.232%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F8YZC667S%22%5D%2C%22locator%22%3A%226%22%7D%7D&quot; width=&quot;380&quot; height=&quot;369&quot; src=&quot;attachments/P6MNIS5S.png&quot; ztype=&quot;zimage&quot;&gt;"></p>
<h3 id="5-3-Analysis"><a href="#5-3-Analysis" class="headerlink" title="5.3 Analysis"></a>5.3 Analysis</h3><p>在这一部分中，我们讨论不同演示策略的效果、跨尺度模型的 IKE 可扩展性以及知识编辑引入的副作用。</p>
<h4 id="5-3-1Ablation-on-Demonstration"><a href="#5-3-1Ablation-on-Demonstration" class="headerlink" title="5.3.1Ablation on Demonstration"></a>5.3.1Ablation on Demonstration</h4><p><strong>演示次数</strong> 演示次数是 ICL 性能的影响因素之一 (Brown et al., 2020)。我们研究了演示数量如何影响第二阶段的 IKE 性能</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="../imgs/$%7Bfiilename%7D/HKQ4CHLZ.png" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;HKQ4CHLZ&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FLB4642KE%22%2C%22annotationKey%22%3A%22MUQZEW2N%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%227%22%2C%22position%22%3A%7B%22pageIndex%22%3A6%2C%22rects%22%3A%5B%5B63.947%2C615.706%2C292.895%2C778.732%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F8YZC667S%22%5D%2C%22locator%22%3A%227%22%7D%7D&quot; width=&quot;382&quot; height=&quot;272&quot; src=&quot;attachments/HKQ4CHLZ.png&quot; ztype=&quot;zimage&quot;&gt;"></p>
<p>表 3 中的块。在没有任何演示的情况下，PROMPT 因其低 NS（37.9）而表现出过度泛化，表明它只是学习复制预测。给定一些演示（4 或 8)，IKE 在有效性和泛化性方面比 PROMPT 表现更差，因为它开始区分提示是否在编辑范围内。随着演示次数的增加，IKE逐渐学会平衡通用性和特殊性，实现更好的权衡。</p>
<p><strong>演示组织 </strong>先前的研究（Liu et al., 2022; Rubin et al., 2022; Lu et al., 2022）表明，包括演示选择和演示排序（Dong et al., 2023）在内的演示组织对于 ICL 也至关重要。我们的建议遵循刘等人的简单无监督方法。 （2022），根据输入提示和演示之间的余弦相似度从训练语料库中检索和排序演示。在表 3 第三块中的两项消融研究中，我们发现删除选择程序（即随机选择）会导致 NS 分数从 77.0 明显下降到 45.0，这表明正确提示选择的重要性。然而，随机排序带来的性能差异可以忽略不计。我们推测这是因为所选的提示与目标事实高度相关，并且基于 Transformer 的 LM 中的注意力机制可以很好地处理长程依赖性。我们将进一步的改进作为未来的工作。</p>
<p><strong>演示格式 </strong>我们进一步检查演示类型的影响，包括复制、更新和保留。如表 3 中的第四个块所示，删除复制演示会导致性能轻微下降，因为即使没有复制演示，LM 也可以轻松复制演示中的内容。相反，更新演示在教导 LM 修改其知识方面发挥着重要作用，删除更新演示后泛化得分要差得多。此外，删除保留演示会导致特异性急剧下降（通过 NM 分数衡量），从 35.2 降至 -47.6。这表明保留演示对于帮助 LM 识别超出范围的事实并维持对这些提示的原始预测至关重要。</p>
<h4 id="5-3-2IKE-Benefits-from-Model-Scaling"><a href="#5-3-2IKE-Benefits-from-Model-Scaling" class="headerlink" title="5.3.2IKE Benefits from Model Scaling"></a>5.3.2IKE Benefits from Model Scaling</h4><p>我们进一步评估了 COUNTERFACT 上的 IKE，针对不同尺度的五种类似 GPT 的因果语言模型。正如之前的实验表明，所有方法都表现出很高的知识编辑功效，因此我们重点关注大型语言模型的泛化性和特异性，因为这些指标的定义是为了衡量可能对最终用户造成巨大影响的副作用。如表 4 所示，我们发现 IKE 的性能与 LM 的规模正相关，并且最大的 OPT-175B 实现了最强的泛化和特异性结果。这是令人鼓舞的，因为 IKE 的性能可以随着 LM 规模的增加而增强，使其可插入未来更强大的 LM 主干。</p>
<h4 id="5-3-3Resilience-to-Over-Editing"><a href="#5-3-3Resilience-to-Over-Editing" class="headerlink" title="5.3.3Resilience to Over-Editing"></a>5.3.3Resilience to Over-Editing</h4><p>过度编辑是知识编辑的常见副作用，指在编辑目标事实时对超出范围的事实产生影响。尽管 COUNTERFACT 已经包含由 (s′, r*, oc) 组成的范围外提示，它们与编辑目标共享相同的关系 r 和原始对象 oc： (s*, r*, oc) → (s*, r*, o*），我们采用Dong等人提出的对比知识评估（CKA）对过度编辑进行更全面的评估。 （2022）。具体来说，对于一个三元组（s，r，o），CKA将r替换为其他相似但不相关的关系r′，并比较PM（o | s，r）和PM（o | s，r′）来评估M是否知道事实（s，r，o）。受此启发，我们将(s*,r’,o*)视为相似但不相关的提示，并考虑P(o*|s*,r’)的变化，发现P(o*|s*,r’ ）在注入（s*，r*，o*）后也会增加。为了进一步探索不同方法中的过度编辑，我们考虑 CKA 分数 P(o*|s*, r*)/Er′∈RP(o*|s*, r′)。</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="../imgs/$%7Bfiilename%7D/A9BSU2NB.png" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;A9BSU2NB&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FLB4642KE%22%2C%22annotationKey%22%3A%22W3GR7IZZ%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%228%22%2C%22position%22%3A%7B%22pageIndex%22%3A7%2C%22rects%22%3A%5B%5B61.731%2C622.082%2C298.269%2C782.467%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F8YZC667S%22%5D%2C%22locator%22%3A%228%22%7D%7D&quot; width=&quot;394&quot; height=&quot;267&quot; src=&quot;attachments/A9BSU2NB.png&quot; ztype=&quot;zimage&quot;&gt;"></p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="../imgs/$%7Bfiilename%7D/JRUG4L94.png" alt="\&lt;img alt=&quot;&quot; data-attachment-key=&quot;JRUG4L94&quot; data-annotation=&quot;%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2FLB4642KE%22%2C%22annotationKey%22%3A%22V8EL5CWL%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%228%22%2C%22position%22%3A%7B%22pageIndex%22%3A7%2C%22rects%22%3A%5B%5B304.038%2C646.313%2C529.038%2C781.89%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2FiUeV0SQs%2Fitems%2F8YZC667S%22%5D%2C%22locator%22%3A%228%22%7D%7D&quot; width=&quot;375&quot; height=&quot;226&quot; src=&quot;attachments/JRUG4L94.png&quot; ztype=&quot;zimage&quot;&gt;"></p>
<p>CKA评估结果如表5所示。如果CKA得分小于预定义阈值α，则正确事实的困惑度为输给了对比虚假事实的困惑，结果证明这是一次编辑失败。尽管所有基线在编辑功效方面都表现良好，但在更严格的对比评估下它们往往过于概括。 ROME 的平均 CKA 得分最低，错误率最高，这表明它识别与目标提示共享同一主题的范围外提示的能力较差。 IKE 对过度编辑的影响较小。</p>
<h4 id="5-3-4Maintenance-for-Original-Knowledge"><a href="#5-3-4Maintenance-for-Original-Knowledge" class="headerlink" title="5.3.4Maintenance for Original Knowledge"></a>5.3.4Maintenance for Original Knowledge</h4><p>我们得出的结论是，先前存储在语言模型中的事实知识将在知识编辑过程中被删除或遗忘。我们在表6中考虑编辑前后P(oc|s*, r)的变化。结果表明，所有编辑方法都会导致P(oc|s*, r*)的下降。罗马几乎忘记了所有最初的事实。如果我们想要纠正 LM 的预测，就必须擦除原来的事实知识。然而，如果我们想更新语言模型的预测，例如更新美国总统是从唐纳德·特朗普到乔·拜登的预测（时间感知关系），那么旧知识 2017 年，美国总统是唐纳德·特朗普不应该被忘记。</p>
<pre><code>为了评估编辑中这种时间感知知识的遗忘，我们基于 TEMPLAMA (Dhingra et al., 2022) 构建了一个小型基准，以进一步表明 IKE 比 §C 中的其他基准可以导致更少的知识遗忘。
</code></pre><h2 id="6-Discussions"><a href="#6-Discussions" class="headerlink" title="6 Discussions"></a>6 Discussions</h2><p>在之前的实验中，我们遵循孟等人之前研究的设置。 （2022a）并主要评估编辑单个事实以进行公平比较的方法。我们的结果表明 IKE 可以获得更好的泛化性和特异性，副作用更少，并且不需要修改参数。尽管如此，为了探讨可行性在将 IKE 应用到现实场景中时，有几个重要问题尚未得到充分探索：(1) IKE 能否扩展以容纳更多的编辑事实？考虑到语言模型的输入长度有限，在上下文中包含大量的编辑事实可能是不可行的。 (2) IKE 能否适应处理不同格式和域的事实和提示？在IKE中，事实和提示的域和格式保持一致。然而，在现实世界中，事实和提示有多种形式。米切尔等人。 (2022b)提出了一种基于检索的方法来编辑多个知识事实。类似地，具有外部存储器来存储事实编辑的 IKE 可以检索正确的事实编辑来构建给定提示的上下文，从而避免永远在上下文中预先添加所有事实编辑。为了验证 IKE 对不同形式的事实或提示的泛化，我们用维基百科中的中性数据替换了事实，或者用生成提示替换了提示，提示 LM 生成与新对象相关的文本。详细讨论可以在§D 中找到。</p>
<h2 id="7-Conclusion"><a href="#7-Conclusion" class="headerlink" title="7 Conclusion"></a>7 Conclusion</h2><p>在这项工作中，我们研究了上下文学习在大规模语言模型上进行知识编辑的潜力。具体来说，我们设计了提示LM的演示策略，包括三种类型的演示格式和基于检索的演示组织。我们表明，所提出的方法 IKE 在不需要任何参数修改的情况下实现了竞争性知识编辑功效，并保持了良好的泛化和特异性性能。进一步的分析证明了它对于大型 LM 的可扩展性、对过度编辑问题的弹性以及通过多轮编辑维护时间感知知识事实的能力。我们的结果证明 ICL 在 LM 知识编辑方面具有巨大潜力。</p>

<div class="article-footer fs14">
    <section id="license">
      <div class="header"><span>许可协议</span></div>
      <div class="body"><p>本文采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">署名-非商业性使用-相同方式共享 4.0 国际</a> 许可协议，转载请注明出处。</p>
</div>
    </section>
    
    <section id="share">
      <div class="header"><span>分享文章</span></div>
      <div class="body">
        <div class="link"><input class="copy-area" readonly="true" id="copy-link" value="http://humble2967738843.github.io/2023/11/02/wo-men-ke-yi-tong-guo-qing-jing-xue-xi-lai-bian-ji-shi-shi-zhi-shi-ma/" /></div>
        <div class="social-wrap dis-select"><a class="social share-item wechat" onclick="util.toggle(&quot;qrcode-wechat&quot)"><img class="lazy"  src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/social/b32ef3da1162a.svg" /></a><a class="social share-item weibo" target="_blank" rel="external nofollow noopener noreferrer" href="https://service.weibo.com/share/share.php?url=http://humble2967738843.github.io/2023/11/02/wo-men-ke-yi-tong-guo-qing-jing-xue-xi-lai-bian-ji-shi-shi-zhi-shi-ma/&title=我们可以通过情景学习来编辑事实知识吗？ - humbleyl&summary=我们可以通过情景学习来编辑事实知识吗？Abstract之前的研究表明，像 GPT 这样的大型语言模型 (LLM) 在其参数中存储了大量事实知识。然而，存储的知识可能是错误的或过时的。传统的知识编辑方法通过对包含特定知识的文本进行微调来..."><img class="lazy"  src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/social/80c07e4dbb303.svg" /></a><a class="social share-item email" href="mailto:?subject=我们可以通过情景学习来编辑事实知识吗？ - humbleyl&amp;body=http://humble2967738843.github.io/2023/11/02/wo-men-ke-yi-tong-guo-qing-jing-xue-xi-lai-bian-ji-shi-shi-zhi-shi-ma/"><img class="lazy"  src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/social/a1b00e20f425d.svg" /></a><a class="social share-item link" onclick="util.copy(&quot;copy-link&quot;, &quot;复制成功&quot;)"><img class="lazy"  src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/social/8411ed322ced6.svg" /></a></div>
        
        <div class="qrcode" id="qrcode-wechat" style="opacity:0;height:0">
          <img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://api.qrserver.com/v1/create-qr-code/?size=256x256&data=http://humble2967738843.github.io/2023/11/02/wo-men-ke-yi-tong-guo-qing-jing-xue-xi-lai-bian-ji-shi-shi-zhi-shi-ma/"/>
        </div>
        
      </div>
    </section>
    </div>
</article>
<div class="related-wrap" id="read-next"><section class="body"><div class="item" id="prev"><div class="note">较新文章</div><a href="/2023/11/02/wo-men-ke-yi-bian-ji-duo-mo-tai-da-xing-yu-yan-mo-xing-ma/">我们可以编辑多模态大型语言模型吗？</a></div><div class="item" id="next"><div class="note">较早文章</div><a href="/2023/11/02/zhi-shi-shen-jing-yuan-zhong-xin-zhi-lu-yu-yan-wu-guan-zhi-shi-shen-jing-yuan-he-jian-bing-zhi-shi-shen-jing-yuan-de-fa-xian/">知识神经元中心之旅：语言无关知识神经元和简并知识神经元的发现</a></div></section></div>

<div class="related-wrap" id="related-posts">
    <section class='header'>
      <div class='title cap theme'>您可能感兴趣的文章</div>
    </section>
    <section class='body'>
    <div class="related-posts"><a class="item" href="\2023\11\02\duo-yu-yan-mo-xing-zhong-shi-shi-zhi-shi-de-kua-yu-yan-yi-zhi-xing\" title="多语言模型中事实知识的跨语言一致性"><span class="title">多语言模型中事实知识的跨语言一致性</span></a><a class="item" href="\2023\11\06\wang-diao-ni-xiang-wang-diao-de-dong-xi-llms-de-gao-xiao-wang-que\" title="忘掉你想忘掉的东西：LLMs的高效忘却"><span class="title">忘掉你想忘掉的东西：LLMs的高效忘却</span></a><a class="item" href="\2023\11\02\qing-jing-xue-xi-chuang-jian-ren-wu-xiang-liang\" title="情境学习创建任务向量"><span class="title">情境学习创建任务向量</span></a><a class="item" href="\2023\11\02\wo-men-ke-yi-bian-ji-duo-mo-tai-da-xing-yu-yan-mo-xing-ma\" title="我们可以编辑多模态大型语言模型吗？"><span class="title">我们可以编辑多模态大型语言模型吗？</span></a><a class="item" href="\2023\11\02\zhi-shi-shen-jing-yuan-zhong-xin-zhi-lu-yu-yan-wu-guan-zhi-shi-shen-jing-yuan-he-jian-bing-zhi-shi-shen-jing-yuan-de-fa-xian\" title="知识神经元中心之旅：语言无关知识神经元和简并知识神经元的发现"><span class="title">知识神经元中心之旅：语言无关知识神经元和简并知识神经元的发现</span></a></div></section></div>


  <div class="related-wrap md-text" id="comments">
    <section class='header cmt-title cap theme'>
      <p>快来参与讨论吧~</p>

    </section>
    <section class='body cmt-body giscus'>
      

<svg class="loading" style="vertical-align:middle;fill:currentColor;overflow:hidden;" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2709"><path d="M832 512c0-176-144-320-320-320V128c211.2 0 384 172.8 384 384h-64zM192 512c0 176 144 320 320 320v64C300.8 896 128 723.2 128 512h64z" p-id="2710"></path></svg>

<div id="giscus" src="https://giscus.app/client.js" data-repo="Humble2967738843/giscus" data-repo-id="R_kgDOLsS5kA" data-category="Announcements" data-category-id="DIC_kwDOLsS5kM4Cel5C" data-mapping="url" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="preferred_color_scheme" data-lang="zh-CN" data-loading="lazy" crossorigin="anonymous"></div>

    </section>
  </div>



<footer class="page-footer footnote"><hr><div class="text"><center>
</br>
</br>
<script type="text/javascript">
function show_runtime() {
    window.setTimeout("show_runtime()", 1000);
    X = new Date("10/20/2023 00:00:00");
    Y = new Date();
    T = (Y.getTime() - X.getTime());
    M = 24 * 60 * 60 * 1000;
    a = T / M;
    A = Math.floor(a);
    b = (a - A) * 24;
    B = Math.floor(b);
    c = (b - B) * 60;
    C = Math.floor((b - B) * 60);
    D = Math.floor((c - C) * 60);
    runtime_span.innerHTML = "⏲️本站已运行 " + A + "天|" + B + "小时|" + C + "分|" + D + "秒⏲️"
}
show_runtime();
</script>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<span id="busuanzi_container_site_pv">🤩本站总访问量<span id="busuanzi_value_site_pv"></span>次</span><br>
<span id="runtime_span"></span>
</center>
</div></footer>
<div class="main-mask" onclick="sidebar.dismiss()"></div></div><aside class="l_right">
<div class="widgets">



<widget class="widget-wrapper toc" id="data-toc" collapse="false"><div class="widget-header dis-select"><span class="name">本文目录</span><a class="cap-action" onclick="sidebar.toggleTOC()" ><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 6h11m-11 6h11m-11 6h11M4 6h1v4m-1 0h2m0 8H4c0-1 2-2 2-3s-1-1.5-2-1"/></svg></a></div><div class="widget-body"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%88%91%E4%BB%AC%E5%8F%AF%E4%BB%A5%E9%80%9A%E8%BF%87%E6%83%85%E6%99%AF%E5%AD%A6%E4%B9%A0%E6%9D%A5%E7%BC%96%E8%BE%91%E4%BA%8B%E5%AE%9E%E7%9F%A5%E8%AF%86%E5%90%97%EF%BC%9F"><span class="toc-text">我们可以通过情景学习来编辑事实知识吗？</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Abstract"><span class="toc-text">Abstract</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Introduction"><span class="toc-text">1 Introduction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Related-Work"><span class="toc-text">2 Related Work</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-Task-Formulation"><span class="toc-text">3 Task Formulation</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-Method-IKE"><span class="toc-text">4 Method: IKE</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-In-Context-Learning"><span class="toc-text">4.1 In-Context Learning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-In-Context-Knowledge-Editing"><span class="toc-text">4.2 In-Context Knowledge Editing</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-1-Demonstration-Formating"><span class="toc-text">4.2.1 Demonstration Formating</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-2-Demonstration-Organization"><span class="toc-text">4.2.2 Demonstration Organization</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-Discussion-Gradient-based-methods-and-gradient-free-methods"><span class="toc-text">4.3 Discussion:Gradient-based methods and gradient-free methods</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-Experiment"><span class="toc-text">5 Experiment</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-Experimental-Setting"><span class="toc-text">5.1 Experimental Setting</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#5-1-1-%E5%9F%BA%E7%BA%BF"><span class="toc-text">5.1.1 基线</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-1-2-Evaluation-Setup"><span class="toc-text">5.1.2 Evaluation Setup</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-Main-Results"><span class="toc-text">5.2 Main Results</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-Analysis"><span class="toc-text">5.3 Analysis</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#5-3-1Ablation-on-Demonstration"><span class="toc-text">5.3.1Ablation on Demonstration</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-3-2IKE-Benefits-from-Model-Scaling"><span class="toc-text">5.3.2IKE Benefits from Model Scaling</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-3-3Resilience-to-Over-Editing"><span class="toc-text">5.3.3Resilience to Over-Editing</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-3-4Maintenance-for-Original-Knowledge"><span class="toc-text">5.3.4Maintenance for Original Knowledge</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-Discussions"><span class="toc-text">6 Discussions</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-Conclusion"><span class="toc-text">7 Conclusion</span></a></li></ol></li></ol></div><div class="widget-footer">

<a class="top" onclick="util.scrollTop()"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-width="1.5"><path d="M2 12c0-4.714 0-7.071 1.464-8.536C4.93 2 7.286 2 12 2c4.714 0 7.071 0 8.535 1.464C22 4.93 22 7.286 22 12c0 4.714 0 7.071-1.465 8.535C19.072 22 16.714 22 12 22s-7.071 0-8.536-1.465C2 19.072 2 16.714 2 12Z"/><path stroke-linecap="round" stroke-linejoin="round" d="m9 15.5l3-3l3 3m-6-4l3-3l3 3"/></g></svg><span>回到顶部</span></a></div></widget>
</div></aside><div class='float-panel blur'>
  <button type='button' style='display:none' class='laptop-only rightbar-toggle mobile' onclick='sidebar.rightbar()'>
    <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 6h11m-11 6h11m-11 6h11M4 6h1v4m-1 0h2m0 8H4c0-1 2-2 2-3s-1-1.5-2-1"/></svg>
  </button>
  <button type='button' style='display:none' class='mobile-only leftbar-toggle mobile' onclick='sidebar.leftbar()'>
    <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-width="1.5"><path d="M2 11c0-3.771 0-5.657 1.172-6.828C4.343 3 6.229 3 10 3h4c3.771 0 5.657 0 6.828 1.172C22 5.343 22 7.229 22 11v2c0 3.771 0 5.657-1.172 6.828C19.657 21 17.771 21 14 21h-4c-3.771 0-5.657 0-6.828-1.172C2 18.657 2 16.771 2 13z"/><path id="sep" stroke-linecap="round" d="M5.5 10h6m-5 4h4m4.5 7V3"/></g></svg>
  </button>
</div>
</div><div class="scripts">
<script type="text/javascript">
  const ctx = {
    date_suffix: {
      just: `刚刚`,
      min: `分钟前`,
      hour: `小时前`,
      day: `天前`,
    },
    root : `/`,
  };

  // required plugins (only load if needs)
  if (`local_search`) {
    ctx.search = {};
    ctx.search.service = `local_search`;
    if (ctx.search.service == 'local_search') {
      let service_obj = Object.assign({}, `{"field":"all","path":"/search.json","content":true,"codeblock":true,"sort":"-date"}`);
      ctx.search[ctx.search.service] = service_obj;
    }
  }
  const def = {
    avatar: `https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/avatar/round/3442075.svg`,
    cover: `https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/cover/76b86c0226ffd.svg`,
  };
  const deps = {
    jquery: `https://cdn.bootcdn.net/ajax/libs/jquery/3.7.1/jquery.min.js`,
    marked: `https://cdn.bootcdn.net/ajax/libs/marked/4.0.18/marked.min.js`
  }
  

</script>

<script type="text/javascript">
  const utils = {
    // 懒加载 css https://github.com/filamentgroup/loadCSS
    css: (href, before, media, attributes) => {
      var doc = window.document;
      var ss = doc.createElement("link");
      var ref;
      if (before) {
        ref = before;
      } else {
        var refs = (doc.body || doc.getElementsByTagName("head")[0]).childNodes;
        ref = refs[refs.length - 1];
      }
      var sheets = doc.styleSheets;
      if (attributes) {
        for (var attributeName in attributes) {
          if (attributes.hasOwnProperty(attributeName)) {
            ss.setAttribute(attributeName, attributes[attributeName]);
          }
        }
      }
      ss.rel = "stylesheet";
      ss.href = href;
      ss.media = "only x";
      function ready(cb) {
        if (doc.body) {
          return cb();
        }
        setTimeout(function () {
          ready(cb);
        });
      }
      ready(function () {
        ref.parentNode.insertBefore(ss, before ? ref : ref.nextSibling);
      });
      var onloadcssdefined = function (cb) {
        var resolvedHref = ss.href;
        var i = sheets.length;
        while (i--) {
          if (sheets[i].href === resolvedHref) {
            return cb();
          }
        }
        setTimeout(function () {
          onloadcssdefined(cb);
        });
      };
      function loadCB() {
        if (ss.addEventListener) {
          ss.removeEventListener("load", loadCB);
        }
        ss.media = media || "all";
      }
      if (ss.addEventListener) {
        ss.addEventListener("load", loadCB);
      }
      ss.onloadcssdefined = onloadcssdefined;
      onloadcssdefined(loadCB);
      return ss;
    },

    js: (src, opt) => new Promise((resolve, reject) => {
      var script = document.createElement('script');
      if (src.startsWith('/')){
        src = ctx.root + src.substring(1);
      }
      script.src = src;
      if (opt) {
        for (let key of Object.keys(opt)) {
          script[key] = opt[key]
        }
      } else {
        // 默认异步，如果需要同步，第二个参数传入 {} 即可
        script.async = true
      }
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    }),

    jq: (fn) => {
      if (typeof jQuery === 'undefined') {
        utils.js(deps.jquery).then(fn)
      } else {
        fn()
      }
    },
    
    onLoading: (el) => {
      if (el) {
        $(el).append('<div class="loading-wrap"><svg xmlns="http://www.w3.org/2000/svg" width="2em" height="2em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-width="2"><path stroke-dasharray="60" stroke-dashoffset="60" stroke-opacity=".3" d="M12 3C16.9706 3 21 7.02944 21 12C21 16.9706 16.9706 21 12 21C7.02944 21 3 16.9706 3 12C3 7.02944 7.02944 3 12 3Z"><animate fill="freeze" attributeName="stroke-dashoffset" dur="1.3s" values="60;0"/></path><path stroke-dasharray="15" stroke-dashoffset="15" d="M12 3C16.9706 3 21 7.02944 21 12"><animate fill="freeze" attributeName="stroke-dashoffset" dur="0.3s" values="15;0"/><animateTransform attributeName="transform" dur="1.5s" repeatCount="indefinite" type="rotate" values="0 12 12;360 12 12"/></path></g></svg></div>');
      }
    },
    onLoadSuccess: (el) => {
      if (el) {
        $(el).find('.loading-wrap').remove();
      }
    },
    onLoadFailure: (el) => {
      if (el) {
        $(el).find('.loading-wrap svg').remove();
        $(el).find('.loading-wrap').append('<svg xmlns="http://www.w3.org/2000/svg" width="2em" height="2em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path stroke-dasharray="60" stroke-dashoffset="60" d="M12 3L21 20H3L12 3Z"><animate fill="freeze" attributeName="stroke-dashoffset" dur="0.5s" values="60;0"/></path><path stroke-dasharray="6" stroke-dashoffset="6" d="M12 10V14"><animate fill="freeze" attributeName="stroke-dashoffset" begin="0.6s" dur="0.2s" values="6;0"/></path></g><circle cx="12" cy="17" r="1" fill="currentColor" fill-opacity="0"><animate fill="freeze" attributeName="fill-opacity" begin="0.8s" dur="0.4s" values="0;1"/></circle></svg>');
        $(el).find('.loading-wrap').addClass('error');
      }
    },
    request: (el, url, callback, onFailure) => {
      let retryTimes = 3;
      utils.onLoading(el);
      function req() {
        return new Promise((resolve, reject) => {
          let status = 0; // 0 等待 1 完成 2 超时
          let timer = setTimeout(() => {
            if (status === 0) {
              status = 2;
              timer = null;
              reject('请求超时');
              if (retryTimes == 0) {
                onFailure();
              }
            }
          }, 5000);
          fetch(url).then(function(response) {
            if (status !== 2) {
              clearTimeout(timer);
              resolve(response);
              timer = null;
              status = 1;
            }
            if (response.ok) {
              return response.json();
            }
            throw new Error('Network response was not ok.');
          }).then(function(data) {
            retryTimes = 0;
            utils.onLoadSuccess(el);
            callback(data);
          }).catch(function(error) {
            if (retryTimes > 0) {
              retryTimes -= 1;
              setTimeout(() => {
                req();
              }, 5000);
            } else {
              utils.onLoadFailure(el);
              onFailure();
            }
          });
        });
      }
      req();
    },
  };
</script>

<script>
  const sidebar = {
    leftbar: () => {
      if (l_body) {
        l_body.toggleAttribute('leftbar');
        l_body.removeAttribute('rightbar');
      }
    },
    rightbar: () => {
      if (l_body) {
        l_body.toggleAttribute('rightbar');
        l_body.removeAttribute('leftbar');
      }
    },
    dismiss: () => {
      if (l_body) {
        l_body.removeAttribute('leftbar');
        l_body.removeAttribute('rightbar');
      }
    },
    toggleTOC: () => {
      document.querySelector('#data-toc').classList.toggle('collapse');
    }
  }
</script>

<!-- required -->
<script src="/js/main.js?v=1.27.0" async></script>

<!-- optional -->

  <script>
  window.addEventListener('DOMContentLoaded', (event) => {
    const els = document.querySelectorAll("#comments #giscus");
    if (els.length === 0) return;
    els.forEach((el, i) => {
      try {
        el.innerHTML = '';
      } catch (error) {
        console.error(error);
      }
      var script = document.createElement('script');
      script.async = true;
      for (let key of Object.keys(el.attributes)) {
        let attr = el.attributes[key];
        if (['class', 'id'].includes(attr.name) === false) {
          script.setAttribute(attr.name, attr.value);
        }
      }
      el.appendChild(script);
    });
  });
</script>




<script defer>
  window.addEventListener('DOMContentLoaded', (event) => {
    ctx.services = Object.assign({}, JSON.parse(`{"mdrender":{"js":"/js/services/mdrender.js"},"siteinfo":{"js":"/js/services/siteinfo.js","api":null},"ghinfo":{"js":"/js/services/ghinfo.js"},"sites":{"js":"/js/services/sites.js"},"friends":{"js":"/js/services/friends.js"},"timeline":{"js":"/js/services/timeline.js"},"fcircle":{"js":"/js/services/fcircle.js"},"weibo":{"js":"/js/services/weibo.js"},"memos":{"js":"/js/services/memos.js"}}`));
    for (let id of Object.keys(ctx.services)) {
      const js = ctx.services[id].js;
      if (id == 'siteinfo') {
        ctx.cardlinks = document.querySelectorAll('a.link-card[cardlink]');
        if (ctx.cardlinks?.length > 0) {
          utils.js(js, { defer: true }).then(function () {
            setCardLink(ctx.cardlinks);
          });
        }
      } else {
        const els = document.getElementsByClassName(`ds-${id}`);
        if (els?.length > 0) {
          utils.jq(() => {
            if (id == 'timeline' || 'memos' || 'marked') {
              utils.js(deps.marked).then(function () {
                utils.js(js, { defer: true });
              });
            } else {
              utils.js(js, { defer: true });
            }
          });
        }
      }
    }
  });
</script>

<script>
  window.addEventListener('DOMContentLoaded', (event) => {
    ctx.search = {
      path: `/search.json`,
    }
    utils.js('/js/search/local-search.js', { defer: true });
  });
</script><script>
  window.FPConfig = {
    delay: 0,
    ignoreKeywords: [],
    maxRPS: 5,
    hoverDelay: 25
  };
</script>
<script defer src="https://cdn.bootcdn.net/ajax/libs/flying-pages/2.1.2/flying-pages.min.js"></script><script defer src="https://cdn.bootcdn.net/ajax/libs/vanilla-lazyload/17.8.4/lazyload.min.js"></script>
<script>
  // https://www.npmjs.com/package/vanilla-lazyload
  // Set the options globally
  // to make LazyLoad self-initialize
  window.lazyLoadOptions = {
    elements_selector: ".lazy",
  };
  // Listen to the initialization event
  // and get the instance of LazyLoad
  window.addEventListener(
    "LazyLoad::Initialized",
    function (event) {
      window.lazyLoadInstance = event.detail.instance;
    },
    false
  );
  document.addEventListener('DOMContentLoaded', function () {
    window.lazyLoadInstance?.update();
  });
</script><script>
  ctx.fancybox = {
    selector: `.timenode p>img`,
    css: `https://cdn.bootcdn.net/ajax/libs/fancyapps-ui/5.0.22/fancybox/fancybox.min.css`,
    js: `https://cdn.bootcdn.net/ajax/libs/fancyapps-ui/5.0.22/fancybox/fancybox.umd.min.js`
  };
  var selector = '[data-fancybox]:not(.error)';
  if (ctx.fancybox.selector) {
    selector += `, ${ctx.fancybox.selector}`
  }
  var needFancybox = document.querySelectorAll(selector).length !== 0;
  if (!needFancybox) {
    const els = document.getElementsByClassName('ds-memos');
    if (els != undefined && els.length > 0) {
      needFancybox = true;
    }
  }
  if (needFancybox) {
    utils.css(ctx.fancybox.css);
    utils.js(ctx.fancybox.js, { defer: true }).then(function () {
      Fancybox.bind(selector, {
        hideScrollbar: false,
        Thumbs: {
          autoStart: false,
        },
        caption: (fancybox, slide) => {
          return slide.triggerEl.alt || null
        }
      });
    })
  }
</script><script>
  window.addEventListener('DOMContentLoaded', (event) => {
    const swiper_api = document.getElementById('swiper-api');
    if (swiper_api != undefined) {
      utils.css(`https://unpkg.com/swiper@10.3.1/swiper-bundle.min.css`);
      utils.js(`https://unpkg.com/swiper@10.3.1/swiper-bundle.min.js`, { defer: true }).then(function () {
        const effect = swiper_api.getAttribute('effect') || '';
        var swiper = new Swiper('.swiper#swiper-api', {
          slidesPerView: 'auto',
          spaceBetween: 8,
          centeredSlides: true,
          effect: effect,
          loop: true,
          pagination: {
            el: '.swiper-pagination',
            clickable: true,
          },
          navigation: {
            nextEl: '.swiper-button-next',
            prevEl: '.swiper-button-prev',
          },
        });
      })
    }
  });
</script><script>
  document.addEventListener('DOMContentLoaded', function () {
    window.codeElements = document.querySelectorAll('.code');
    if (window.codeElements.length > 0) {
      ctx.copycode = {
        default_text: `Copy`,
        success_text: `Copied`,
        toast: `复制成功`,
      };
      utils.js('/js/plugins/copycode.js');
    }
  });
</script>


<!-- inject -->

</div></body></html>
