
<!DOCTYPE html><html lang="zh-CN">

<head>
  <meta charset="utf-8">
  <meta name="hexo-theme" content="https://github.com/xaoxuu/hexo-theme-stellar/tree/1.27.0" theme-name="Stellar" theme-version="1.27.0">
  
  <meta name="generator" content="Hexo 7.0.0">
  <meta http-equiv='x-dns-prefetch-control' content='on' />
  
  <meta name="renderer" content="webkit">
  <meta name="force-rendering" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  <meta name="HandheldFriendly" content="True" >
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="theme-color" content="#f8f8f8">
  
  <title>忘掉你想忘掉的东西：LLMs的高效忘却 - 院龙的博客</title>

  
    <meta name="description" content="忘掉你想忘掉的东西：LLMs的高效忘却Abstract大型语言模型（LLM）在预训练和记忆各种文本数据方面取得了显着进展，然而，这个过程可能会遇到隐私问题和违反数据保护法规的问题。因此，从此类模型中轻松删除与个人用户相关的数据，同时在删除后不降低其预测质量的能力变得越来越重要。为了解决这些问题，在这项工作中，我们提出了一种有效的取消学习框架，通过将选择性师生目标学习的轻量级取消学习层引入到变压器中">
<meta property="og:type" content="article">
<meta property="og:title" content="忘掉你想忘掉的东西：LLMs的高效忘却">
<meta property="og:url" content="http://humble2967738843.github.io/2023/11/06/wang-diao-ni-xiang-wang-diao-de-dong-xi-llms-de-gao-xiao-wang-que/index.html">
<meta property="og:site_name" content="院龙的博客">
<meta property="og:description" content="忘掉你想忘掉的东西：LLMs的高效忘却Abstract大型语言模型（LLM）在预训练和记忆各种文本数据方面取得了显着进展，然而，这个过程可能会遇到隐私问题和违反数据保护法规的问题。因此，从此类模型中轻松删除与个人用户相关的数据，同时在删除后不降低其预测质量的能力变得越来越重要。为了解决这些问题，在这项工作中，我们提出了一种有效的取消学习框架，通过将选择性师生目标学习的轻量级取消学习层引入到变压器中">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://humble2967738843.github.io/imgs/$%7Bfiilename%7D/image-20231107182632183-1699352793499-1.png">
<meta property="og:image" content="http://humble2967738843.github.io/imgs/$%7Bfiilename%7D/image-20231107183151791-1699353113266-3.png">
<meta property="og:image" content="http://humble2967738843.github.io/imgs/$%7Bfiilename%7D/image-20231107183310417-1699353191715-5.png">
<meta property="og:image" content="http://humble2967738843.github.io/imgs/$%7Bfiilename%7D/image-20231107183345526-1699353226937-7.png">
<meta property="og:image" content="http://humble2967738843.github.io/imgs/$%7Bfiilename%7D/image-20231107183433768-1699353275101-9.png">
<meta property="og:image" content="http://humble2967738843.github.io/imgs/$%7Bfiilename%7D/image-20231107183512165-1699353314324-11.png">
<meta property="og:image" content="http://humble2967738843.github.io/imgs/$%7Bfiilename%7D/image-20231107183611459-1699353373309-13.png">
<meta property="og:image" content="http://humble2967738843.github.io/imgs/$%7Bfiilename%7D/image-20231107183649235-1699353410763-15.png">
<meta property="article:published_time" content="2023-11-06T03:40:03.000Z">
<meta property="article:modified_time" content="2023-11-07T10:37:39.351Z">
<meta property="article:author" content="yuan long">
<meta property="article:tag" content="EMNLP2023">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://humble2967738843.github.io/imgs/$%7Bfiilename%7D/image-20231107182632183-1699352793499-1.png">
  
  
  
  <meta name="keywords" content="EMNLP2023">

  <!-- feed -->
  
    <link rel="alternate" href="/atom.xml" title="院龙的博客" type="application/atom+xml">
  

  <link rel="stylesheet" href="/css/main.css?v=1.27.0">

  

  

  
</head>
<body>

<div class="l_body s:aa content tech" id="start" layout="post" ><aside class="l_left"><div class="leftbar-container">


<header class="header"><div class="logo-wrap"><a class="avatar" href="/about/"><div class="bg" style="opacity:0;background-image:url(https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/avatar/round/rainbow64@3x.webp);"></div><img no-lazy class="avatar" src="undefined" onerror="javascript:this.classList.add('error');this.src='https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/image/2659360.svg';"></a><a class="title" href="/"><div class="main" ff="title">院龙的博客</div></a></div></header>

<div class="nav-area">
<div class="search-wrapper" id="search-wrapper"><form class="search-form"><a class="search-button" onclick="document.getElementById(&quot;search-input&quot;).focus();"><svg t="1705074644177" viewBox="0 0 1025 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="1560" width="200" height="200"><path d="M1008.839137 935.96571L792.364903 719.491476a56.783488 56.783488 0 0 0-80.152866 0 358.53545 358.53545 0 1 1 100.857314-335.166073 362.840335 362.840335 0 0 1-3.689902 170.145468 51.248635 51.248635 0 1 0 99.217358 26.444296 462.057693 462.057693 0 1 0-158.255785 242.303546l185.930047 185.725053a51.248635 51.248635 0 0 0 72.568068 0 51.248635 51.248635 0 0 0 0-72.978056z" p-id="1561"></path><path d="M616.479587 615.969233a50.428657 50.428657 0 0 0-61.498362-5.534852 174.655348 174.655348 0 0 1-177.525271 3.484907 49.403684 49.403684 0 0 0-58.833433 6.76482l-3.074918 2.869923a49.403684 49.403684 0 0 0 8.609771 78.10292 277.767601 277.767601 0 0 0 286.992355-5.739847 49.403684 49.403684 0 0 0 8.404776-76.667958z" p-id="1562"></path></svg></a><input type="text" class="search-input" id="search-input" placeholder="站内搜索"></form><div id="search-result"></div><div class="search-no-result">没有找到内容！</div></div>


<nav class="menu dis-select"></nav>
</div>
<div class="widgets">


<widget class="widget-wrapper post-list"><div class="widget-header dis-select"><span class="name">最近更新</span></div><div class="widget-body fs14"><a class="item title" href="/2023/12/02/16-1-ci-qian-ru-word2vec/"><span class="title">16.1词嵌入（Word2Vec）</span></a><a class="item title" href="/2023/11/02/suan-fa-bi-ji-v2.0/"><span class="title">算法笔记V2.0</span></a><a class="item title" href="/2023/12/06/ci-xiang-liang-yu-yu-yan-mo-xing/"><span class="title">词向量与语言模型</span></a><a class="item title" href="/2023/11/16/kaggle-s-30-days-of-ml/"><span class="title">Kaggle's_30_Days_Of_ML</span></a><a class="item title" href="/2023/11/02/qing-jing-xue-xi-chuang-jian-ren-wu-xiang-liang/"><span class="title">情境学习创建任务向量</span></a><a class="item title" href="/2023/11/02/she-ji-mo-shi/"><span class="title">设计模式</span></a><a class="item title" href="/2023/11/09/wen-xian-zheng-li/"><span class="title">文献整理</span></a><a class="item title" href="/2023/11/06/wang-diao-ni-xiang-wang-diao-de-dong-xi-llms-de-gao-xiao-wang-que/"><span class="title">忘掉你想忘掉的东西：LLMs的高效忘却</span></a><a class="item title" href="/2023/11/02/zhi-shi-shen-jing-yuan-zhong-xin-zhi-lu-yu-yan-wu-guan-zhi-shi-shen-jing-yuan-he-jian-bing-zhi-shi-shen-jing-yuan-de-fa-xian/"><span class="title">知识神经元中心之旅：语言无关知识神经元和简并知识神经元的发现</span></a><a class="item title" href="/2023/11/02/bian-ji-da-xing-yu-yan-mo-xing-wen-ti-fang-fa-he-ji-yu/"><span class="title">编辑大型语言模型：问题、方法和机遇</span></a></div></widget>
</div>

</div></aside><div class="l_main" id="main">





<div class="article banner top">
  <div class="content">
    <div class="top bread-nav footnote"><div class="left"><div class="flex-row" id="breadcrumb"><a class="cap breadcrumb" href="/">主页</a>
<span class="sep"></span><a class="cap breadcrumb" href="/">文章</a><span class="sep"></span><a class="cap breadcrumb-link" href="/categories/NLP%E9%A1%B6%E4%BC%9A/">NLP顶会</a></div>
<div class="flex-row" id="post-meta"><span class="text created">发布于：<time datetime="2023-11-06T03:40:03.000Z">2023-11-06</time></span><span class="sep updated"></span><span class="text updated">更新于：<time datetime="2023-11-07T10:37:39.351Z">2023-11-07</time></span></div></div></div>
    
    <div class="bottom only-title">
      
      <div class="text-area">
        <h1 class="text title"><span>忘掉你想忘掉的东西：LLMs的高效忘却</span></h1>
        
      </div>
    </div>
    
  </div>
  </div><article class="md-text content"><h1 id="忘掉你想忘掉的东西：LLMs的高效忘却"><a href="#忘掉你想忘掉的东西：LLMs的高效忘却" class="headerlink" title="忘掉你想忘掉的东西：LLMs的高效忘却"></a>忘掉你想忘掉的东西：LLMs的高效忘却</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>大型语言模型（LLM）在预训练和记忆各种文本数据方面取得了显着进展，然而，这个过程可能会遇到<strong>隐私问题</strong>和<strong>违反数据保护法规</strong>的问题。因此，<strong>从此类模型中轻松删除与个人用户相关的数据，同时在删除后不降低其预测质量的能力变得越来越重要</strong>。为了解决这些问题，在这项工作中，我们提出了一种有效的取消学习框架，<strong>通过将选择性师生目标学习的轻量级取消学习层引入到变压器中，可以有效地更新 LLM，而无需在数据删除后重新训练整个模型</strong>。此外，我们引入了<strong>一种融合机制来有效地结合不同的遗忘层，学习遗忘不同的数据集来处理一系列遗忘操作</strong>。<strong>分类和生成任务</strong>的实验证明了我们提出的方法与最先进的基线相比的有效性。</p>
<h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h2><p>利用大型语言模型（LLM）已成为各种 NLP 应用的主导范式（Brown et al., 2020；Chowdhery et al., 2022a；Kojima et al., 2022；Ouyang et al., 2022；Brown et al., 2020；Radford et al., 2019；Lewkowycz et al., 2022；Qin et al., 2023；Touvron et al., 2023），因为法学硕士在预训练或大范围微调期间会记住大量知识文本数据（Brown 等人，2020；Radford 等人，2019；Hoffmann 等人，2022；Webson 和 Pavlick，2022；Min 等人，2022；Liang 等人，2022；Carlini 等人， 2022）。然而，这些数据可能包含敏感信息，例如姓名、电话号码、电子邮件地址和私人临床记录（Jang 等人，2022 年；Kurmanji 等人，2023 年；Kumar 等人，2022）。广泛的研究表明，法学硕士可以生成私人信息，例如《麻省理工学院技术评论》主编，包括他的家庭成员、工作地址和电话号码（Carlini 等人，2022）。最近，欧盟的《通用数据保护条例》（GDPR）和美国的《加州消费者隐私法案》（CCPA）也对被遗忘权提出了新的规定，要求应用程序支持在用户请求时删除用户生成的内容（Sekhari）等人，2021 年；库马尔等人，2022 年）。有鉴于此，有必要为法学硕士提供一种高效且有效的方法来忘记用户所请求的信息。</p>
<p>​		最近人们开始关注通过再训练和数据预处理来处理法学硕士的此类忘却请求（Bourtoule et al., 2021; Kumar et al., 2022），其中训练数据存储在不同的隔离切片和每个检查点中在每个切片上训练后保存。当收到删除请求时，相应的数据点将从切片中删除，并且直到该数据点的模型检查点将用于进一步重新训练模型。遗忘的影响通常通过已删除数据的模型错误来体现（模型无法预测已删除数据）（Kurmanji et al., 2023; Jang et al., 2022）。其他工作也探索了确保差分隐私（DP）的算法设计（Yu et al., 2021；Li et al., 2021；Anil et al., 2021）。然而，像 SISA (Bourtoule et al., 2021) 这样的机器去学习方法通常需要大量的存储空间 (Bourtoule et al., 2021)，而 DP 方法可能会导致模型性能收敛缓慢和显着恶化 (Nguyen等人，2022）。此外，两者都需要重新训练整个模型，考虑到当前法学硕士的模型规模，这是极其昂贵和耗时的。这些限制也使它们无法动态处理一系列忘记学习的请求，这些请求通常是现实场景中的需要（Jang et al., 2022; Nguyen et al., 2022）。</p>
<p><img src="/../imgs/$%7Bfiilename%7D/image-20231107182632183-1699352793499-1.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/image-20231107182632183-1699352793499-1.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="image-20231107182632183"></p>
<p>【我们EUL框架的整体流程。遗忘层被插入到前馈网络之后的变压器层中。在训练过程中，只有取消学习层会忘记所请求的数据，而原始的 LLM 保持不变。对于每个删除请求，首先学习一个取消学习层，然后通过我们设计的融合机制与其他取消学习层合并，形成满足一系列删除请求的融合取消学习变压器。】</p>
<p>​		为了填补这些空白，在这项工作中，我们提出了一种 LLM 的高效忘却方法（EUL），可以有效地忘却需要忘记的内容，而无需完全重新训练整个模型，同时保留模型的性能。具体来说，我们提出了一种轻量级方法来学习遗忘层，该方法通过选择性的师生公式（Kurmanji 等人，2023）在几次更新中插入变压器，而无需调整大型语言模型。此外，我们引入了一种融合机制，通过最小化回归目标，有效地将学习忘记不同数据集的不同未学习层的权重组合到单个统一的未学习层。这使得 EUL 能够有效地处理一系列删除操作。为了证明我们提出的 EUL 的有效性，我们在不同设置下的 IMDB（Maas 等人，2011）和 SAMSum（Gliwa 等人，2019）上进行了实验，与最先进的取消学习或模型编辑基线相比。总而言之，我们的主要贡献有三个：</p>
<ul>
<li>我们引入了一种有效的忘却方法，通过选择性的师生公式以轻量级的方式消除所需数据的影响。</li>
<li>我们设计了一种融合机制，将学习忘记不同数据集的遗忘层合并到单个遗忘层中，以处理一系列删除操作。</li>
<li>我们在不同设置下使用不同规模的骨干模型进行分类和生成任务的实验，以说明EUL的有效性。</li>
</ul>
<h2 id="2-Related-Work"><a href="#2-Related-Work" class="headerlink" title="2 Related Work"></a>2 Related Work</h2><h3 id="2-1-Large-Language-Models"><a href="#2-1-Large-Language-Models" class="headerlink" title="2.1 Large Language Models"></a>2.1 Large Language Models</h3><p>大型语言模型最近取得了广泛的进展（Brown et al., 2020; Radford et al., 2019; Smith et al., 2022; Rae et al., 2021; Chowdhery et al., 2022b; Touvron et al., 2023 ），特别是在扩大法学硕士方面，例如 LLAMA（Touvron 等人，2023）、Megatron-turing NLG（Smith 等人，2022）、Gopher（Rae 等人，2021）和 PaLM Chowdhery 等人。 （2022b）。其他工作也通过更长的训练（Hoffmann et al., 2022）、指令调整（Wang et al., 2022；Zhou et al., 2023）和人类反馈（Ouyang et al., 2022）在较小的模型上取得了更好的性能。 。然而，最近的研究表明，训练数据，例如姓名、电话号码、电子邮件地址，甚至银行帐号等个人身份信息（Carlini 等人，2021；Lee 等人，2021；Carlini 等人，2022） ; Jagielski et al., 2022），可以很容易地从 LLM 中提取，因为 LLM 会记住数十亿个参数的训练数据（Carlini et al., 2022）。我们的工作旨在通过允许从法学硕士中学习的参数中有效地消除所请求的或私有的数据来缓解此类问题。</p>
<h3 id="2-2-Machine-Unlearning-for-Privacy"><a href="#2-2-Machine-Unlearning-for-Privacy" class="headerlink" title="2.2 Machine Unlearning for Privacy"></a>2.2 Machine Unlearning for Privacy</h3><p>为了减轻法学硕士的隐私风险，引入了机器取消学习方法来消除用户要求删除的训练示例的贡献（Bourtoule 等人，2021；Chien 等人，2023），包括重新训练深度学习的精确取消学习删除后新数据集上的学习模型（Bourtoule et al., 2021）和近似遗忘（Izzo et al., 2021; Golatkar et al., 2020; Kurmanji et al., 2023; Jang et al., 2022），旨在修改训练模型的权重以生成一组新的权重，这些权重近似于重新训练的权重。遗忘的影响通常通过已删除数据的模型错误来体现（模型无法预测已删除数据）（Kurmanji et al., 2023; Jang et al., 2022）。另一条工作重点是差分隐私（DP），它确保训练数据中的用户信息无法被推断（Dwork，2008；Yu et al.，2021；Li et al.，2021；Anil et al.，2021；Abadi等人，2016）。然而，这两种方法都需要重新训练整个模型，这是极其昂贵和耗时的，特别是对于大型语言模型，甚至会影响任务性能（Anil et al., 2021）。因此，它们无法动态处理删除序列（Jang et al., 2022；Nguyen et al., 2022）。为了克服这些限制，我们引入了一种有效的忘却方法以及融合机制来高效、动态地忘却用户数据序列。		我们的工作也与模型编辑相关（Mitchell et al., 2021; Belinkov et al., 2017; Dai et al., 2021; Wang et al., 2020），而他们通常专注于根据几个给定的数据编辑模型输出有关世界的语言结构或事实，而不是忘记所需的数据。</p>
<h2 id="3-Efficient-Unlearning-for-LLMs"><a href="#3-Efficient-Unlearning-for-LLMs" class="headerlink" title="3 Efficient Unlearning for LLMs"></a>3 Efficient Unlearning for LLMs</h2><p>本节介绍了我们为法学硕士（EUL）设计的高效遗忘方法，该方法可以高效、动态地处理一系列删除请求。整体流程如图1所示。形式上，对于在数据集D &#x3D; {(x, y)}上训练的大型语言模型F(.)，其中x是文本数据，y是相应的标签，并且删除请求忘记 Df &#x3D; {(xf , yf } )，我们的目标是学习满足以下条件的更新模型 F ′(.) (Kurmanji et al., 2023)：</p>
<p><img src="/../imgs/$%7Bfiilename%7D/image-20231107183151791-1699353113266-3.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/image-20231107183151791-1699353113266-3.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="image-20231107183151791"></p>
<p>其中 Dr &#x3D; D − Df &#x3D; {(xr, yr)} 指的是我们想要保留的数据，I(.) 是互信息。直观上，我们将用 F(.) 更新 F(.)，为我们想要保留的数据生成类似的输出，同时丢失有关对我们想要忘记的数据进行预测的所有信息。</p>
<h3 id="3-1-Learning-to-Forget-via-Unlearning-Layers"><a href="#3-1-Learning-to-Forget-via-Unlearning-Layers" class="headerlink" title="3.1 Learning to Forget via Unlearning Layers"></a>3.1 Learning to Forget via Unlearning Layers</h3><p>由于当前法学硕士的规模和训练数据量通常很大，更新模型 F(.) 中的所有参数（例如，在 Dr i 上重新训练 F(.)）变得极其昂贵。受参数高效微调最新进展的启发（Houlsby et al., 2019; Chien et al., 2023），我们通过 F (f (.)) 对 F ′(.) 进行建模，其中 f (.; W ) 是与 F (.) 相比，W 的参数数量显着减少。我们只会更新 f(.) 来满足取消学习的请求。</p>
<p>​		为了有效地实现等式 1 中的忘却目标，我们最小化了选择性的师生目标，其中学生模型 F ′(.) &#x3D; F (f (.)) 被学习以遵循 Dr 上的教师模型 F (.)，同时不服从F (.) 在 Df 上：</p>
<p><img src="/../imgs/$%7Bfiilename%7D/image-20231107183310417-1699353191715-5.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/image-20231107183310417-1699353191715-5.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="image-20231107183310417"></p>
<p>其中 α 是一个超参数，用于平衡忘记 xf 和保留 xr 之间的权衡。直观上，在训练过程中，f(.) 倾向于最小化更新模型的输出和原始模型在要保留的数据上的输出之间的 KL 散度，同时最大化它们在要忘记的数据上的输出之间的 KL 散度。</p>
<p>​		为了保持任务性能，我们针对保留数据上的任务损失优化 f(.)：</p>
<p><img src="/../imgs/$%7Bfiilename%7D/image-20231107183345526-1699353226937-7.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/image-20231107183345526-1699353226937-7.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="image-20231107183345526"></p>
<p>其中 l(.) 是与任务相关的损失，例如，对于分类任务，交叉熵损失 - log P (F (f (xr)))。</p>
<p>​		此外，我们还否定了法学硕士中使用的原始训练目标（例如，掩码语言建模目标（Raffel et al., 2020）），以忘记与数据相关的知识，以便忘记预先训练的参数并确保遗忘数据中的信息不能轻易地从 F(.) 中提取：</p>
<p><img src="/../imgs/$%7Bfiilename%7D/image-20231107183433768-1699353275101-9.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/image-20231107183433768-1699353275101-9.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="image-20231107183433768"></p>
<p>其中l(.)是预训练F(.)时使用的语言模型损失，例如，屏蔽语言模型损失，− log P (^ x|x − ^ x)（^ x是随机屏蔽的标记）。在我们的实验中，我们使用 T5 模型（Raffel et al., 2020）。因此，我们在这个损失项的输入开头添加了一个额外的“预测屏蔽词”。</p>
<p>​		我们的最终培训目标如下：</p>
<p><img src="/../imgs/$%7Bfiilename%7D/image-20231107183512165-1699353314324-11.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/image-20231107183512165-1699353314324-11.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="image-20231107183512165"></p>
<p>其中 λ 和 γ 是超参数。在实践中，遵循 Kurmanji 等人。 （2023），我们交替更新要忘记的数据和要保留的数据，以更稳定地优化 LEUL 中的最小-最大项。具体来说，我们迭代地对要保留的数据执行一个纪元更新，然后对要忘记的数据执行一个纪元更新。</p>
<h3 id="3-2-Fusing-Unlearning-Layers"><a href="#3-2-Fusing-Unlearning-Layers" class="headerlink" title="3.2 Fusing Unlearning Layers"></a>3.2 Fusing Unlearning Layers</h3><p>为了动态处理一系列遗忘请求并导出一个可以忘记所有请求数据的统一模型，我们引入了一种融合机制，可以合并不同的遗忘层 fi(.; Wi)，这些层学会了忘记 Df i &#x3D; (Xf i ,Yf i ) 将上一节中的单个 f m(.; Wm) 转换为单个 f m(.; Wm)。也就是说，我们希望 Df i 上的 f m(.) 输出接近 fi(.)：</p>
<p><img src="/../imgs/$%7Bfiilename%7D/image-20231107183611459-1699353373309-13.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/image-20231107183611459-1699353373309-13.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="image-20231107183611459"></p>
<p>这是一个线性回归问题，有一个封闭式解：</p>
<p><img src="/../imgs/$%7Bfiilename%7D/image-20231107183649235-1699353410763-15.png" class="lazyload placeholder" data-srcset="/../imgs/$%7Bfiilename%7D/image-20231107183649235-1699353410763-15.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="image-20231107183649235"></p>
<p>具体来说，为了导出合并的遗忘层 f m 的权重 Wm，我们将使用遗忘数据 Xf i T Xf i 的 LLM 中的遗忘层之前的隐藏表示的预先计算的内积矩阵，然后根据公式 7 计算 Wm。</p>
<p>​		融合机制确保了效率和隐私，因为它可以在没有任何额外训练的情况下执行，并且只需要存储要忘记的数据表示的内积矩阵而不是数据本身。</p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>在这项工作中，我们提出了 EUL，这是一种针对LLMs的有效忘却方法，可以<strong>通过选择性的师生目标通过学习忘却层来高效且有效地忘却用户请求的数据</strong>。我们进一步引入了<strong>一种融合机制，可以将不同的遗忘层合并到一个统一的层中，以动态地遗忘一系列数据</strong>。对不同设置（不同数据集、不同模型大小、不同遗忘集大小）的实验证明了我们提出的 EUL 方法与最先进的基线相比的有效性。</p>

<div class="article-footer fs14">
    <section id="license">
      <div class="header"><span>许可协议</span></div>
      <div class="body"><p>本文采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">署名-非商业性使用-相同方式共享 4.0 国际</a> 许可协议，转载请注明出处。</p>
</div>
    </section>
    </div>
</article>
<div class="related-wrap" id="read-next"><section class="body"><div class="item" id="prev"><div class="note">较新文章</div><a href="/2023/11/06/ji-yu-ti-shi-de-ling-yang-ben-guan-xi-chou-qu-fang-fa-tan-suo/">基于提示的零样本关系抽取方法探索</a></div><div class="item" id="next"><div class="note">较早文章</div><a href="/2023/11/03/bing-fa-bian-cheng/">并发编程</a></div></section></div>






<footer class="page-footer footnote"><hr><div class="text"><p>本站由 <a href="/">yuan long</a> 使用 <a target="_blank" rel="noopener" href="https://github.com/xaoxuu/hexo-theme-stellar/tree/1.27.0">Stellar 1.27.0</a> 主题创建。<br>本博客所有文章除特别声明外，均采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议，转载请注明出处。</p>
</div></footer>
<div class="main-mask" onclick="sidebar.dismiss()"></div></div><aside class="l_right">
<div class="widgets">



<widget class="widget-wrapper toc" id="data-toc" collapse="false"><div class="widget-header dis-select"><span class="name">本文目录</span><a class="cap-action" onclick="sidebar.toggleTOC()" ><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 6h11m-11 6h11m-11 6h11M4 6h1v4m-1 0h2m0 8H4c0-1 2-2 2-3s-1-1.5-2-1"/></svg></a></div><div class="widget-body"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%BF%98%E6%8E%89%E4%BD%A0%E6%83%B3%E5%BF%98%E6%8E%89%E7%9A%84%E4%B8%9C%E8%A5%BF%EF%BC%9ALLMs%E7%9A%84%E9%AB%98%E6%95%88%E5%BF%98%E5%8D%B4"><span class="toc-text">忘掉你想忘掉的东西：LLMs的高效忘却</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Abstract"><span class="toc-text">Abstract</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Introduction"><span class="toc-text">1 Introduction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Related-Work"><span class="toc-text">2 Related Work</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-Large-Language-Models"><span class="toc-text">2.1 Large Language Models</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-Machine-Unlearning-for-Privacy"><span class="toc-text">2.2 Machine Unlearning for Privacy</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Efficient-Unlearning-for-LLMs"><span class="toc-text">3 Efficient Unlearning for LLMs</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-Learning-to-Forget-via-Unlearning-Layers"><span class="toc-text">3.1 Learning to Forget via Unlearning Layers</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-Fusing-Unlearning-Layers"><span class="toc-text">3.2 Fusing Unlearning Layers</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Conclusion"><span class="toc-text">Conclusion</span></a></li></ol></li></ol></div><div class="widget-footer">

<a class="top" onclick="util.scrollTop()"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-width="1.5"><path d="M2 12c0-4.714 0-7.071 1.464-8.536C4.93 2 7.286 2 12 2c4.714 0 7.071 0 8.535 1.464C22 4.93 22 7.286 22 12c0 4.714 0 7.071-1.465 8.535C19.072 22 16.714 22 12 22s-7.071 0-8.536-1.465C2 19.072 2 16.714 2 12Z"/><path stroke-linecap="round" stroke-linejoin="round" d="m9 15.5l3-3l3 3m-6-4l3-3l3 3"/></g></svg><span>回到顶部</span></a></div></widget>
</div></aside><div class='float-panel blur'>
  <button type='button' style='display:none' class='laptop-only rightbar-toggle mobile' onclick='sidebar.rightbar()'>
    <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 6h11m-11 6h11m-11 6h11M4 6h1v4m-1 0h2m0 8H4c0-1 2-2 2-3s-1-1.5-2-1"/></svg>
  </button>
  <button type='button' style='display:none' class='mobile-only leftbar-toggle mobile' onclick='sidebar.leftbar()'>
    <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-width="1.5"><path d="M2 11c0-3.771 0-5.657 1.172-6.828C4.343 3 6.229 3 10 3h4c3.771 0 5.657 0 6.828 1.172C22 5.343 22 7.229 22 11v2c0 3.771 0 5.657-1.172 6.828C19.657 21 17.771 21 14 21h-4c-3.771 0-5.657 0-6.828-1.172C2 18.657 2 16.771 2 13z"/><path id="sep" stroke-linecap="round" d="M5.5 10h6m-5 4h4m4.5 7V3"/></g></svg>
  </button>
</div>
</div><div class="scripts">
<script type="text/javascript">
  const ctx = {
    date_suffix: {
      just: `刚刚`,
      min: `分钟前`,
      hour: `小时前`,
      day: `天前`,
    },
    root : `/`,
  };

  // required plugins (only load if needs)
  if (`local_search`) {
    ctx.search = {};
    ctx.search.service = `local_search`;
    if (ctx.search.service == 'local_search') {
      let service_obj = Object.assign({}, `{"field":"all","path":"/search.json","content":true,"sort":"-date"}`);
      ctx.search[ctx.search.service] = service_obj;
    }
  }
  const def = {
    avatar: `https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/avatar/round/3442075.svg`,
    cover: `https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/cover/76b86c0226ffd.svg`,
  };
  const deps = {
    jquery: `https://cdn.bootcdn.net/ajax/libs/jquery/3.7.1/jquery.min.js`,
    marked: `https://cdn.bootcdn.net/ajax/libs/marked/4.0.18/marked.min.js`
  }
  

</script>

<script type="text/javascript">
  const utils = {
    // 懒加载 css https://github.com/filamentgroup/loadCSS
    css: (href, before, media, attributes) => {
      var doc = window.document;
      var ss = doc.createElement("link");
      var ref;
      if (before) {
        ref = before;
      } else {
        var refs = (doc.body || doc.getElementsByTagName("head")[0]).childNodes;
        ref = refs[refs.length - 1];
      }
      var sheets = doc.styleSheets;
      if (attributes) {
        for (var attributeName in attributes) {
          if (attributes.hasOwnProperty(attributeName)) {
            ss.setAttribute(attributeName, attributes[attributeName]);
          }
        }
      }
      ss.rel = "stylesheet";
      ss.href = href;
      ss.media = "only x";
      function ready(cb) {
        if (doc.body) {
          return cb();
        }
        setTimeout(function () {
          ready(cb);
        });
      }
      ready(function () {
        ref.parentNode.insertBefore(ss, before ? ref : ref.nextSibling);
      });
      var onloadcssdefined = function (cb) {
        var resolvedHref = ss.href;
        var i = sheets.length;
        while (i--) {
          if (sheets[i].href === resolvedHref) {
            return cb();
          }
        }
        setTimeout(function () {
          onloadcssdefined(cb);
        });
      };
      function loadCB() {
        if (ss.addEventListener) {
          ss.removeEventListener("load", loadCB);
        }
        ss.media = media || "all";
      }
      if (ss.addEventListener) {
        ss.addEventListener("load", loadCB);
      }
      ss.onloadcssdefined = onloadcssdefined;
      onloadcssdefined(loadCB);
      return ss;
    },

    js: (src, opt) => new Promise((resolve, reject) => {
      var script = document.createElement('script');
      if (src.startsWith('/')){
        src = ctx.root + src.substring(1);
      }
      script.src = src;
      if (opt) {
        for (let key of Object.keys(opt)) {
          script[key] = opt[key]
        }
      } else {
        // 默认异步，如果需要同步，第二个参数传入 {} 即可
        script.async = true
      }
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    }),

    jq: (fn) => {
      if (typeof jQuery === 'undefined') {
        utils.js(deps.jquery).then(fn)
      } else {
        fn()
      }
    },
    
    onLoading: (el) => {
      if (el) {
        $(el).append('<div class="loading-wrap"><svg xmlns="http://www.w3.org/2000/svg" width="2em" height="2em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-width="2"><path stroke-dasharray="60" stroke-dashoffset="60" stroke-opacity=".3" d="M12 3C16.9706 3 21 7.02944 21 12C21 16.9706 16.9706 21 12 21C7.02944 21 3 16.9706 3 12C3 7.02944 7.02944 3 12 3Z"><animate fill="freeze" attributeName="stroke-dashoffset" dur="1.3s" values="60;0"/></path><path stroke-dasharray="15" stroke-dashoffset="15" d="M12 3C16.9706 3 21 7.02944 21 12"><animate fill="freeze" attributeName="stroke-dashoffset" dur="0.3s" values="15;0"/><animateTransform attributeName="transform" dur="1.5s" repeatCount="indefinite" type="rotate" values="0 12 12;360 12 12"/></path></g></svg></div>');
      }
    },
    onLoadSuccess: (el) => {
      if (el) {
        $(el).find('.loading-wrap').remove();
      }
    },
    onLoadFailure: (el) => {
      if (el) {
        $(el).find('.loading-wrap svg').remove();
        $(el).find('.loading-wrap').append('<svg xmlns="http://www.w3.org/2000/svg" width="2em" height="2em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path stroke-dasharray="60" stroke-dashoffset="60" d="M12 3L21 20H3L12 3Z"><animate fill="freeze" attributeName="stroke-dashoffset" dur="0.5s" values="60;0"/></path><path stroke-dasharray="6" stroke-dashoffset="6" d="M12 10V14"><animate fill="freeze" attributeName="stroke-dashoffset" begin="0.6s" dur="0.2s" values="6;0"/></path></g><circle cx="12" cy="17" r="1" fill="currentColor" fill-opacity="0"><animate fill="freeze" attributeName="fill-opacity" begin="0.8s" dur="0.4s" values="0;1"/></circle></svg>');
        $(el).find('.loading-wrap').addClass('error');
      }
    },
    request: (el, url, callback, onFailure) => {
      let retryTimes = 3;
      utils.onLoading(el);
      function req() {
        return new Promise((resolve, reject) => {
          let status = 0; // 0 等待 1 完成 2 超时
          let timer = setTimeout(() => {
            if (status === 0) {
              status = 2;
              timer = null;
              reject('请求超时');
              if (retryTimes == 0) {
                onFailure();
              }
            }
          }, 5000);
          fetch(url).then(function(response) {
            if (status !== 2) {
              clearTimeout(timer);
              resolve(response);
              timer = null;
              status = 1;
            }
            if (response.ok) {
              return response.json();
            }
            throw new Error('Network response was not ok.');
          }).then(function(data) {
            retryTimes = 0;
            utils.onLoadSuccess(el);
            callback(data);
          }).catch(function(error) {
            if (retryTimes > 0) {
              retryTimes -= 1;
              setTimeout(() => {
                req();
              }, 5000);
            } else {
              utils.onLoadFailure(el);
              onFailure();
            }
          });
        });
      }
      req();
    },
  };
</script>

<script>
  const sidebar = {
    leftbar: () => {
      if (l_body) {
        l_body.toggleAttribute('leftbar');
        l_body.removeAttribute('rightbar');
      }
    },
    rightbar: () => {
      if (l_body) {
        l_body.toggleAttribute('rightbar');
        l_body.removeAttribute('leftbar');
      }
    },
    dismiss: () => {
      if (l_body) {
        l_body.removeAttribute('leftbar');
        l_body.removeAttribute('rightbar');
      }
    },
    toggleTOC: () => {
      document.querySelector('#data-toc').classList.toggle('collapse');
    }
  }
</script>

<!-- required -->
<script src="/js/main.js?v=1.27.0" async></script>

<!-- optional -->



<script defer>
  window.addEventListener('DOMContentLoaded', (event) => {
    ctx.services = Object.assign({}, JSON.parse(`{"mdrender":{"js":"/js/services/mdrender.js"},"siteinfo":{"js":"/js/services/siteinfo.js","api":null},"ghinfo":{"js":"/js/services/ghinfo.js"},"sites":{"js":"/js/services/sites.js"},"friends":{"js":"/js/services/friends.js"},"timeline":{"js":"/js/services/timeline.js"},"fcircle":{"js":"/js/services/fcircle.js"},"weibo":{"js":"/js/services/weibo.js"},"memos":{"js":"/js/services/memos.js"}}`));
    for (let id of Object.keys(ctx.services)) {
      const js = ctx.services[id].js;
      if (id == 'siteinfo') {
        ctx.cardlinks = document.querySelectorAll('a.link-card[cardlink]');
        if (ctx.cardlinks?.length > 0) {
          utils.js(js, { defer: true }).then(function () {
            setCardLink(ctx.cardlinks);
          });
        }
      } else {
        const els = document.getElementsByClassName(`ds-${id}`);
        if (els?.length > 0) {
          utils.jq(() => {
            if (id == 'timeline' || 'memos' || 'marked') {
              utils.js(deps.marked).then(function () {
                utils.js(js, { defer: true });
              });
            } else {
              utils.js(js, { defer: true });
            }
          });
        }
      }
    }
  });
</script>

<script>
  window.addEventListener('DOMContentLoaded', (event) => {
    ctx.search = {
      path: `/search.json`,
    }
    utils.js('/js/search/local-search.js', { defer: true });
  });
</script><script>
  window.FPConfig = {
    delay: 0,
    ignoreKeywords: [],
    maxRPS: 5,
    hoverDelay: 25
  };
</script>
<script defer src="https://cdn.bootcdn.net/ajax/libs/flying-pages/2.1.2/flying-pages.min.js"></script><script defer src="https://cdn.bootcdn.net/ajax/libs/vanilla-lazyload/17.8.4/lazyload.min.js"></script>
<script>
  // https://www.npmjs.com/package/vanilla-lazyload
  // Set the options globally
  // to make LazyLoad self-initialize
  window.lazyLoadOptions = {
    elements_selector: ".lazy",
  };
  // Listen to the initialization event
  // and get the instance of LazyLoad
  window.addEventListener(
    "LazyLoad::Initialized",
    function (event) {
      window.lazyLoadInstance = event.detail.instance;
    },
    false
  );
  document.addEventListener('DOMContentLoaded', function () {
    window.lazyLoadInstance?.update();
  });
</script><script>
  ctx.fancybox = {
    selector: `.timenode p>img`,
    css: `https://cdn.bootcdn.net/ajax/libs/fancyapps-ui/5.0.22/fancybox/fancybox.min.css`,
    js: `https://cdn.bootcdn.net/ajax/libs/fancyapps-ui/5.0.22/fancybox/fancybox.umd.min.js`
  };
  var selector = '[data-fancybox]:not(.error)';
  if (ctx.fancybox.selector) {
    selector += `, ${ctx.fancybox.selector}`
  }
  var needFancybox = document.querySelectorAll(selector).length !== 0;
  if (!needFancybox) {
    const els = document.getElementsByClassName('ds-memos');
    if (els != undefined && els.length > 0) {
      needFancybox = true;
    }
  }
  if (needFancybox) {
    utils.css(ctx.fancybox.css);
    utils.js(ctx.fancybox.js, { defer: true }).then(function () {
      Fancybox.bind(selector, {
        hideScrollbar: false,
        Thumbs: {
          autoStart: false,
        },
        caption: (fancybox, slide) => {
          return slide.triggerEl.alt || null
        }
      });
    })
  }
</script><script>
  window.addEventListener('DOMContentLoaded', (event) => {
    const swiper_api = document.getElementById('swiper-api');
    if (swiper_api != undefined) {
      utils.css(`https://unpkg.com/swiper@10.3.1/swiper-bundle.min.css`);
      utils.js(`https://unpkg.com/swiper@10.3.1/swiper-bundle.min.js`, { defer: true }).then(function () {
        const effect = swiper_api.getAttribute('effect') || '';
        var swiper = new Swiper('.swiper#swiper-api', {
          slidesPerView: 'auto',
          spaceBetween: 8,
          centeredSlides: true,
          effect: effect,
          loop: true,
          pagination: {
            el: '.swiper-pagination',
            clickable: true,
          },
          navigation: {
            nextEl: '.swiper-button-next',
            prevEl: '.swiper-button-prev',
          },
        });
      })
    }
  });
</script><script>
  document.addEventListener('DOMContentLoaded', function () {
    window.codeElements = document.querySelectorAll('.code');
    if (window.codeElements.length > 0) {
      ctx.copycode = {
        default_text: `Copy`,
        success_text: `Copied`,
        toast: `复制成功`,
      };
      utils.js('/js/plugins/copycode.js');
    }
  });
</script>


<!-- inject -->

</div></body></html>
